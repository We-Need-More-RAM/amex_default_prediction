{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63470949",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to optimize hyperparameters for the XGBoost model. The feature engineering process was revamped, and gave me data with the following features:\n",
    "\n",
    "Null count feature for each customer and column, scaled with StandardScaler to return values similar to continuous features.  \n",
    "Dummy variable columns for each categorical feature, including one for Null.  \n",
    "Continuous features capped at -3 and 3 to reduce the impact of outliers.  \n",
    "Aggregate features calculated from the continuous columns: minimum, maximum, median, standard deviation, last, and change over course of account.\n",
    "\n",
    "I achieved the best amex metric score of 0.77 on the validation set with this data. My model appeared to be overfit to the training sample, which scored 0.87. I have investigated useful hyperparameters to adjust for overfitting and I'm left with the following list:\n",
    "\n",
    "colsample_bytree  \n",
    "subsample  \n",
    "max_depth  \n",
    "gamma  \n",
    "eta  \n",
    "min_child_weight  \n",
    "scale_pos_weight\n",
    "\n",
    "I will investigate different values for these hyperparameters and combinations of these changes to optimize my model for the dataset.\n",
    "\n",
    "Starting hyperparameters from the best model:\n",
    "\n",
    "params = {  \n",
    "    'verbosity': 1,  \n",
    "    'max_depth': 4,  \n",
    "    'objective': 'binary:logistic',  \n",
    "    'eta': 0.15,  \n",
    "    'random_state': seed,  \n",
    "    'colsample_bytree': 0.8,  \n",
    "    'colsample_bylevel': 0.8  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8049b68e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosave disabled\n"
     ]
    }
   ],
   "source": [
    "%autosave 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc8f8a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import myfunctions as mf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ff733f",
   "metadata": {},
   "source": [
    "Read in the processed data from the boosting3 notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e182dae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39007, 1272), (214152, 1272))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train_final.csv')\n",
    "valid = pd.read_csv('valid_final.csv')\n",
    "\n",
    "train.shape, valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105fc79d",
   "metadata": {},
   "source": [
    "Read in the targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a312b9a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39007, 2), (214152, 2))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_url = '../../data/prepared/'\n",
    "\n",
    "train_labels = pd.read_csv(base_url + 'train_labels.csv')\n",
    "valid_labels = pd.read_csv(base_url + 'val_labels.csv')\n",
    "\n",
    "train_labels.shape, valid_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b5f208",
   "metadata": {},
   "source": [
    "Match up the features with the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c52300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(train_labels, how='left', on='customer_ID')\n",
    "valid = valid.merge(valid_labels, how='left', on='customer_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8923a94",
   "metadata": {},
   "source": [
    "Create the DMatrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f6f3349",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix = xgb.DMatrix(train.drop(columns=['customer_ID', 'target']), label=train['target'])\n",
    "valid_matrix = xgb.DMatrix(valid.drop(columns=['customer_ID', 'target']), label=valid['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bc78b7",
   "metadata": {},
   "source": [
    "My first pass will try lowering the colsample_bytree to pull from fewer features every time a new tree is created in an attempt to increase my model's ability to generalize to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "876ea516",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 1000\n",
    "seed = 42\n",
    "\n",
    "params1 = {\n",
    "    'verbosity': 1,\n",
    "    'max_depth': 4,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eta': 0.15,\n",
    "    'random_state': seed,\n",
    "    'colsample_bytree': 0.4,\n",
    "    'colsample_bylevel': 0.8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a807fb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTrain-logloss:0.61053\tValid-logloss:0.61163\n",
      "[1]\tTrain-logloss:0.54265\tValid-logloss:0.54423\n",
      "[2]\tTrain-logloss:0.49193\tValid-logloss:0.49434\n",
      "[3]\tTrain-logloss:0.45108\tValid-logloss:0.45391\n",
      "[4]\tTrain-logloss:0.41864\tValid-logloss:0.42197\n",
      "[5]\tTrain-logloss:0.39005\tValid-logloss:0.39399\n",
      "[6]\tTrain-logloss:0.36667\tValid-logloss:0.37108\n",
      "[7]\tTrain-logloss:0.34801\tValid-logloss:0.35308\n",
      "[8]\tTrain-logloss:0.33170\tValid-logloss:0.33718\n",
      "[9]\tTrain-logloss:0.31815\tValid-logloss:0.32411\n",
      "[10]\tTrain-logloss:0.30680\tValid-logloss:0.31320\n",
      "[11]\tTrain-logloss:0.29691\tValid-logloss:0.30391\n",
      "[12]\tTrain-logloss:0.28853\tValid-logloss:0.29599\n",
      "[13]\tTrain-logloss:0.28119\tValid-logloss:0.28911\n",
      "[14]\tTrain-logloss:0.27442\tValid-logloss:0.28296\n",
      "[15]\tTrain-logloss:0.26837\tValid-logloss:0.27751\n",
      "[16]\tTrain-logloss:0.26337\tValid-logloss:0.27306\n",
      "[17]\tTrain-logloss:0.25887\tValid-logloss:0.26899\n",
      "[18]\tTrain-logloss:0.25492\tValid-logloss:0.26556\n",
      "[19]\tTrain-logloss:0.25128\tValid-logloss:0.26236\n",
      "[20]\tTrain-logloss:0.24810\tValid-logloss:0.25964\n",
      "[21]\tTrain-logloss:0.24537\tValid-logloss:0.25741\n",
      "[22]\tTrain-logloss:0.24282\tValid-logloss:0.25548\n",
      "[23]\tTrain-logloss:0.24033\tValid-logloss:0.25362\n",
      "[24]\tTrain-logloss:0.23827\tValid-logloss:0.25196\n",
      "[25]\tTrain-logloss:0.23616\tValid-logloss:0.25043\n",
      "[26]\tTrain-logloss:0.23421\tValid-logloss:0.24911\n",
      "[27]\tTrain-logloss:0.23248\tValid-logloss:0.24803\n",
      "[28]\tTrain-logloss:0.23091\tValid-logloss:0.24695\n",
      "[29]\tTrain-logloss:0.22950\tValid-logloss:0.24604\n",
      "[30]\tTrain-logloss:0.22797\tValid-logloss:0.24502\n",
      "[31]\tTrain-logloss:0.22666\tValid-logloss:0.24417\n",
      "[32]\tTrain-logloss:0.22529\tValid-logloss:0.24339\n",
      "[33]\tTrain-logloss:0.22403\tValid-logloss:0.24270\n",
      "[34]\tTrain-logloss:0.22288\tValid-logloss:0.24208\n",
      "[35]\tTrain-logloss:0.22179\tValid-logloss:0.24150\n",
      "[36]\tTrain-logloss:0.22079\tValid-logloss:0.24101\n",
      "[37]\tTrain-logloss:0.21970\tValid-logloss:0.24048\n",
      "[38]\tTrain-logloss:0.21867\tValid-logloss:0.23993\n",
      "[39]\tTrain-logloss:0.21772\tValid-logloss:0.23950\n",
      "[40]\tTrain-logloss:0.21668\tValid-logloss:0.23910\n",
      "[41]\tTrain-logloss:0.21561\tValid-logloss:0.23867\n",
      "[42]\tTrain-logloss:0.21472\tValid-logloss:0.23830\n",
      "[43]\tTrain-logloss:0.21379\tValid-logloss:0.23802\n",
      "[44]\tTrain-logloss:0.21293\tValid-logloss:0.23780\n",
      "[45]\tTrain-logloss:0.21215\tValid-logloss:0.23746\n",
      "[46]\tTrain-logloss:0.21134\tValid-logloss:0.23710\n",
      "[47]\tTrain-logloss:0.21060\tValid-logloss:0.23686\n",
      "[48]\tTrain-logloss:0.20979\tValid-logloss:0.23661\n",
      "[49]\tTrain-logloss:0.20891\tValid-logloss:0.23633\n",
      "[50]\tTrain-logloss:0.20812\tValid-logloss:0.23598\n",
      "[51]\tTrain-logloss:0.20730\tValid-logloss:0.23575\n",
      "[52]\tTrain-logloss:0.20671\tValid-logloss:0.23559\n",
      "[53]\tTrain-logloss:0.20607\tValid-logloss:0.23533\n",
      "[54]\tTrain-logloss:0.20518\tValid-logloss:0.23520\n",
      "[55]\tTrain-logloss:0.20461\tValid-logloss:0.23503\n",
      "[56]\tTrain-logloss:0.20390\tValid-logloss:0.23490\n",
      "[57]\tTrain-logloss:0.20326\tValid-logloss:0.23472\n",
      "[58]\tTrain-logloss:0.20252\tValid-logloss:0.23464\n",
      "[59]\tTrain-logloss:0.20192\tValid-logloss:0.23453\n",
      "[60]\tTrain-logloss:0.20133\tValid-logloss:0.23444\n",
      "[61]\tTrain-logloss:0.20063\tValid-logloss:0.23436\n",
      "[62]\tTrain-logloss:0.19992\tValid-logloss:0.23419\n",
      "[63]\tTrain-logloss:0.19945\tValid-logloss:0.23406\n",
      "[64]\tTrain-logloss:0.19881\tValid-logloss:0.23391\n",
      "[65]\tTrain-logloss:0.19805\tValid-logloss:0.23385\n",
      "[66]\tTrain-logloss:0.19756\tValid-logloss:0.23377\n",
      "[67]\tTrain-logloss:0.19690\tValid-logloss:0.23367\n",
      "[68]\tTrain-logloss:0.19633\tValid-logloss:0.23359\n",
      "[69]\tTrain-logloss:0.19559\tValid-logloss:0.23355\n",
      "[70]\tTrain-logloss:0.19498\tValid-logloss:0.23350\n",
      "[71]\tTrain-logloss:0.19441\tValid-logloss:0.23340\n",
      "[72]\tTrain-logloss:0.19383\tValid-logloss:0.23331\n",
      "[73]\tTrain-logloss:0.19320\tValid-logloss:0.23321\n",
      "[74]\tTrain-logloss:0.19257\tValid-logloss:0.23311\n",
      "[75]\tTrain-logloss:0.19219\tValid-logloss:0.23301\n",
      "[76]\tTrain-logloss:0.19163\tValid-logloss:0.23298\n",
      "[77]\tTrain-logloss:0.19107\tValid-logloss:0.23303\n",
      "[78]\tTrain-logloss:0.19039\tValid-logloss:0.23293\n",
      "[79]\tTrain-logloss:0.18978\tValid-logloss:0.23290\n",
      "[80]\tTrain-logloss:0.18907\tValid-logloss:0.23267\n",
      "[81]\tTrain-logloss:0.18868\tValid-logloss:0.23262\n",
      "[82]\tTrain-logloss:0.18803\tValid-logloss:0.23259\n",
      "[83]\tTrain-logloss:0.18757\tValid-logloss:0.23254\n",
      "[84]\tTrain-logloss:0.18697\tValid-logloss:0.23254\n",
      "[85]\tTrain-logloss:0.18645\tValid-logloss:0.23249\n",
      "[86]\tTrain-logloss:0.18616\tValid-logloss:0.23241\n",
      "[87]\tTrain-logloss:0.18552\tValid-logloss:0.23243\n",
      "[88]\tTrain-logloss:0.18492\tValid-logloss:0.23245\n"
     ]
    }
   ],
   "source": [
    "model1 = xgb.train(params1, train_matrix, steps, early_stopping_rounds=3,\n",
    "                  evals=[(train_matrix, 'Train'), (valid_matrix, 'Valid')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7375ae7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7710386427762723"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1 = mf.model_evaluator(model1, valid_matrix, valid['target'])\n",
    "result1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9628e715",
   "metadata": {},
   "source": [
    "Roughly the same as my best result. No drop in performance on the out-of-set data and the difference between my train loss/validation loss is less severe. I will keep this new value for colsample_bytree for future tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0910ec06",
   "metadata": {},
   "source": [
    "In my next pass, I will introduce the subsample hyperparameter. This value means that 80% of all my training data will be sampled prior to growing another tree. The default value is 1: choosing a value less than 1 is a way to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b78468f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "params2 = {\n",
    "    'verbosity': 1,\n",
    "    'max_depth': 4,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eta': 0.15,\n",
    "    'random_state': seed,\n",
    "    'colsample_bytree': 0.4,\n",
    "    'colsample_bylevel': 0.8,\n",
    "    'subsample': 0.8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f121cc42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTrain-logloss:0.61091\tValid-logloss:0.61205\n",
      "[1]\tTrain-logloss:0.54526\tValid-logloss:0.54706\n",
      "[2]\tTrain-logloss:0.49199\tValid-logloss:0.49420\n",
      "[3]\tTrain-logloss:0.45241\tValid-logloss:0.45507\n",
      "[4]\tTrain-logloss:0.41840\tValid-logloss:0.42169\n",
      "[5]\tTrain-logloss:0.39033\tValid-logloss:0.39404\n",
      "[6]\tTrain-logloss:0.36715\tValid-logloss:0.37153\n",
      "[7]\tTrain-logloss:0.34798\tValid-logloss:0.35279\n",
      "[8]\tTrain-logloss:0.33173\tValid-logloss:0.33706\n",
      "[9]\tTrain-logloss:0.31811\tValid-logloss:0.32398\n",
      "[10]\tTrain-logloss:0.30675\tValid-logloss:0.31314\n",
      "[11]\tTrain-logloss:0.29658\tValid-logloss:0.30370\n",
      "[12]\tTrain-logloss:0.28823\tValid-logloss:0.29587\n",
      "[13]\tTrain-logloss:0.28060\tValid-logloss:0.28887\n",
      "[14]\tTrain-logloss:0.27392\tValid-logloss:0.28281\n",
      "[15]\tTrain-logloss:0.26824\tValid-logloss:0.27760\n",
      "[16]\tTrain-logloss:0.26324\tValid-logloss:0.27314\n",
      "[17]\tTrain-logloss:0.25899\tValid-logloss:0.26926\n",
      "[18]\tTrain-logloss:0.25497\tValid-logloss:0.26554\n",
      "[19]\tTrain-logloss:0.25160\tValid-logloss:0.26268\n",
      "[20]\tTrain-logloss:0.24863\tValid-logloss:0.26012\n",
      "[21]\tTrain-logloss:0.24572\tValid-logloss:0.25780\n",
      "[22]\tTrain-logloss:0.24324\tValid-logloss:0.25569\n",
      "[23]\tTrain-logloss:0.24088\tValid-logloss:0.25384\n",
      "[24]\tTrain-logloss:0.23870\tValid-logloss:0.25226\n",
      "[25]\tTrain-logloss:0.23654\tValid-logloss:0.25083\n",
      "[26]\tTrain-logloss:0.23469\tValid-logloss:0.24960\n",
      "[27]\tTrain-logloss:0.23303\tValid-logloss:0.24837\n",
      "[28]\tTrain-logloss:0.23126\tValid-logloss:0.24717\n",
      "[29]\tTrain-logloss:0.22983\tValid-logloss:0.24623\n",
      "[30]\tTrain-logloss:0.22838\tValid-logloss:0.24535\n",
      "[31]\tTrain-logloss:0.22702\tValid-logloss:0.24448\n",
      "[32]\tTrain-logloss:0.22568\tValid-logloss:0.24363\n",
      "[33]\tTrain-logloss:0.22445\tValid-logloss:0.24295\n",
      "[34]\tTrain-logloss:0.22341\tValid-logloss:0.24232\n",
      "[35]\tTrain-logloss:0.22237\tValid-logloss:0.24174\n",
      "[36]\tTrain-logloss:0.22124\tValid-logloss:0.24110\n",
      "[37]\tTrain-logloss:0.22036\tValid-logloss:0.24065\n",
      "[38]\tTrain-logloss:0.21926\tValid-logloss:0.24020\n",
      "[39]\tTrain-logloss:0.21831\tValid-logloss:0.23991\n",
      "[40]\tTrain-logloss:0.21747\tValid-logloss:0.23953\n",
      "[41]\tTrain-logloss:0.21641\tValid-logloss:0.23906\n",
      "[42]\tTrain-logloss:0.21554\tValid-logloss:0.23863\n",
      "[43]\tTrain-logloss:0.21468\tValid-logloss:0.23829\n",
      "[44]\tTrain-logloss:0.21368\tValid-logloss:0.23794\n",
      "[45]\tTrain-logloss:0.21275\tValid-logloss:0.23755\n",
      "[46]\tTrain-logloss:0.21184\tValid-logloss:0.23736\n",
      "[47]\tTrain-logloss:0.21105\tValid-logloss:0.23712\n",
      "[48]\tTrain-logloss:0.21035\tValid-logloss:0.23687\n",
      "[49]\tTrain-logloss:0.20961\tValid-logloss:0.23669\n",
      "[50]\tTrain-logloss:0.20888\tValid-logloss:0.23648\n",
      "[51]\tTrain-logloss:0.20803\tValid-logloss:0.23625\n",
      "[52]\tTrain-logloss:0.20727\tValid-logloss:0.23596\n",
      "[53]\tTrain-logloss:0.20655\tValid-logloss:0.23578\n",
      "[54]\tTrain-logloss:0.20590\tValid-logloss:0.23568\n",
      "[55]\tTrain-logloss:0.20523\tValid-logloss:0.23554\n",
      "[56]\tTrain-logloss:0.20466\tValid-logloss:0.23545\n",
      "[57]\tTrain-logloss:0.20391\tValid-logloss:0.23533\n",
      "[58]\tTrain-logloss:0.20310\tValid-logloss:0.23516\n",
      "[59]\tTrain-logloss:0.20226\tValid-logloss:0.23504\n",
      "[60]\tTrain-logloss:0.20182\tValid-logloss:0.23489\n",
      "[61]\tTrain-logloss:0.20125\tValid-logloss:0.23485\n",
      "[62]\tTrain-logloss:0.20068\tValid-logloss:0.23475\n",
      "[63]\tTrain-logloss:0.20023\tValid-logloss:0.23461\n",
      "[64]\tTrain-logloss:0.19941\tValid-logloss:0.23450\n",
      "[65]\tTrain-logloss:0.19869\tValid-logloss:0.23434\n",
      "[66]\tTrain-logloss:0.19807\tValid-logloss:0.23425\n",
      "[67]\tTrain-logloss:0.19746\tValid-logloss:0.23415\n",
      "[68]\tTrain-logloss:0.19695\tValid-logloss:0.23406\n",
      "[69]\tTrain-logloss:0.19635\tValid-logloss:0.23400\n",
      "[70]\tTrain-logloss:0.19560\tValid-logloss:0.23398\n",
      "[71]\tTrain-logloss:0.19505\tValid-logloss:0.23405\n",
      "[72]\tTrain-logloss:0.19447\tValid-logloss:0.23404\n",
      "[73]\tTrain-logloss:0.19369\tValid-logloss:0.23391\n",
      "[74]\tTrain-logloss:0.19326\tValid-logloss:0.23382\n",
      "[75]\tTrain-logloss:0.19266\tValid-logloss:0.23376\n",
      "[76]\tTrain-logloss:0.19201\tValid-logloss:0.23368\n",
      "[77]\tTrain-logloss:0.19145\tValid-logloss:0.23363\n",
      "[78]\tTrain-logloss:0.19102\tValid-logloss:0.23363\n",
      "[79]\tTrain-logloss:0.19041\tValid-logloss:0.23348\n",
      "[80]\tTrain-logloss:0.18969\tValid-logloss:0.23332\n",
      "[81]\tTrain-logloss:0.18937\tValid-logloss:0.23323\n",
      "[82]\tTrain-logloss:0.18889\tValid-logloss:0.23318\n",
      "[83]\tTrain-logloss:0.18823\tValid-logloss:0.23309\n",
      "[84]\tTrain-logloss:0.18770\tValid-logloss:0.23301\n",
      "[85]\tTrain-logloss:0.18712\tValid-logloss:0.23300\n",
      "[86]\tTrain-logloss:0.18655\tValid-logloss:0.23288\n",
      "[87]\tTrain-logloss:0.18609\tValid-logloss:0.23281\n",
      "[88]\tTrain-logloss:0.18549\tValid-logloss:0.23277\n",
      "[89]\tTrain-logloss:0.18510\tValid-logloss:0.23272\n",
      "[90]\tTrain-logloss:0.18485\tValid-logloss:0.23271\n",
      "[91]\tTrain-logloss:0.18440\tValid-logloss:0.23272\n",
      "[92]\tTrain-logloss:0.18383\tValid-logloss:0.23265\n",
      "[93]\tTrain-logloss:0.18330\tValid-logloss:0.23268\n",
      "[94]\tTrain-logloss:0.18274\tValid-logloss:0.23268\n"
     ]
    }
   ],
   "source": [
    "model2 = xgb.train(params2, train_matrix, steps, early_stopping_rounds=3,\n",
    "                   evals=[(train_matrix, 'Train'), (valid_matrix, 'Valid')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3dd20482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7700153701869945"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2 = mf.model_evaluator(model2, valid_matrix, valid['target'])\n",
    "result2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d2e3b1",
   "metadata": {},
   "source": [
    "My results are still the same. I will try a more drastic subsample value before moving on to explore other hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba710b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "params3 = {\n",
    "    'verbosity': 1,\n",
    "    'max_depth': 4,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eta': 0.15,\n",
    "    'random_state': seed,\n",
    "    'colsample_bytree': 0.4,\n",
    "    'colsample_bylevel': 0.8,\n",
    "    'subsample': 0.4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0a6744e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTrain-logloss:0.61101\tValid-logloss:0.61170\n",
      "[1]\tTrain-logloss:0.54532\tValid-logloss:0.54648\n",
      "[2]\tTrain-logloss:0.49230\tValid-logloss:0.49379\n",
      "[3]\tTrain-logloss:0.45289\tValid-logloss:0.45496\n",
      "[4]\tTrain-logloss:0.41891\tValid-logloss:0.42154\n",
      "[5]\tTrain-logloss:0.39065\tValid-logloss:0.39390\n",
      "[6]\tTrain-logloss:0.36804\tValid-logloss:0.37190\n",
      "[7]\tTrain-logloss:0.34787\tValid-logloss:0.35234\n",
      "[8]\tTrain-logloss:0.33199\tValid-logloss:0.33686\n",
      "[9]\tTrain-logloss:0.31848\tValid-logloss:0.32382\n",
      "[10]\tTrain-logloss:0.30663\tValid-logloss:0.31268\n",
      "[11]\tTrain-logloss:0.29689\tValid-logloss:0.30332\n",
      "[12]\tTrain-logloss:0.28872\tValid-logloss:0.29556\n",
      "[13]\tTrain-logloss:0.28125\tValid-logloss:0.28887\n",
      "[14]\tTrain-logloss:0.27488\tValid-logloss:0.28292\n",
      "[15]\tTrain-logloss:0.26941\tValid-logloss:0.27777\n",
      "[16]\tTrain-logloss:0.26464\tValid-logloss:0.27354\n",
      "[17]\tTrain-logloss:0.26046\tValid-logloss:0.26983\n",
      "[18]\tTrain-logloss:0.25646\tValid-logloss:0.26602\n",
      "[19]\tTrain-logloss:0.25304\tValid-logloss:0.26317\n",
      "[20]\tTrain-logloss:0.25010\tValid-logloss:0.26064\n",
      "[21]\tTrain-logloss:0.24701\tValid-logloss:0.25832\n",
      "[22]\tTrain-logloss:0.24431\tValid-logloss:0.25625\n",
      "[23]\tTrain-logloss:0.24194\tValid-logloss:0.25430\n",
      "[24]\tTrain-logloss:0.23979\tValid-logloss:0.25254\n",
      "[25]\tTrain-logloss:0.23796\tValid-logloss:0.25132\n",
      "[26]\tTrain-logloss:0.23601\tValid-logloss:0.25011\n",
      "[27]\tTrain-logloss:0.23427\tValid-logloss:0.24895\n",
      "[28]\tTrain-logloss:0.23254\tValid-logloss:0.24773\n",
      "[29]\tTrain-logloss:0.23097\tValid-logloss:0.24674\n",
      "[30]\tTrain-logloss:0.22977\tValid-logloss:0.24589\n",
      "[31]\tTrain-logloss:0.22853\tValid-logloss:0.24519\n",
      "[32]\tTrain-logloss:0.22726\tValid-logloss:0.24449\n",
      "[33]\tTrain-logloss:0.22609\tValid-logloss:0.24396\n",
      "[34]\tTrain-logloss:0.22493\tValid-logloss:0.24344\n",
      "[35]\tTrain-logloss:0.22404\tValid-logloss:0.24299\n",
      "[36]\tTrain-logloss:0.22307\tValid-logloss:0.24256\n",
      "[37]\tTrain-logloss:0.22208\tValid-logloss:0.24184\n",
      "[38]\tTrain-logloss:0.22113\tValid-logloss:0.24135\n",
      "[39]\tTrain-logloss:0.22029\tValid-logloss:0.24112\n",
      "[40]\tTrain-logloss:0.21940\tValid-logloss:0.24084\n",
      "[41]\tTrain-logloss:0.21845\tValid-logloss:0.24029\n",
      "[42]\tTrain-logloss:0.21761\tValid-logloss:0.24001\n",
      "[43]\tTrain-logloss:0.21690\tValid-logloss:0.23996\n",
      "[44]\tTrain-logloss:0.21599\tValid-logloss:0.23966\n",
      "[45]\tTrain-logloss:0.21506\tValid-logloss:0.23926\n",
      "[46]\tTrain-logloss:0.21442\tValid-logloss:0.23921\n",
      "[47]\tTrain-logloss:0.21378\tValid-logloss:0.23902\n",
      "[48]\tTrain-logloss:0.21301\tValid-logloss:0.23877\n",
      "[49]\tTrain-logloss:0.21224\tValid-logloss:0.23845\n",
      "[50]\tTrain-logloss:0.21149\tValid-logloss:0.23836\n",
      "[51]\tTrain-logloss:0.21076\tValid-logloss:0.23815\n",
      "[52]\tTrain-logloss:0.21027\tValid-logloss:0.23800\n",
      "[53]\tTrain-logloss:0.20954\tValid-logloss:0.23783\n",
      "[54]\tTrain-logloss:0.20882\tValid-logloss:0.23782\n",
      "[55]\tTrain-logloss:0.20830\tValid-logloss:0.23780\n",
      "[56]\tTrain-logloss:0.20769\tValid-logloss:0.23766\n",
      "[57]\tTrain-logloss:0.20688\tValid-logloss:0.23759\n",
      "[58]\tTrain-logloss:0.20635\tValid-logloss:0.23745\n",
      "[59]\tTrain-logloss:0.20560\tValid-logloss:0.23720\n",
      "[60]\tTrain-logloss:0.20522\tValid-logloss:0.23708\n",
      "[61]\tTrain-logloss:0.20460\tValid-logloss:0.23702\n",
      "[62]\tTrain-logloss:0.20405\tValid-logloss:0.23698\n",
      "[63]\tTrain-logloss:0.20360\tValid-logloss:0.23687\n",
      "[64]\tTrain-logloss:0.20304\tValid-logloss:0.23682\n",
      "[65]\tTrain-logloss:0.20239\tValid-logloss:0.23668\n",
      "[66]\tTrain-logloss:0.20204\tValid-logloss:0.23674\n",
      "[67]\tTrain-logloss:0.20129\tValid-logloss:0.23663\n",
      "[68]\tTrain-logloss:0.20083\tValid-logloss:0.23656\n",
      "[69]\tTrain-logloss:0.20022\tValid-logloss:0.23659\n",
      "[70]\tTrain-logloss:0.19962\tValid-logloss:0.23655\n",
      "[71]\tTrain-logloss:0.19916\tValid-logloss:0.23659\n",
      "[72]\tTrain-logloss:0.19865\tValid-logloss:0.23662\n",
      "[73]\tTrain-logloss:0.19812\tValid-logloss:0.23664\n"
     ]
    }
   ],
   "source": [
    "model3 = xgb.train(params3, train_matrix, steps, early_stopping_rounds=3,\n",
    "                   evals=[(train_matrix, 'Train'), (valid_matrix, 'Valid')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2a740b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7635269140504961"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result3 = mf.model_evaluator(model3, valid_matrix, valid['target'])\n",
    "result3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a123115",
   "metadata": {},
   "source": [
    "Sampling only a small portion of my features (40%) when growing a new tree had a strong negative effect on my results. I think it will be appropriate to keep this value at 0.8 for future tuning steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2208599d",
   "metadata": {},
   "source": [
    "In the next training pass, I will try a max depth of 3 to curb overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b16aacc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTrain-logloss:0.61498\tValid-logloss:0.61561\n",
      "[1]\tTrain-logloss:0.55141\tValid-logloss:0.55250\n",
      "[2]\tTrain-logloss:0.49932\tValid-logloss:0.50049\n",
      "[3]\tTrain-logloss:0.46147\tValid-logloss:0.46269\n",
      "[4]\tTrain-logloss:0.42831\tValid-logloss:0.42995\n",
      "[5]\tTrain-logloss:0.40051\tValid-logloss:0.40238\n",
      "[6]\tTrain-logloss:0.37864\tValid-logloss:0.38066\n",
      "[7]\tTrain-logloss:0.36005\tValid-logloss:0.36218\n",
      "[8]\tTrain-logloss:0.34420\tValid-logloss:0.34658\n",
      "[9]\tTrain-logloss:0.33148\tValid-logloss:0.33407\n",
      "[10]\tTrain-logloss:0.32063\tValid-logloss:0.32369\n",
      "[11]\tTrain-logloss:0.31069\tValid-logloss:0.31411\n",
      "[12]\tTrain-logloss:0.30244\tValid-logloss:0.30619\n",
      "[13]\tTrain-logloss:0.29504\tValid-logloss:0.29918\n",
      "[14]\tTrain-logloss:0.28869\tValid-logloss:0.29314\n",
      "[15]\tTrain-logloss:0.28298\tValid-logloss:0.28777\n",
      "[16]\tTrain-logloss:0.27815\tValid-logloss:0.28329\n",
      "[17]\tTrain-logloss:0.27382\tValid-logloss:0.27928\n",
      "[18]\tTrain-logloss:0.26943\tValid-logloss:0.27511\n",
      "[19]\tTrain-logloss:0.26574\tValid-logloss:0.27164\n",
      "[20]\tTrain-logloss:0.26272\tValid-logloss:0.26900\n",
      "[21]\tTrain-logloss:0.26009\tValid-logloss:0.26658\n",
      "[22]\tTrain-logloss:0.25763\tValid-logloss:0.26432\n",
      "[23]\tTrain-logloss:0.25543\tValid-logloss:0.26231\n",
      "[24]\tTrain-logloss:0.25305\tValid-logloss:0.26024\n",
      "[25]\tTrain-logloss:0.25102\tValid-logloss:0.25857\n",
      "[26]\tTrain-logloss:0.24927\tValid-logloss:0.25699\n",
      "[27]\tTrain-logloss:0.24737\tValid-logloss:0.25536\n",
      "[28]\tTrain-logloss:0.24566\tValid-logloss:0.25402\n",
      "[29]\tTrain-logloss:0.24399\tValid-logloss:0.25273\n",
      "[30]\tTrain-logloss:0.24251\tValid-logloss:0.25159\n",
      "[31]\tTrain-logloss:0.24120\tValid-logloss:0.25060\n",
      "[32]\tTrain-logloss:0.24000\tValid-logloss:0.24961\n",
      "[33]\tTrain-logloss:0.23901\tValid-logloss:0.24896\n",
      "[34]\tTrain-logloss:0.23799\tValid-logloss:0.24816\n",
      "[35]\tTrain-logloss:0.23705\tValid-logloss:0.24749\n",
      "[36]\tTrain-logloss:0.23620\tValid-logloss:0.24684\n",
      "[37]\tTrain-logloss:0.23541\tValid-logloss:0.24619\n",
      "[38]\tTrain-logloss:0.23459\tValid-logloss:0.24562\n",
      "[39]\tTrain-logloss:0.23376\tValid-logloss:0.24515\n",
      "[40]\tTrain-logloss:0.23297\tValid-logloss:0.24473\n",
      "[41]\tTrain-logloss:0.23209\tValid-logloss:0.24416\n",
      "[42]\tTrain-logloss:0.23130\tValid-logloss:0.24363\n",
      "[43]\tTrain-logloss:0.23062\tValid-logloss:0.24312\n",
      "[44]\tTrain-logloss:0.22986\tValid-logloss:0.24266\n",
      "[45]\tTrain-logloss:0.22912\tValid-logloss:0.24221\n",
      "[46]\tTrain-logloss:0.22855\tValid-logloss:0.24190\n",
      "[47]\tTrain-logloss:0.22791\tValid-logloss:0.24158\n",
      "[48]\tTrain-logloss:0.22732\tValid-logloss:0.24125\n",
      "[49]\tTrain-logloss:0.22679\tValid-logloss:0.24092\n",
      "[50]\tTrain-logloss:0.22616\tValid-logloss:0.24059\n",
      "[51]\tTrain-logloss:0.22557\tValid-logloss:0.24039\n",
      "[52]\tTrain-logloss:0.22507\tValid-logloss:0.24009\n",
      "[53]\tTrain-logloss:0.22454\tValid-logloss:0.23975\n",
      "[54]\tTrain-logloss:0.22399\tValid-logloss:0.23951\n",
      "[55]\tTrain-logloss:0.22346\tValid-logloss:0.23925\n",
      "[56]\tTrain-logloss:0.22293\tValid-logloss:0.23898\n",
      "[57]\tTrain-logloss:0.22242\tValid-logloss:0.23878\n",
      "[58]\tTrain-logloss:0.22190\tValid-logloss:0.23851\n",
      "[59]\tTrain-logloss:0.22142\tValid-logloss:0.23830\n",
      "[60]\tTrain-logloss:0.22104\tValid-logloss:0.23810\n",
      "[61]\tTrain-logloss:0.22064\tValid-logloss:0.23797\n",
      "[62]\tTrain-logloss:0.22014\tValid-logloss:0.23771\n",
      "[63]\tTrain-logloss:0.21975\tValid-logloss:0.23752\n",
      "[64]\tTrain-logloss:0.21922\tValid-logloss:0.23726\n",
      "[65]\tTrain-logloss:0.21873\tValid-logloss:0.23703\n",
      "[66]\tTrain-logloss:0.21827\tValid-logloss:0.23686\n",
      "[67]\tTrain-logloss:0.21782\tValid-logloss:0.23667\n",
      "[68]\tTrain-logloss:0.21741\tValid-logloss:0.23657\n",
      "[69]\tTrain-logloss:0.21693\tValid-logloss:0.23635\n",
      "[70]\tTrain-logloss:0.21662\tValid-logloss:0.23629\n",
      "[71]\tTrain-logloss:0.21619\tValid-logloss:0.23616\n",
      "[72]\tTrain-logloss:0.21575\tValid-logloss:0.23602\n",
      "[73]\tTrain-logloss:0.21532\tValid-logloss:0.23585\n",
      "[74]\tTrain-logloss:0.21487\tValid-logloss:0.23571\n",
      "[75]\tTrain-logloss:0.21433\tValid-logloss:0.23539\n",
      "[76]\tTrain-logloss:0.21395\tValid-logloss:0.23532\n",
      "[77]\tTrain-logloss:0.21361\tValid-logloss:0.23518\n",
      "[78]\tTrain-logloss:0.21320\tValid-logloss:0.23498\n",
      "[79]\tTrain-logloss:0.21284\tValid-logloss:0.23485\n",
      "[80]\tTrain-logloss:0.21243\tValid-logloss:0.23472\n",
      "[81]\tTrain-logloss:0.21208\tValid-logloss:0.23452\n",
      "[82]\tTrain-logloss:0.21170\tValid-logloss:0.23436\n",
      "[83]\tTrain-logloss:0.21126\tValid-logloss:0.23428\n",
      "[84]\tTrain-logloss:0.21085\tValid-logloss:0.23422\n",
      "[85]\tTrain-logloss:0.21047\tValid-logloss:0.23413\n",
      "[86]\tTrain-logloss:0.21014\tValid-logloss:0.23401\n",
      "[87]\tTrain-logloss:0.20980\tValid-logloss:0.23387\n",
      "[88]\tTrain-logloss:0.20944\tValid-logloss:0.23377\n",
      "[89]\tTrain-logloss:0.20911\tValid-logloss:0.23373\n",
      "[90]\tTrain-logloss:0.20895\tValid-logloss:0.23368\n",
      "[91]\tTrain-logloss:0.20862\tValid-logloss:0.23365\n",
      "[92]\tTrain-logloss:0.20824\tValid-logloss:0.23352\n",
      "[93]\tTrain-logloss:0.20794\tValid-logloss:0.23350\n",
      "[94]\tTrain-logloss:0.20755\tValid-logloss:0.23344\n",
      "[95]\tTrain-logloss:0.20717\tValid-logloss:0.23338\n",
      "[96]\tTrain-logloss:0.20683\tValid-logloss:0.23331\n",
      "[97]\tTrain-logloss:0.20644\tValid-logloss:0.23322\n",
      "[98]\tTrain-logloss:0.20619\tValid-logloss:0.23323\n",
      "[99]\tTrain-logloss:0.20594\tValid-logloss:0.23304\n",
      "[100]\tTrain-logloss:0.20560\tValid-logloss:0.23295\n",
      "[101]\tTrain-logloss:0.20531\tValid-logloss:0.23284\n",
      "[102]\tTrain-logloss:0.20499\tValid-logloss:0.23272\n",
      "[103]\tTrain-logloss:0.20465\tValid-logloss:0.23263\n",
      "[104]\tTrain-logloss:0.20437\tValid-logloss:0.23260\n",
      "[105]\tTrain-logloss:0.20404\tValid-logloss:0.23261\n",
      "[106]\tTrain-logloss:0.20376\tValid-logloss:0.23256\n",
      "[107]\tTrain-logloss:0.20351\tValid-logloss:0.23249\n",
      "[108]\tTrain-logloss:0.20316\tValid-logloss:0.23244\n",
      "[109]\tTrain-logloss:0.20279\tValid-logloss:0.23236\n",
      "[110]\tTrain-logloss:0.20252\tValid-logloss:0.23237\n",
      "[111]\tTrain-logloss:0.20226\tValid-logloss:0.23231\n",
      "[112]\tTrain-logloss:0.20198\tValid-logloss:0.23228\n",
      "[113]\tTrain-logloss:0.20176\tValid-logloss:0.23230\n",
      "[114]\tTrain-logloss:0.20146\tValid-logloss:0.23224\n",
      "[115]\tTrain-logloss:0.20122\tValid-logloss:0.23224\n",
      "[116]\tTrain-logloss:0.20079\tValid-logloss:0.23215\n",
      "[117]\tTrain-logloss:0.20049\tValid-logloss:0.23212\n",
      "[118]\tTrain-logloss:0.20017\tValid-logloss:0.23209\n",
      "[119]\tTrain-logloss:0.19990\tValid-logloss:0.23210\n",
      "[120]\tTrain-logloss:0.19953\tValid-logloss:0.23202\n",
      "[121]\tTrain-logloss:0.19927\tValid-logloss:0.23198\n",
      "[122]\tTrain-logloss:0.19896\tValid-logloss:0.23190\n",
      "[123]\tTrain-logloss:0.19867\tValid-logloss:0.23190\n",
      "[124]\tTrain-logloss:0.19838\tValid-logloss:0.23188\n",
      "[125]\tTrain-logloss:0.19809\tValid-logloss:0.23193\n",
      "[126]\tTrain-logloss:0.19780\tValid-logloss:0.23192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7720946805913114"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params4 = {\n",
    "    'verbosity': 1,\n",
    "    'max_depth': 3,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eta': 0.15,\n",
    "    'random_state': seed,\n",
    "    'colsample_bytree': 0.4,\n",
    "    'colsample_bylevel': 0.8,\n",
    "    'subsample': 0.8\n",
    "}\n",
    "\n",
    "model4 = xgb.train(params4, train_matrix, steps, early_stopping_rounds=3,\n",
    "                   evals=[(train_matrix, 'Train'), (valid_matrix, 'Valid')])\n",
    "\n",
    "result4 = mf.model_evaluator(model4, valid_matrix, valid['target'])\n",
    "result4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbcf0d3",
   "metadata": {},
   "source": [
    "Reducing my max depth results in a slight increase in model performance on the validation set. I will keep a max depth of 3 moving forward with the other features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25ef2a8",
   "metadata": {},
   "source": [
    "I will experiment with gamma next. Gamma is set to 0 by default, and it is defined as the minimum loss reduction required to add more splits to a tree. A larger value of gamma is associated with a more conservative algorithm. Increasing gamma may be a way to curb the complexity of my trees and reduce overfitting. Gamma accepts values from 0 to infinity, however I will limit myself from 0 to 10 initially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82c2df13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTrain-logloss:0.61498\tValid-logloss:0.61561\n",
      "[1]\tTrain-logloss:0.55141\tValid-logloss:0.55250\n",
      "[2]\tTrain-logloss:0.49932\tValid-logloss:0.50049\n",
      "[3]\tTrain-logloss:0.46147\tValid-logloss:0.46269\n",
      "[4]\tTrain-logloss:0.42831\tValid-logloss:0.42995\n",
      "[5]\tTrain-logloss:0.40051\tValid-logloss:0.40238\n",
      "[6]\tTrain-logloss:0.37864\tValid-logloss:0.38066\n",
      "[7]\tTrain-logloss:0.36005\tValid-logloss:0.36218\n",
      "[8]\tTrain-logloss:0.34420\tValid-logloss:0.34658\n",
      "[9]\tTrain-logloss:0.33148\tValid-logloss:0.33407\n",
      "[10]\tTrain-logloss:0.32063\tValid-logloss:0.32369\n",
      "[11]\tTrain-logloss:0.31069\tValid-logloss:0.31411\n",
      "[12]\tTrain-logloss:0.30244\tValid-logloss:0.30619\n",
      "[13]\tTrain-logloss:0.29504\tValid-logloss:0.29918\n",
      "[14]\tTrain-logloss:0.28869\tValid-logloss:0.29314\n",
      "[15]\tTrain-logloss:0.28298\tValid-logloss:0.28777\n",
      "[16]\tTrain-logloss:0.27815\tValid-logloss:0.28329\n",
      "[17]\tTrain-logloss:0.27382\tValid-logloss:0.27928\n",
      "[18]\tTrain-logloss:0.26943\tValid-logloss:0.27511\n",
      "[19]\tTrain-logloss:0.26574\tValid-logloss:0.27164\n",
      "[20]\tTrain-logloss:0.26272\tValid-logloss:0.26900\n",
      "[21]\tTrain-logloss:0.26009\tValid-logloss:0.26658\n",
      "[22]\tTrain-logloss:0.25763\tValid-logloss:0.26432\n",
      "[23]\tTrain-logloss:0.25543\tValid-logloss:0.26231\n",
      "[24]\tTrain-logloss:0.25305\tValid-logloss:0.26024\n",
      "[25]\tTrain-logloss:0.25102\tValid-logloss:0.25857\n",
      "[26]\tTrain-logloss:0.24927\tValid-logloss:0.25699\n",
      "[27]\tTrain-logloss:0.24737\tValid-logloss:0.25536\n",
      "[28]\tTrain-logloss:0.24566\tValid-logloss:0.25402\n",
      "[29]\tTrain-logloss:0.24399\tValid-logloss:0.25273\n",
      "[30]\tTrain-logloss:0.24251\tValid-logloss:0.25159\n",
      "[31]\tTrain-logloss:0.24120\tValid-logloss:0.25060\n",
      "[32]\tTrain-logloss:0.24000\tValid-logloss:0.24961\n",
      "[33]\tTrain-logloss:0.23901\tValid-logloss:0.24896\n",
      "[34]\tTrain-logloss:0.23799\tValid-logloss:0.24816\n",
      "[35]\tTrain-logloss:0.23705\tValid-logloss:0.24749\n",
      "[36]\tTrain-logloss:0.23620\tValid-logloss:0.24684\n",
      "[37]\tTrain-logloss:0.23541\tValid-logloss:0.24619\n",
      "[38]\tTrain-logloss:0.23459\tValid-logloss:0.24562\n",
      "[39]\tTrain-logloss:0.23376\tValid-logloss:0.24515\n",
      "[40]\tTrain-logloss:0.23297\tValid-logloss:0.24473\n",
      "[41]\tTrain-logloss:0.23209\tValid-logloss:0.24416\n",
      "[42]\tTrain-logloss:0.23130\tValid-logloss:0.24363\n",
      "[43]\tTrain-logloss:0.23062\tValid-logloss:0.24312\n",
      "[44]\tTrain-logloss:0.22986\tValid-logloss:0.24266\n",
      "[45]\tTrain-logloss:0.22912\tValid-logloss:0.24221\n",
      "[46]\tTrain-logloss:0.22855\tValid-logloss:0.24190\n",
      "[47]\tTrain-logloss:0.22791\tValid-logloss:0.24158\n",
      "[48]\tTrain-logloss:0.22732\tValid-logloss:0.24125\n",
      "[49]\tTrain-logloss:0.22679\tValid-logloss:0.24092\n",
      "[50]\tTrain-logloss:0.22616\tValid-logloss:0.24059\n",
      "[51]\tTrain-logloss:0.22557\tValid-logloss:0.24039\n",
      "[52]\tTrain-logloss:0.22507\tValid-logloss:0.24009\n",
      "[53]\tTrain-logloss:0.22454\tValid-logloss:0.23975\n",
      "[54]\tTrain-logloss:0.22399\tValid-logloss:0.23951\n",
      "[55]\tTrain-logloss:0.22346\tValid-logloss:0.23925\n",
      "[56]\tTrain-logloss:0.22293\tValid-logloss:0.23898\n",
      "[57]\tTrain-logloss:0.22242\tValid-logloss:0.23878\n",
      "[58]\tTrain-logloss:0.22190\tValid-logloss:0.23851\n",
      "[59]\tTrain-logloss:0.22142\tValid-logloss:0.23830\n",
      "[60]\tTrain-logloss:0.22104\tValid-logloss:0.23810\n",
      "[61]\tTrain-logloss:0.22064\tValid-logloss:0.23797\n",
      "[62]\tTrain-logloss:0.22014\tValid-logloss:0.23771\n",
      "[63]\tTrain-logloss:0.21975\tValid-logloss:0.23752\n",
      "[64]\tTrain-logloss:0.21922\tValid-logloss:0.23726\n",
      "[65]\tTrain-logloss:0.21873\tValid-logloss:0.23703\n",
      "[66]\tTrain-logloss:0.21827\tValid-logloss:0.23686\n",
      "[67]\tTrain-logloss:0.21782\tValid-logloss:0.23667\n",
      "[68]\tTrain-logloss:0.21741\tValid-logloss:0.23657\n",
      "[69]\tTrain-logloss:0.21693\tValid-logloss:0.23635\n",
      "[70]\tTrain-logloss:0.21662\tValid-logloss:0.23629\n",
      "[71]\tTrain-logloss:0.21619\tValid-logloss:0.23616\n",
      "[72]\tTrain-logloss:0.21575\tValid-logloss:0.23602\n",
      "[73]\tTrain-logloss:0.21532\tValid-logloss:0.23585\n",
      "[74]\tTrain-logloss:0.21487\tValid-logloss:0.23571\n",
      "[75]\tTrain-logloss:0.21433\tValid-logloss:0.23539\n",
      "[76]\tTrain-logloss:0.21395\tValid-logloss:0.23532\n",
      "[77]\tTrain-logloss:0.21361\tValid-logloss:0.23518\n",
      "[78]\tTrain-logloss:0.21320\tValid-logloss:0.23498\n",
      "[79]\tTrain-logloss:0.21284\tValid-logloss:0.23485\n",
      "[80]\tTrain-logloss:0.21243\tValid-logloss:0.23472\n",
      "[81]\tTrain-logloss:0.21208\tValid-logloss:0.23452\n",
      "[82]\tTrain-logloss:0.21170\tValid-logloss:0.23436\n",
      "[83]\tTrain-logloss:0.21126\tValid-logloss:0.23428\n",
      "[84]\tTrain-logloss:0.21085\tValid-logloss:0.23422\n",
      "[85]\tTrain-logloss:0.21047\tValid-logloss:0.23413\n",
      "[86]\tTrain-logloss:0.21014\tValid-logloss:0.23401\n",
      "[87]\tTrain-logloss:0.20980\tValid-logloss:0.23387\n",
      "[88]\tTrain-logloss:0.20944\tValid-logloss:0.23377\n",
      "[89]\tTrain-logloss:0.20911\tValid-logloss:0.23373\n",
      "[90]\tTrain-logloss:0.20895\tValid-logloss:0.23368\n",
      "[91]\tTrain-logloss:0.20862\tValid-logloss:0.23365\n",
      "[92]\tTrain-logloss:0.20824\tValid-logloss:0.23352\n",
      "[93]\tTrain-logloss:0.20794\tValid-logloss:0.23350\n",
      "[94]\tTrain-logloss:0.20756\tValid-logloss:0.23344\n",
      "[95]\tTrain-logloss:0.20717\tValid-logloss:0.23338\n",
      "[96]\tTrain-logloss:0.20683\tValid-logloss:0.23331\n",
      "[97]\tTrain-logloss:0.20645\tValid-logloss:0.23322\n",
      "[98]\tTrain-logloss:0.20619\tValid-logloss:0.23323\n",
      "[99]\tTrain-logloss:0.20594\tValid-logloss:0.23304\n",
      "[100]\tTrain-logloss:0.20560\tValid-logloss:0.23295\n",
      "[101]\tTrain-logloss:0.20531\tValid-logloss:0.23284\n",
      "[102]\tTrain-logloss:0.20499\tValid-logloss:0.23272\n",
      "[103]\tTrain-logloss:0.20465\tValid-logloss:0.23263\n",
      "[104]\tTrain-logloss:0.20437\tValid-logloss:0.23260\n",
      "[105]\tTrain-logloss:0.20404\tValid-logloss:0.23261\n",
      "[106]\tTrain-logloss:0.20376\tValid-logloss:0.23256\n",
      "[107]\tTrain-logloss:0.20352\tValid-logloss:0.23249\n",
      "[108]\tTrain-logloss:0.20316\tValid-logloss:0.23244\n",
      "[109]\tTrain-logloss:0.20279\tValid-logloss:0.23236\n",
      "[110]\tTrain-logloss:0.20253\tValid-logloss:0.23237\n",
      "[111]\tTrain-logloss:0.20226\tValid-logloss:0.23231\n",
      "[112]\tTrain-logloss:0.20198\tValid-logloss:0.23228\n",
      "[113]\tTrain-logloss:0.20176\tValid-logloss:0.23230\n",
      "[114]\tTrain-logloss:0.20146\tValid-logloss:0.23224\n",
      "[115]\tTrain-logloss:0.20122\tValid-logloss:0.23224\n",
      "[116]\tTrain-logloss:0.20079\tValid-logloss:0.23215\n",
      "[117]\tTrain-logloss:0.20049\tValid-logloss:0.23212\n",
      "[118]\tTrain-logloss:0.20017\tValid-logloss:0.23209\n",
      "[119]\tTrain-logloss:0.19990\tValid-logloss:0.23210\n",
      "[120]\tTrain-logloss:0.19953\tValid-logloss:0.23202\n",
      "[121]\tTrain-logloss:0.19927\tValid-logloss:0.23198\n",
      "[122]\tTrain-logloss:0.19896\tValid-logloss:0.23190\n",
      "[123]\tTrain-logloss:0.19867\tValid-logloss:0.23190\n",
      "[124]\tTrain-logloss:0.19838\tValid-logloss:0.23188\n",
      "[125]\tTrain-logloss:0.19809\tValid-logloss:0.23193\n",
      "[126]\tTrain-logloss:0.19780\tValid-logloss:0.23192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7720945900961371"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params5 = {\n",
    "    'verbosity': 1,\n",
    "    'max_depth': 3,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eta': 0.15,\n",
    "    'random_state': seed,\n",
    "    'colsample_bytree': 0.4,\n",
    "    'colsample_bylevel': 0.8,\n",
    "    'subsample': 0.8,\n",
    "    'gamma': 2\n",
    "}\n",
    "\n",
    "model5 = xgb.train(params5, train_matrix, steps, early_stopping_rounds=3,\n",
    "                   evals=[(train_matrix, 'Train'), (valid_matrix, 'Valid')])\n",
    "\n",
    "result5 = mf.model_evaluator(model5, valid_matrix, valid['target'])\n",
    "result5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb677e0",
   "metadata": {},
   "source": [
    "I see very little difference between my results with and without gamma (all other hyperparameters being the same). I will try an extreme value of gamma to see if I can see a difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11bc0d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTrain-logloss:0.61498\tValid-logloss:0.61561\n",
      "[1]\tTrain-logloss:0.55141\tValid-logloss:0.55250\n",
      "[2]\tTrain-logloss:0.49932\tValid-logloss:0.50049\n",
      "[3]\tTrain-logloss:0.46147\tValid-logloss:0.46269\n",
      "[4]\tTrain-logloss:0.42831\tValid-logloss:0.42995\n",
      "[5]\tTrain-logloss:0.40092\tValid-logloss:0.40280\n",
      "[6]\tTrain-logloss:0.37901\tValid-logloss:0.38104\n",
      "[7]\tTrain-logloss:0.36069\tValid-logloss:0.36275\n",
      "[8]\tTrain-logloss:0.34528\tValid-logloss:0.34747\n",
      "[9]\tTrain-logloss:0.33279\tValid-logloss:0.33513\n",
      "[10]\tTrain-logloss:0.32209\tValid-logloss:0.32480\n",
      "[11]\tTrain-logloss:0.31211\tValid-logloss:0.31510\n",
      "[12]\tTrain-logloss:0.30435\tValid-logloss:0.30757\n",
      "[13]\tTrain-logloss:0.29734\tValid-logloss:0.30085\n",
      "[14]\tTrain-logloss:0.29126\tValid-logloss:0.29497\n",
      "[15]\tTrain-logloss:0.28571\tValid-logloss:0.28974\n",
      "[16]\tTrain-logloss:0.28111\tValid-logloss:0.28545\n",
      "[17]\tTrain-logloss:0.27732\tValid-logloss:0.28184\n",
      "[18]\tTrain-logloss:0.27332\tValid-logloss:0.27799\n",
      "[19]\tTrain-logloss:0.27007\tValid-logloss:0.27474\n",
      "[20]\tTrain-logloss:0.26700\tValid-logloss:0.27191\n",
      "[21]\tTrain-logloss:0.26432\tValid-logloss:0.26952\n",
      "[22]\tTrain-logloss:0.26221\tValid-logloss:0.26750\n",
      "[23]\tTrain-logloss:0.26027\tValid-logloss:0.26569\n",
      "[24]\tTrain-logloss:0.25862\tValid-logloss:0.26399\n",
      "[25]\tTrain-logloss:0.25675\tValid-logloss:0.26230\n",
      "[26]\tTrain-logloss:0.25522\tValid-logloss:0.26081\n",
      "[27]\tTrain-logloss:0.25364\tValid-logloss:0.25928\n",
      "[28]\tTrain-logloss:0.25206\tValid-logloss:0.25791\n",
      "[29]\tTrain-logloss:0.25117\tValid-logloss:0.25703\n",
      "[30]\tTrain-logloss:0.25039\tValid-logloss:0.25633\n",
      "[31]\tTrain-logloss:0.24916\tValid-logloss:0.25523\n",
      "[32]\tTrain-logloss:0.24833\tValid-logloss:0.25449\n",
      "[33]\tTrain-logloss:0.24715\tValid-logloss:0.25344\n",
      "[34]\tTrain-logloss:0.24612\tValid-logloss:0.25252\n",
      "[35]\tTrain-logloss:0.24578\tValid-logloss:0.25221\n",
      "[36]\tTrain-logloss:0.24513\tValid-logloss:0.25168\n",
      "[37]\tTrain-logloss:0.24452\tValid-logloss:0.25115\n",
      "[38]\tTrain-logloss:0.24360\tValid-logloss:0.25039\n",
      "[39]\tTrain-logloss:0.24330\tValid-logloss:0.25011\n",
      "[40]\tTrain-logloss:0.24303\tValid-logloss:0.24987\n",
      "[41]\tTrain-logloss:0.24275\tValid-logloss:0.24965\n",
      "[42]\tTrain-logloss:0.24247\tValid-logloss:0.24940\n",
      "[43]\tTrain-logloss:0.24247\tValid-logloss:0.24939\n",
      "[44]\tTrain-logloss:0.24247\tValid-logloss:0.24939\n",
      "[45]\tTrain-logloss:0.24220\tValid-logloss:0.24921\n",
      "[46]\tTrain-logloss:0.24192\tValid-logloss:0.24893\n",
      "[47]\tTrain-logloss:0.24192\tValid-logloss:0.24893\n",
      "[48]\tTrain-logloss:0.24192\tValid-logloss:0.24893\n",
      "[49]\tTrain-logloss:0.24192\tValid-logloss:0.24893\n",
      "[50]\tTrain-logloss:0.24141\tValid-logloss:0.24853\n",
      "[51]\tTrain-logloss:0.24141\tValid-logloss:0.24853\n",
      "[52]\tTrain-logloss:0.24141\tValid-logloss:0.24852\n",
      "[53]\tTrain-logloss:0.24141\tValid-logloss:0.24853\n",
      "[54]\tTrain-logloss:0.24141\tValid-logloss:0.24853\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7524617273872352"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params6 = {\n",
    "    'verbosity': 1,\n",
    "    'max_depth': 3,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eta': 0.15,\n",
    "    'random_state': seed,\n",
    "    'colsample_bytree': 0.4,\n",
    "    'colsample_bylevel': 0.8,\n",
    "    'subsample': 0.8,\n",
    "    'gamma': 64\n",
    "}\n",
    "\n",
    "model6 = xgb.train(params6, train_matrix, steps, early_stopping_rounds=3,\n",
    "                   evals=[(train_matrix, 'Train'), (valid_matrix, 'Valid')])\n",
    "\n",
    "result6 = mf.model_evaluator(model6, valid_matrix, valid['target'])\n",
    "result6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e42fdde",
   "metadata": {},
   "source": [
    "I got my answer. A gamma this large negatively impacts my score by a great margin. I think I will abandon the gamma hyperparameter for the time being. A small value had no effect, and a large value had a negative effect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b369c71",
   "metadata": {},
   "source": [
    "Next I will try cutting the learning rate ('eta') in half. A lower learning rate should increase the amount of training steps required to reach convergence and decrease the amount of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e01a42bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTrain-logloss:0.65249\tValid-logloss:0.65280\n",
      "[1]\tTrain-logloss:0.61491\tValid-logloss:0.61545\n",
      "[2]\tTrain-logloss:0.58044\tValid-logloss:0.58098\n",
      "[3]\tTrain-logloss:0.55261\tValid-logloss:0.55325\n",
      "[4]\tTrain-logloss:0.52609\tValid-logloss:0.52691\n",
      "[5]\tTrain-logloss:0.50175\tValid-logloss:0.50266\n",
      "[6]\tTrain-logloss:0.48111\tValid-logloss:0.48210\n",
      "[7]\tTrain-logloss:0.46171\tValid-logloss:0.46278\n",
      "[8]\tTrain-logloss:0.44418\tValid-logloss:0.44535\n",
      "[9]\tTrain-logloss:0.42871\tValid-logloss:0.43000\n",
      "[10]\tTrain-logloss:0.41480\tValid-logloss:0.41639\n",
      "[11]\tTrain-logloss:0.40239\tValid-logloss:0.40407\n",
      "[12]\tTrain-logloss:0.39088\tValid-logloss:0.39280\n",
      "[13]\tTrain-logloss:0.38003\tValid-logloss:0.38218\n",
      "[14]\tTrain-logloss:0.36999\tValid-logloss:0.37227\n",
      "[15]\tTrain-logloss:0.36130\tValid-logloss:0.36366\n",
      "[16]\tTrain-logloss:0.35315\tValid-logloss:0.35560\n",
      "[17]\tTrain-logloss:0.34564\tValid-logloss:0.34819\n",
      "[18]\tTrain-logloss:0.33870\tValid-logloss:0.34145\n",
      "[19]\tTrain-logloss:0.33225\tValid-logloss:0.33516\n",
      "[20]\tTrain-logloss:0.32639\tValid-logloss:0.32949\n",
      "[21]\tTrain-logloss:0.32081\tValid-logloss:0.32404\n",
      "[22]\tTrain-logloss:0.31572\tValid-logloss:0.31909\n",
      "[23]\tTrain-logloss:0.31085\tValid-logloss:0.31440\n",
      "[24]\tTrain-logloss:0.30636\tValid-logloss:0.31006\n",
      "[25]\tTrain-logloss:0.30230\tValid-logloss:0.30611\n",
      "[26]\tTrain-logloss:0.29844\tValid-logloss:0.30233\n",
      "[27]\tTrain-logloss:0.29466\tValid-logloss:0.29875\n",
      "[28]\tTrain-logloss:0.29136\tValid-logloss:0.29560\n",
      "[29]\tTrain-logloss:0.28825\tValid-logloss:0.29269\n",
      "[30]\tTrain-logloss:0.28534\tValid-logloss:0.28991\n",
      "[31]\tTrain-logloss:0.28256\tValid-logloss:0.28728\n",
      "[32]\tTrain-logloss:0.28005\tValid-logloss:0.28491\n",
      "[33]\tTrain-logloss:0.27757\tValid-logloss:0.28268\n",
      "[34]\tTrain-logloss:0.27525\tValid-logloss:0.28041\n",
      "[35]\tTrain-logloss:0.27303\tValid-logloss:0.27840\n",
      "[36]\tTrain-logloss:0.27096\tValid-logloss:0.27645\n",
      "[37]\tTrain-logloss:0.26915\tValid-logloss:0.27470\n",
      "[38]\tTrain-logloss:0.26736\tValid-logloss:0.27298\n",
      "[39]\tTrain-logloss:0.26558\tValid-logloss:0.27138\n",
      "[40]\tTrain-logloss:0.26401\tValid-logloss:0.26986\n",
      "[41]\tTrain-logloss:0.26246\tValid-logloss:0.26842\n",
      "[42]\tTrain-logloss:0.26109\tValid-logloss:0.26714\n",
      "[43]\tTrain-logloss:0.25964\tValid-logloss:0.26581\n",
      "[44]\tTrain-logloss:0.25833\tValid-logloss:0.26464\n",
      "[45]\tTrain-logloss:0.25711\tValid-logloss:0.26353\n",
      "[46]\tTrain-logloss:0.25596\tValid-logloss:0.26257\n",
      "[47]\tTrain-logloss:0.25471\tValid-logloss:0.26151\n",
      "[48]\tTrain-logloss:0.25346\tValid-logloss:0.26048\n",
      "[49]\tTrain-logloss:0.25247\tValid-logloss:0.25962\n",
      "[50]\tTrain-logloss:0.25152\tValid-logloss:0.25877\n",
      "[51]\tTrain-logloss:0.25060\tValid-logloss:0.25796\n",
      "[52]\tTrain-logloss:0.24953\tValid-logloss:0.25703\n",
      "[53]\tTrain-logloss:0.24858\tValid-logloss:0.25626\n",
      "[54]\tTrain-logloss:0.24764\tValid-logloss:0.25547\n",
      "[55]\tTrain-logloss:0.24684\tValid-logloss:0.25483\n",
      "[56]\tTrain-logloss:0.24603\tValid-logloss:0.25414\n",
      "[57]\tTrain-logloss:0.24533\tValid-logloss:0.25357\n",
      "[58]\tTrain-logloss:0.24446\tValid-logloss:0.25284\n",
      "[59]\tTrain-logloss:0.24374\tValid-logloss:0.25222\n",
      "[60]\tTrain-logloss:0.24299\tValid-logloss:0.25158\n",
      "[61]\tTrain-logloss:0.24219\tValid-logloss:0.25092\n",
      "[62]\tTrain-logloss:0.24162\tValid-logloss:0.25048\n",
      "[63]\tTrain-logloss:0.24099\tValid-logloss:0.24992\n",
      "[64]\tTrain-logloss:0.24027\tValid-logloss:0.24931\n",
      "[65]\tTrain-logloss:0.23961\tValid-logloss:0.24883\n",
      "[66]\tTrain-logloss:0.23905\tValid-logloss:0.24837\n",
      "[67]\tTrain-logloss:0.23846\tValid-logloss:0.24790\n",
      "[68]\tTrain-logloss:0.23792\tValid-logloss:0.24751\n",
      "[69]\tTrain-logloss:0.23738\tValid-logloss:0.24708\n",
      "[70]\tTrain-logloss:0.23682\tValid-logloss:0.24663\n",
      "[71]\tTrain-logloss:0.23627\tValid-logloss:0.24614\n",
      "[72]\tTrain-logloss:0.23572\tValid-logloss:0.24574\n",
      "[73]\tTrain-logloss:0.23522\tValid-logloss:0.24540\n",
      "[74]\tTrain-logloss:0.23474\tValid-logloss:0.24509\n",
      "[75]\tTrain-logloss:0.23425\tValid-logloss:0.24473\n",
      "[76]\tTrain-logloss:0.23379\tValid-logloss:0.24441\n",
      "[77]\tTrain-logloss:0.23336\tValid-logloss:0.24411\n",
      "[78]\tTrain-logloss:0.23295\tValid-logloss:0.24384\n",
      "[79]\tTrain-logloss:0.23249\tValid-logloss:0.24350\n",
      "[80]\tTrain-logloss:0.23205\tValid-logloss:0.24323\n",
      "[81]\tTrain-logloss:0.23164\tValid-logloss:0.24293\n",
      "[82]\tTrain-logloss:0.23124\tValid-logloss:0.24269\n",
      "[83]\tTrain-logloss:0.23090\tValid-logloss:0.24249\n",
      "[84]\tTrain-logloss:0.23057\tValid-logloss:0.24229\n",
      "[85]\tTrain-logloss:0.23015\tValid-logloss:0.24199\n",
      "[86]\tTrain-logloss:0.22973\tValid-logloss:0.24170\n",
      "[87]\tTrain-logloss:0.22936\tValid-logloss:0.24146\n",
      "[88]\tTrain-logloss:0.22899\tValid-logloss:0.24121\n",
      "[89]\tTrain-logloss:0.22866\tValid-logloss:0.24102\n",
      "[90]\tTrain-logloss:0.22827\tValid-logloss:0.24079\n",
      "[91]\tTrain-logloss:0.22797\tValid-logloss:0.24060\n",
      "[92]\tTrain-logloss:0.22765\tValid-logloss:0.24041\n",
      "[93]\tTrain-logloss:0.22730\tValid-logloss:0.24022\n",
      "[94]\tTrain-logloss:0.22705\tValid-logloss:0.24003\n",
      "[95]\tTrain-logloss:0.22678\tValid-logloss:0.23989\n",
      "[96]\tTrain-logloss:0.22650\tValid-logloss:0.23975\n",
      "[97]\tTrain-logloss:0.22620\tValid-logloss:0.23961\n",
      "[98]\tTrain-logloss:0.22586\tValid-logloss:0.23942\n",
      "[99]\tTrain-logloss:0.22557\tValid-logloss:0.23922\n",
      "[100]\tTrain-logloss:0.22526\tValid-logloss:0.23906\n",
      "[101]\tTrain-logloss:0.22502\tValid-logloss:0.23892\n",
      "[102]\tTrain-logloss:0.22474\tValid-logloss:0.23881\n",
      "[103]\tTrain-logloss:0.22440\tValid-logloss:0.23865\n",
      "[104]\tTrain-logloss:0.22414\tValid-logloss:0.23850\n",
      "[105]\tTrain-logloss:0.22384\tValid-logloss:0.23840\n",
      "[106]\tTrain-logloss:0.22354\tValid-logloss:0.23823\n",
      "[107]\tTrain-logloss:0.22325\tValid-logloss:0.23808\n",
      "[108]\tTrain-logloss:0.22295\tValid-logloss:0.23794\n",
      "[109]\tTrain-logloss:0.22266\tValid-logloss:0.23780\n",
      "[110]\tTrain-logloss:0.22236\tValid-logloss:0.23763\n",
      "[111]\tTrain-logloss:0.22212\tValid-logloss:0.23751\n",
      "[112]\tTrain-logloss:0.22185\tValid-logloss:0.23736\n",
      "[113]\tTrain-logloss:0.22163\tValid-logloss:0.23722\n",
      "[114]\tTrain-logloss:0.22134\tValid-logloss:0.23705\n",
      "[115]\tTrain-logloss:0.22115\tValid-logloss:0.23693\n",
      "[116]\tTrain-logloss:0.22085\tValid-logloss:0.23679\n",
      "[117]\tTrain-logloss:0.22061\tValid-logloss:0.23666\n",
      "[118]\tTrain-logloss:0.22035\tValid-logloss:0.23652\n",
      "[119]\tTrain-logloss:0.22010\tValid-logloss:0.23643\n",
      "[120]\tTrain-logloss:0.21988\tValid-logloss:0.23634\n",
      "[121]\tTrain-logloss:0.21964\tValid-logloss:0.23620\n",
      "[122]\tTrain-logloss:0.21937\tValid-logloss:0.23608\n",
      "[123]\tTrain-logloss:0.21909\tValid-logloss:0.23593\n",
      "[124]\tTrain-logloss:0.21879\tValid-logloss:0.23579\n",
      "[125]\tTrain-logloss:0.21852\tValid-logloss:0.23562\n",
      "[126]\tTrain-logloss:0.21829\tValid-logloss:0.23549\n",
      "[127]\tTrain-logloss:0.21805\tValid-logloss:0.23540\n",
      "[128]\tTrain-logloss:0.21781\tValid-logloss:0.23531\n",
      "[129]\tTrain-logloss:0.21757\tValid-logloss:0.23521\n",
      "[130]\tTrain-logloss:0.21733\tValid-logloss:0.23514\n",
      "[131]\tTrain-logloss:0.21708\tValid-logloss:0.23506\n",
      "[132]\tTrain-logloss:0.21685\tValid-logloss:0.23497\n",
      "[133]\tTrain-logloss:0.21666\tValid-logloss:0.23490\n",
      "[134]\tTrain-logloss:0.21643\tValid-logloss:0.23481\n",
      "[135]\tTrain-logloss:0.21620\tValid-logloss:0.23474\n",
      "[136]\tTrain-logloss:0.21600\tValid-logloss:0.23464\n",
      "[137]\tTrain-logloss:0.21582\tValid-logloss:0.23460\n",
      "[138]\tTrain-logloss:0.21562\tValid-logloss:0.23451\n",
      "[139]\tTrain-logloss:0.21538\tValid-logloss:0.23439\n",
      "[140]\tTrain-logloss:0.21515\tValid-logloss:0.23432\n",
      "[141]\tTrain-logloss:0.21492\tValid-logloss:0.23423\n",
      "[142]\tTrain-logloss:0.21469\tValid-logloss:0.23414\n",
      "[143]\tTrain-logloss:0.21442\tValid-logloss:0.23401\n",
      "[144]\tTrain-logloss:0.21427\tValid-logloss:0.23395\n",
      "[145]\tTrain-logloss:0.21405\tValid-logloss:0.23382\n",
      "[146]\tTrain-logloss:0.21386\tValid-logloss:0.23373\n",
      "[147]\tTrain-logloss:0.21359\tValid-logloss:0.23361\n",
      "[148]\tTrain-logloss:0.21341\tValid-logloss:0.23357\n",
      "[149]\tTrain-logloss:0.21323\tValid-logloss:0.23349\n",
      "[150]\tTrain-logloss:0.21299\tValid-logloss:0.23337\n",
      "[151]\tTrain-logloss:0.21278\tValid-logloss:0.23328\n",
      "[152]\tTrain-logloss:0.21258\tValid-logloss:0.23325\n",
      "[153]\tTrain-logloss:0.21236\tValid-logloss:0.23318\n",
      "[154]\tTrain-logloss:0.21219\tValid-logloss:0.23314\n",
      "[155]\tTrain-logloss:0.21198\tValid-logloss:0.23306\n",
      "[156]\tTrain-logloss:0.21180\tValid-logloss:0.23302\n",
      "[157]\tTrain-logloss:0.21160\tValid-logloss:0.23293\n",
      "[158]\tTrain-logloss:0.21141\tValid-logloss:0.23285\n",
      "[159]\tTrain-logloss:0.21123\tValid-logloss:0.23277\n",
      "[160]\tTrain-logloss:0.21106\tValid-logloss:0.23276\n",
      "[161]\tTrain-logloss:0.21089\tValid-logloss:0.23273\n",
      "[162]\tTrain-logloss:0.21072\tValid-logloss:0.23267\n",
      "[163]\tTrain-logloss:0.21051\tValid-logloss:0.23263\n",
      "[164]\tTrain-logloss:0.21031\tValid-logloss:0.23257\n",
      "[165]\tTrain-logloss:0.21012\tValid-logloss:0.23249\n",
      "[166]\tTrain-logloss:0.20992\tValid-logloss:0.23244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[167]\tTrain-logloss:0.20974\tValid-logloss:0.23241\n",
      "[168]\tTrain-logloss:0.20955\tValid-logloss:0.23236\n",
      "[169]\tTrain-logloss:0.20939\tValid-logloss:0.23228\n",
      "[170]\tTrain-logloss:0.20922\tValid-logloss:0.23224\n",
      "[171]\tTrain-logloss:0.20905\tValid-logloss:0.23221\n",
      "[172]\tTrain-logloss:0.20886\tValid-logloss:0.23217\n",
      "[173]\tTrain-logloss:0.20866\tValid-logloss:0.23209\n",
      "[174]\tTrain-logloss:0.20848\tValid-logloss:0.23202\n",
      "[175]\tTrain-logloss:0.20830\tValid-logloss:0.23198\n",
      "[176]\tTrain-logloss:0.20812\tValid-logloss:0.23194\n",
      "[177]\tTrain-logloss:0.20792\tValid-logloss:0.23190\n",
      "[178]\tTrain-logloss:0.20771\tValid-logloss:0.23178\n",
      "[179]\tTrain-logloss:0.20759\tValid-logloss:0.23176\n",
      "[180]\tTrain-logloss:0.20740\tValid-logloss:0.23173\n",
      "[181]\tTrain-logloss:0.20719\tValid-logloss:0.23164\n",
      "[182]\tTrain-logloss:0.20700\tValid-logloss:0.23164\n",
      "[183]\tTrain-logloss:0.20687\tValid-logloss:0.23158\n",
      "[184]\tTrain-logloss:0.20670\tValid-logloss:0.23153\n",
      "[185]\tTrain-logloss:0.20654\tValid-logloss:0.23149\n",
      "[186]\tTrain-logloss:0.20638\tValid-logloss:0.23146\n",
      "[187]\tTrain-logloss:0.20621\tValid-logloss:0.23143\n",
      "[188]\tTrain-logloss:0.20604\tValid-logloss:0.23143\n",
      "[189]\tTrain-logloss:0.20585\tValid-logloss:0.23133\n",
      "[190]\tTrain-logloss:0.20566\tValid-logloss:0.23127\n",
      "[191]\tTrain-logloss:0.20553\tValid-logloss:0.23126\n",
      "[192]\tTrain-logloss:0.20534\tValid-logloss:0.23123\n",
      "[193]\tTrain-logloss:0.20518\tValid-logloss:0.23118\n",
      "[194]\tTrain-logloss:0.20506\tValid-logloss:0.23112\n",
      "[195]\tTrain-logloss:0.20486\tValid-logloss:0.23107\n",
      "[196]\tTrain-logloss:0.20472\tValid-logloss:0.23106\n",
      "[197]\tTrain-logloss:0.20457\tValid-logloss:0.23104\n",
      "[198]\tTrain-logloss:0.20446\tValid-logloss:0.23101\n",
      "[199]\tTrain-logloss:0.20426\tValid-logloss:0.23094\n",
      "[200]\tTrain-logloss:0.20407\tValid-logloss:0.23088\n",
      "[201]\tTrain-logloss:0.20388\tValid-logloss:0.23082\n",
      "[202]\tTrain-logloss:0.20371\tValid-logloss:0.23079\n",
      "[203]\tTrain-logloss:0.20358\tValid-logloss:0.23077\n",
      "[204]\tTrain-logloss:0.20339\tValid-logloss:0.23075\n",
      "[205]\tTrain-logloss:0.20321\tValid-logloss:0.23070\n",
      "[206]\tTrain-logloss:0.20305\tValid-logloss:0.23067\n",
      "[207]\tTrain-logloss:0.20290\tValid-logloss:0.23066\n",
      "[208]\tTrain-logloss:0.20280\tValid-logloss:0.23062\n",
      "[209]\tTrain-logloss:0.20267\tValid-logloss:0.23060\n",
      "[210]\tTrain-logloss:0.20259\tValid-logloss:0.23059\n",
      "[211]\tTrain-logloss:0.20244\tValid-logloss:0.23059\n",
      "[212]\tTrain-logloss:0.20227\tValid-logloss:0.23060\n",
      "[213]\tTrain-logloss:0.20214\tValid-logloss:0.23056\n",
      "[214]\tTrain-logloss:0.20202\tValid-logloss:0.23050\n",
      "[215]\tTrain-logloss:0.20189\tValid-logloss:0.23047\n",
      "[216]\tTrain-logloss:0.20173\tValid-logloss:0.23041\n",
      "[217]\tTrain-logloss:0.20156\tValid-logloss:0.23039\n",
      "[218]\tTrain-logloss:0.20140\tValid-logloss:0.23035\n",
      "[219]\tTrain-logloss:0.20124\tValid-logloss:0.23035\n",
      "[220]\tTrain-logloss:0.20107\tValid-logloss:0.23035\n",
      "[221]\tTrain-logloss:0.20094\tValid-logloss:0.23033\n",
      "[222]\tTrain-logloss:0.20082\tValid-logloss:0.23030\n",
      "[223]\tTrain-logloss:0.20068\tValid-logloss:0.23026\n",
      "[224]\tTrain-logloss:0.20054\tValid-logloss:0.23024\n",
      "[225]\tTrain-logloss:0.20040\tValid-logloss:0.23022\n",
      "[226]\tTrain-logloss:0.20027\tValid-logloss:0.23021\n",
      "[227]\tTrain-logloss:0.20013\tValid-logloss:0.23023\n",
      "[228]\tTrain-logloss:0.19998\tValid-logloss:0.23022\n",
      "[229]\tTrain-logloss:0.19982\tValid-logloss:0.23017\n",
      "[230]\tTrain-logloss:0.19973\tValid-logloss:0.23017\n",
      "[231]\tTrain-logloss:0.19957\tValid-logloss:0.23015\n",
      "[232]\tTrain-logloss:0.19944\tValid-logloss:0.23014\n",
      "[233]\tTrain-logloss:0.19933\tValid-logloss:0.23010\n",
      "[234]\tTrain-logloss:0.19916\tValid-logloss:0.23009\n",
      "[235]\tTrain-logloss:0.19906\tValid-logloss:0.23008\n",
      "[236]\tTrain-logloss:0.19891\tValid-logloss:0.23005\n",
      "[237]\tTrain-logloss:0.19876\tValid-logloss:0.23004\n",
      "[238]\tTrain-logloss:0.19867\tValid-logloss:0.23004\n",
      "[239]\tTrain-logloss:0.19851\tValid-logloss:0.23001\n",
      "[240]\tTrain-logloss:0.19832\tValid-logloss:0.22995\n",
      "[241]\tTrain-logloss:0.19818\tValid-logloss:0.22993\n",
      "[242]\tTrain-logloss:0.19807\tValid-logloss:0.22993\n",
      "[243]\tTrain-logloss:0.19793\tValid-logloss:0.22989\n",
      "[244]\tTrain-logloss:0.19781\tValid-logloss:0.22987\n",
      "[245]\tTrain-logloss:0.19768\tValid-logloss:0.22986\n",
      "[246]\tTrain-logloss:0.19753\tValid-logloss:0.22984\n",
      "[247]\tTrain-logloss:0.19740\tValid-logloss:0.22981\n",
      "[248]\tTrain-logloss:0.19728\tValid-logloss:0.22979\n",
      "[249]\tTrain-logloss:0.19714\tValid-logloss:0.22980\n",
      "[250]\tTrain-logloss:0.19696\tValid-logloss:0.22977\n",
      "[251]\tTrain-logloss:0.19683\tValid-logloss:0.22977\n",
      "[252]\tTrain-logloss:0.19670\tValid-logloss:0.22977\n",
      "[253]\tTrain-logloss:0.19655\tValid-logloss:0.22975\n",
      "[254]\tTrain-logloss:0.19640\tValid-logloss:0.22973\n",
      "[255]\tTrain-logloss:0.19631\tValid-logloss:0.22972\n",
      "[256]\tTrain-logloss:0.19613\tValid-logloss:0.22968\n",
      "[257]\tTrain-logloss:0.19598\tValid-logloss:0.22965\n",
      "[258]\tTrain-logloss:0.19584\tValid-logloss:0.22964\n",
      "[259]\tTrain-logloss:0.19566\tValid-logloss:0.22962\n",
      "[260]\tTrain-logloss:0.19553\tValid-logloss:0.22964\n",
      "[261]\tTrain-logloss:0.19543\tValid-logloss:0.22963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7742527529940828"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params7 = {\n",
    "    'verbosity': 1,\n",
    "    'max_depth': 3,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eta': 0.075,\n",
    "    'random_state': seed,\n",
    "    'colsample_bytree': 0.4,\n",
    "    'colsample_bylevel': 0.8,\n",
    "    'subsample': 0.8,\n",
    "}\n",
    "\n",
    "model7 = xgb.train(params7, train_matrix, steps, early_stopping_rounds=3,\n",
    "                   evals=[(train_matrix, 'Train'), (valid_matrix, 'Valid')])\n",
    "\n",
    "result7 = mf.model_evaluator(model7, valid_matrix, valid['target'])\n",
    "result7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3ddf5d",
   "metadata": {},
   "source": [
    "Decreasing the learning rate had a small positive impact on the score. It may not be worth using the slower learning rate because it took over twice the time to arrive at the same amex score. Since it's technically the best model I've built in this notebook and I have time on my hands, I'll use this smaller value for learning rate moving forward."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7da6a5",
   "metadata": {},
   "source": [
    "Next I will investigate the effect of min_child_weight on my results. The hyperparameter sets the cutoff at which any values lower will stop the partitioning process. A larger value is associated with a more conservative algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5342fcc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTrain-logloss:0.65249\tValid-logloss:0.65280\n",
      "[1]\tTrain-logloss:0.61491\tValid-logloss:0.61545\n",
      "[2]\tTrain-logloss:0.58044\tValid-logloss:0.58098\n",
      "[3]\tTrain-logloss:0.55261\tValid-logloss:0.55325\n",
      "[4]\tTrain-logloss:0.52609\tValid-logloss:0.52691\n",
      "[5]\tTrain-logloss:0.50175\tValid-logloss:0.50266\n",
      "[6]\tTrain-logloss:0.48111\tValid-logloss:0.48210\n",
      "[7]\tTrain-logloss:0.46171\tValid-logloss:0.46278\n",
      "[8]\tTrain-logloss:0.44418\tValid-logloss:0.44535\n",
      "[9]\tTrain-logloss:0.42871\tValid-logloss:0.43000\n",
      "[10]\tTrain-logloss:0.41480\tValid-logloss:0.41639\n",
      "[11]\tTrain-logloss:0.40239\tValid-logloss:0.40407\n",
      "[12]\tTrain-logloss:0.39088\tValid-logloss:0.39280\n",
      "[13]\tTrain-logloss:0.38003\tValid-logloss:0.38218\n",
      "[14]\tTrain-logloss:0.36999\tValid-logloss:0.37227\n",
      "[15]\tTrain-logloss:0.36130\tValid-logloss:0.36366\n",
      "[16]\tTrain-logloss:0.35315\tValid-logloss:0.35560\n",
      "[17]\tTrain-logloss:0.34564\tValid-logloss:0.34819\n",
      "[18]\tTrain-logloss:0.33870\tValid-logloss:0.34145\n",
      "[19]\tTrain-logloss:0.33225\tValid-logloss:0.33516\n",
      "[20]\tTrain-logloss:0.32639\tValid-logloss:0.32949\n",
      "[21]\tTrain-logloss:0.32081\tValid-logloss:0.32404\n",
      "[22]\tTrain-logloss:0.31572\tValid-logloss:0.31909\n",
      "[23]\tTrain-logloss:0.31085\tValid-logloss:0.31440\n",
      "[24]\tTrain-logloss:0.30636\tValid-logloss:0.31006\n",
      "[25]\tTrain-logloss:0.30230\tValid-logloss:0.30611\n",
      "[26]\tTrain-logloss:0.29844\tValid-logloss:0.30233\n",
      "[27]\tTrain-logloss:0.29466\tValid-logloss:0.29875\n",
      "[28]\tTrain-logloss:0.29136\tValid-logloss:0.29560\n",
      "[29]\tTrain-logloss:0.28825\tValid-logloss:0.29269\n",
      "[30]\tTrain-logloss:0.28534\tValid-logloss:0.28991\n",
      "[31]\tTrain-logloss:0.28256\tValid-logloss:0.28728\n",
      "[32]\tTrain-logloss:0.28005\tValid-logloss:0.28491\n",
      "[33]\tTrain-logloss:0.27757\tValid-logloss:0.28268\n",
      "[34]\tTrain-logloss:0.27525\tValid-logloss:0.28041\n",
      "[35]\tTrain-logloss:0.27303\tValid-logloss:0.27840\n",
      "[36]\tTrain-logloss:0.27096\tValid-logloss:0.27645\n",
      "[37]\tTrain-logloss:0.26915\tValid-logloss:0.27470\n",
      "[38]\tTrain-logloss:0.26736\tValid-logloss:0.27298\n",
      "[39]\tTrain-logloss:0.26558\tValid-logloss:0.27138\n",
      "[40]\tTrain-logloss:0.26400\tValid-logloss:0.26985\n",
      "[41]\tTrain-logloss:0.26246\tValid-logloss:0.26842\n",
      "[42]\tTrain-logloss:0.26109\tValid-logloss:0.26714\n",
      "[43]\tTrain-logloss:0.25963\tValid-logloss:0.26581\n",
      "[44]\tTrain-logloss:0.25832\tValid-logloss:0.26464\n",
      "[45]\tTrain-logloss:0.25711\tValid-logloss:0.26354\n",
      "[46]\tTrain-logloss:0.25596\tValid-logloss:0.26258\n",
      "[47]\tTrain-logloss:0.25471\tValid-logloss:0.26152\n",
      "[48]\tTrain-logloss:0.25346\tValid-logloss:0.26048\n",
      "[49]\tTrain-logloss:0.25247\tValid-logloss:0.25963\n",
      "[50]\tTrain-logloss:0.25151\tValid-logloss:0.25878\n",
      "[51]\tTrain-logloss:0.25060\tValid-logloss:0.25797\n",
      "[52]\tTrain-logloss:0.24953\tValid-logloss:0.25703\n",
      "[53]\tTrain-logloss:0.24857\tValid-logloss:0.25626\n",
      "[54]\tTrain-logloss:0.24764\tValid-logloss:0.25547\n",
      "[55]\tTrain-logloss:0.24684\tValid-logloss:0.25483\n",
      "[56]\tTrain-logloss:0.24603\tValid-logloss:0.25414\n",
      "[57]\tTrain-logloss:0.24532\tValid-logloss:0.25357\n",
      "[58]\tTrain-logloss:0.24446\tValid-logloss:0.25284\n",
      "[59]\tTrain-logloss:0.24374\tValid-logloss:0.25222\n",
      "[60]\tTrain-logloss:0.24299\tValid-logloss:0.25158\n",
      "[61]\tTrain-logloss:0.24219\tValid-logloss:0.25092\n",
      "[62]\tTrain-logloss:0.24162\tValid-logloss:0.25049\n",
      "[63]\tTrain-logloss:0.24100\tValid-logloss:0.24992\n",
      "[64]\tTrain-logloss:0.24029\tValid-logloss:0.24931\n",
      "[65]\tTrain-logloss:0.23963\tValid-logloss:0.24883\n",
      "[66]\tTrain-logloss:0.23907\tValid-logloss:0.24837\n",
      "[67]\tTrain-logloss:0.23848\tValid-logloss:0.24790\n",
      "[68]\tTrain-logloss:0.23794\tValid-logloss:0.24751\n",
      "[69]\tTrain-logloss:0.23739\tValid-logloss:0.24708\n",
      "[70]\tTrain-logloss:0.23683\tValid-logloss:0.24663\n",
      "[71]\tTrain-logloss:0.23629\tValid-logloss:0.24615\n",
      "[72]\tTrain-logloss:0.23574\tValid-logloss:0.24574\n",
      "[73]\tTrain-logloss:0.23524\tValid-logloss:0.24540\n",
      "[74]\tTrain-logloss:0.23476\tValid-logloss:0.24510\n",
      "[75]\tTrain-logloss:0.23427\tValid-logloss:0.24473\n",
      "[76]\tTrain-logloss:0.23380\tValid-logloss:0.24441\n",
      "[77]\tTrain-logloss:0.23339\tValid-logloss:0.24412\n",
      "[78]\tTrain-logloss:0.23298\tValid-logloss:0.24385\n",
      "[79]\tTrain-logloss:0.23252\tValid-logloss:0.24351\n",
      "[80]\tTrain-logloss:0.23208\tValid-logloss:0.24324\n",
      "[81]\tTrain-logloss:0.23167\tValid-logloss:0.24294\n",
      "[82]\tTrain-logloss:0.23127\tValid-logloss:0.24269\n",
      "[83]\tTrain-logloss:0.23093\tValid-logloss:0.24250\n",
      "[84]\tTrain-logloss:0.23060\tValid-logloss:0.24229\n",
      "[85]\tTrain-logloss:0.23019\tValid-logloss:0.24200\n",
      "[86]\tTrain-logloss:0.22977\tValid-logloss:0.24171\n",
      "[87]\tTrain-logloss:0.22941\tValid-logloss:0.24147\n",
      "[88]\tTrain-logloss:0.22904\tValid-logloss:0.24122\n",
      "[89]\tTrain-logloss:0.22870\tValid-logloss:0.24103\n",
      "[90]\tTrain-logloss:0.22832\tValid-logloss:0.24080\n",
      "[91]\tTrain-logloss:0.22799\tValid-logloss:0.24061\n",
      "[92]\tTrain-logloss:0.22768\tValid-logloss:0.24041\n",
      "[93]\tTrain-logloss:0.22733\tValid-logloss:0.24022\n",
      "[94]\tTrain-logloss:0.22709\tValid-logloss:0.24003\n",
      "[95]\tTrain-logloss:0.22682\tValid-logloss:0.23990\n",
      "[96]\tTrain-logloss:0.22656\tValid-logloss:0.23976\n",
      "[97]\tTrain-logloss:0.22626\tValid-logloss:0.23962\n",
      "[98]\tTrain-logloss:0.22592\tValid-logloss:0.23943\n",
      "[99]\tTrain-logloss:0.22563\tValid-logloss:0.23924\n",
      "[100]\tTrain-logloss:0.22533\tValid-logloss:0.23908\n",
      "[101]\tTrain-logloss:0.22510\tValid-logloss:0.23891\n",
      "[102]\tTrain-logloss:0.22483\tValid-logloss:0.23880\n",
      "[103]\tTrain-logloss:0.22449\tValid-logloss:0.23864\n",
      "[104]\tTrain-logloss:0.22423\tValid-logloss:0.23847\n",
      "[105]\tTrain-logloss:0.22394\tValid-logloss:0.23836\n",
      "[106]\tTrain-logloss:0.22364\tValid-logloss:0.23819\n",
      "[107]\tTrain-logloss:0.22335\tValid-logloss:0.23804\n",
      "[108]\tTrain-logloss:0.22306\tValid-logloss:0.23792\n",
      "[109]\tTrain-logloss:0.22277\tValid-logloss:0.23778\n",
      "[110]\tTrain-logloss:0.22250\tValid-logloss:0.23765\n",
      "[111]\tTrain-logloss:0.22225\tValid-logloss:0.23750\n",
      "[112]\tTrain-logloss:0.22196\tValid-logloss:0.23735\n",
      "[113]\tTrain-logloss:0.22174\tValid-logloss:0.23721\n",
      "[114]\tTrain-logloss:0.22146\tValid-logloss:0.23705\n",
      "[115]\tTrain-logloss:0.22128\tValid-logloss:0.23693\n",
      "[116]\tTrain-logloss:0.22099\tValid-logloss:0.23678\n",
      "[117]\tTrain-logloss:0.22075\tValid-logloss:0.23665\n",
      "[118]\tTrain-logloss:0.22049\tValid-logloss:0.23649\n",
      "[119]\tTrain-logloss:0.22024\tValid-logloss:0.23640\n",
      "[120]\tTrain-logloss:0.21995\tValid-logloss:0.23625\n",
      "[121]\tTrain-logloss:0.21970\tValid-logloss:0.23616\n",
      "[122]\tTrain-logloss:0.21943\tValid-logloss:0.23603\n",
      "[123]\tTrain-logloss:0.21915\tValid-logloss:0.23588\n",
      "[124]\tTrain-logloss:0.21894\tValid-logloss:0.23579\n",
      "[125]\tTrain-logloss:0.21867\tValid-logloss:0.23564\n",
      "[126]\tTrain-logloss:0.21846\tValid-logloss:0.23551\n",
      "[127]\tTrain-logloss:0.21822\tValid-logloss:0.23542\n",
      "[128]\tTrain-logloss:0.21799\tValid-logloss:0.23533\n",
      "[129]\tTrain-logloss:0.21775\tValid-logloss:0.23523\n",
      "[130]\tTrain-logloss:0.21749\tValid-logloss:0.23513\n",
      "[131]\tTrain-logloss:0.21725\tValid-logloss:0.23500\n",
      "[132]\tTrain-logloss:0.21702\tValid-logloss:0.23491\n",
      "[133]\tTrain-logloss:0.21679\tValid-logloss:0.23481\n",
      "[134]\tTrain-logloss:0.21657\tValid-logloss:0.23476\n",
      "[135]\tTrain-logloss:0.21637\tValid-logloss:0.23468\n",
      "[136]\tTrain-logloss:0.21613\tValid-logloss:0.23452\n",
      "[137]\tTrain-logloss:0.21592\tValid-logloss:0.23444\n",
      "[138]\tTrain-logloss:0.21570\tValid-logloss:0.23438\n",
      "[139]\tTrain-logloss:0.21545\tValid-logloss:0.23426\n",
      "[140]\tTrain-logloss:0.21522\tValid-logloss:0.23420\n",
      "[141]\tTrain-logloss:0.21505\tValid-logloss:0.23412\n",
      "[142]\tTrain-logloss:0.21482\tValid-logloss:0.23403\n",
      "[143]\tTrain-logloss:0.21464\tValid-logloss:0.23394\n",
      "[144]\tTrain-logloss:0.21450\tValid-logloss:0.23388\n",
      "[145]\tTrain-logloss:0.21434\tValid-logloss:0.23377\n",
      "[146]\tTrain-logloss:0.21412\tValid-logloss:0.23367\n",
      "[147]\tTrain-logloss:0.21386\tValid-logloss:0.23356\n",
      "[148]\tTrain-logloss:0.21370\tValid-logloss:0.23351\n",
      "[149]\tTrain-logloss:0.21352\tValid-logloss:0.23343\n",
      "[150]\tTrain-logloss:0.21327\tValid-logloss:0.23330\n",
      "[151]\tTrain-logloss:0.21309\tValid-logloss:0.23326\n",
      "[152]\tTrain-logloss:0.21294\tValid-logloss:0.23322\n",
      "[153]\tTrain-logloss:0.21275\tValid-logloss:0.23315\n",
      "[154]\tTrain-logloss:0.21259\tValid-logloss:0.23311\n",
      "[155]\tTrain-logloss:0.21238\tValid-logloss:0.23305\n",
      "[156]\tTrain-logloss:0.21219\tValid-logloss:0.23299\n",
      "[157]\tTrain-logloss:0.21203\tValid-logloss:0.23293\n",
      "[158]\tTrain-logloss:0.21183\tValid-logloss:0.23288\n",
      "[159]\tTrain-logloss:0.21164\tValid-logloss:0.23279\n",
      "[160]\tTrain-logloss:0.21143\tValid-logloss:0.23272\n",
      "[161]\tTrain-logloss:0.21126\tValid-logloss:0.23269\n",
      "[162]\tTrain-logloss:0.21107\tValid-logloss:0.23263\n",
      "[163]\tTrain-logloss:0.21086\tValid-logloss:0.23259\n",
      "[164]\tTrain-logloss:0.21068\tValid-logloss:0.23255\n",
      "[165]\tTrain-logloss:0.21050\tValid-logloss:0.23247\n",
      "[166]\tTrain-logloss:0.21030\tValid-logloss:0.23242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[167]\tTrain-logloss:0.21009\tValid-logloss:0.23238\n",
      "[168]\tTrain-logloss:0.20991\tValid-logloss:0.23233\n",
      "[169]\tTrain-logloss:0.20976\tValid-logloss:0.23229\n",
      "[170]\tTrain-logloss:0.20961\tValid-logloss:0.23227\n",
      "[171]\tTrain-logloss:0.20944\tValid-logloss:0.23224\n",
      "[172]\tTrain-logloss:0.20926\tValid-logloss:0.23219\n",
      "[173]\tTrain-logloss:0.20906\tValid-logloss:0.23213\n",
      "[174]\tTrain-logloss:0.20889\tValid-logloss:0.23205\n",
      "[175]\tTrain-logloss:0.20872\tValid-logloss:0.23201\n",
      "[176]\tTrain-logloss:0.20856\tValid-logloss:0.23197\n",
      "[177]\tTrain-logloss:0.20837\tValid-logloss:0.23192\n",
      "[178]\tTrain-logloss:0.20817\tValid-logloss:0.23184\n",
      "[179]\tTrain-logloss:0.20802\tValid-logloss:0.23179\n",
      "[180]\tTrain-logloss:0.20786\tValid-logloss:0.23171\n",
      "[181]\tTrain-logloss:0.20766\tValid-logloss:0.23162\n",
      "[182]\tTrain-logloss:0.20749\tValid-logloss:0.23161\n",
      "[183]\tTrain-logloss:0.20728\tValid-logloss:0.23150\n",
      "[184]\tTrain-logloss:0.20712\tValid-logloss:0.23146\n",
      "[185]\tTrain-logloss:0.20695\tValid-logloss:0.23141\n",
      "[186]\tTrain-logloss:0.20680\tValid-logloss:0.23132\n",
      "[187]\tTrain-logloss:0.20663\tValid-logloss:0.23129\n",
      "[188]\tTrain-logloss:0.20647\tValid-logloss:0.23125\n",
      "[189]\tTrain-logloss:0.20628\tValid-logloss:0.23115\n",
      "[190]\tTrain-logloss:0.20613\tValid-logloss:0.23108\n",
      "[191]\tTrain-logloss:0.20596\tValid-logloss:0.23105\n",
      "[192]\tTrain-logloss:0.20577\tValid-logloss:0.23102\n",
      "[193]\tTrain-logloss:0.20558\tValid-logloss:0.23102\n",
      "[194]\tTrain-logloss:0.20544\tValid-logloss:0.23101\n",
      "[195]\tTrain-logloss:0.20525\tValid-logloss:0.23097\n",
      "[196]\tTrain-logloss:0.20511\tValid-logloss:0.23095\n",
      "[197]\tTrain-logloss:0.20492\tValid-logloss:0.23091\n",
      "[198]\tTrain-logloss:0.20481\tValid-logloss:0.23088\n",
      "[199]\tTrain-logloss:0.20465\tValid-logloss:0.23085\n",
      "[200]\tTrain-logloss:0.20447\tValid-logloss:0.23078\n",
      "[201]\tTrain-logloss:0.20430\tValid-logloss:0.23075\n",
      "[202]\tTrain-logloss:0.20412\tValid-logloss:0.23071\n",
      "[203]\tTrain-logloss:0.20394\tValid-logloss:0.23068\n",
      "[204]\tTrain-logloss:0.20376\tValid-logloss:0.23066\n",
      "[205]\tTrain-logloss:0.20361\tValid-logloss:0.23063\n",
      "[206]\tTrain-logloss:0.20346\tValid-logloss:0.23060\n",
      "[207]\tTrain-logloss:0.20334\tValid-logloss:0.23060\n",
      "[208]\tTrain-logloss:0.20323\tValid-logloss:0.23054\n",
      "[209]\tTrain-logloss:0.20309\tValid-logloss:0.23052\n",
      "[210]\tTrain-logloss:0.20301\tValid-logloss:0.23050\n",
      "[211]\tTrain-logloss:0.20286\tValid-logloss:0.23052\n",
      "[212]\tTrain-logloss:0.20276\tValid-logloss:0.23050\n",
      "[213]\tTrain-logloss:0.20269\tValid-logloss:0.23048\n",
      "[214]\tTrain-logloss:0.20259\tValid-logloss:0.23045\n",
      "[215]\tTrain-logloss:0.20240\tValid-logloss:0.23040\n",
      "[216]\tTrain-logloss:0.20225\tValid-logloss:0.23034\n",
      "[217]\tTrain-logloss:0.20211\tValid-logloss:0.23029\n",
      "[218]\tTrain-logloss:0.20196\tValid-logloss:0.23026\n",
      "[219]\tTrain-logloss:0.20180\tValid-logloss:0.23026\n",
      "[220]\tTrain-logloss:0.20167\tValid-logloss:0.23025\n",
      "[221]\tTrain-logloss:0.20151\tValid-logloss:0.23023\n",
      "[222]\tTrain-logloss:0.20142\tValid-logloss:0.23020\n",
      "[223]\tTrain-logloss:0.20125\tValid-logloss:0.23018\n",
      "[224]\tTrain-logloss:0.20115\tValid-logloss:0.23016\n",
      "[225]\tTrain-logloss:0.20097\tValid-logloss:0.23011\n",
      "[226]\tTrain-logloss:0.20084\tValid-logloss:0.23010\n",
      "[227]\tTrain-logloss:0.20070\tValid-logloss:0.23008\n",
      "[228]\tTrain-logloss:0.20057\tValid-logloss:0.23008\n",
      "[229]\tTrain-logloss:0.20040\tValid-logloss:0.23002\n",
      "[230]\tTrain-logloss:0.20031\tValid-logloss:0.23001\n",
      "[231]\tTrain-logloss:0.20013\tValid-logloss:0.22996\n",
      "[232]\tTrain-logloss:0.20003\tValid-logloss:0.22995\n",
      "[233]\tTrain-logloss:0.19988\tValid-logloss:0.22992\n",
      "[234]\tTrain-logloss:0.19973\tValid-logloss:0.22990\n",
      "[235]\tTrain-logloss:0.19967\tValid-logloss:0.22989\n",
      "[236]\tTrain-logloss:0.19951\tValid-logloss:0.22988\n",
      "[237]\tTrain-logloss:0.19938\tValid-logloss:0.22989\n",
      "[238]\tTrain-logloss:0.19931\tValid-logloss:0.22990\n",
      "[239]\tTrain-logloss:0.19916\tValid-logloss:0.22988\n",
      "[240]\tTrain-logloss:0.19899\tValid-logloss:0.22982\n",
      "[241]\tTrain-logloss:0.19885\tValid-logloss:0.22978\n",
      "[242]\tTrain-logloss:0.19874\tValid-logloss:0.22979\n",
      "[243]\tTrain-logloss:0.19861\tValid-logloss:0.22976\n",
      "[244]\tTrain-logloss:0.19848\tValid-logloss:0.22975\n",
      "[245]\tTrain-logloss:0.19834\tValid-logloss:0.22975\n",
      "[246]\tTrain-logloss:0.19822\tValid-logloss:0.22973\n",
      "[247]\tTrain-logloss:0.19810\tValid-logloss:0.22970\n",
      "[248]\tTrain-logloss:0.19798\tValid-logloss:0.22967\n",
      "[249]\tTrain-logloss:0.19783\tValid-logloss:0.22969\n",
      "[250]\tTrain-logloss:0.19766\tValid-logloss:0.22966\n",
      "[251]\tTrain-logloss:0.19753\tValid-logloss:0.22967\n",
      "[252]\tTrain-logloss:0.19738\tValid-logloss:0.22968\n",
      "[253]\tTrain-logloss:0.19723\tValid-logloss:0.22967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7752500774789979"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params8 = {\n",
    "    'verbosity': 1,\n",
    "    'max_depth': 3,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eta': 0.075,\n",
    "    'random_state': seed,\n",
    "    'colsample_bytree': 0.4,\n",
    "    'colsample_bylevel': 0.8,\n",
    "    'subsample': 0.8,\n",
    "    'min_child_weight': 4\n",
    "}\n",
    "\n",
    "model8 = xgb.train(params8, train_matrix, steps, early_stopping_rounds=3,\n",
    "                   evals=[(train_matrix, 'Train'), (valid_matrix, 'Valid')])\n",
    "\n",
    "result8 = mf.model_evaluator(model8, valid_matrix, valid['target'])\n",
    "result8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ece087b",
   "metadata": {},
   "source": [
    "Like some experiments before, I've added a hyperparameter and my results have not been changed in any meaningful way. I will try cranking this hyperparameter up to 11 to see if it has an impact before I try altering my last hyperparameter to try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6aa9a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTrain-logloss:0.65249\tValid-logloss:0.65280\n",
      "[1]\tTrain-logloss:0.61491\tValid-logloss:0.61545\n",
      "[2]\tTrain-logloss:0.58044\tValid-logloss:0.58098\n",
      "[3]\tTrain-logloss:0.55261\tValid-logloss:0.55325\n",
      "[4]\tTrain-logloss:0.52609\tValid-logloss:0.52691\n",
      "[5]\tTrain-logloss:0.50175\tValid-logloss:0.50266\n",
      "[6]\tTrain-logloss:0.48111\tValid-logloss:0.48210\n",
      "[7]\tTrain-logloss:0.46171\tValid-logloss:0.46278\n",
      "[8]\tTrain-logloss:0.44419\tValid-logloss:0.44535\n",
      "[9]\tTrain-logloss:0.42868\tValid-logloss:0.42998\n",
      "[10]\tTrain-logloss:0.41476\tValid-logloss:0.41636\n",
      "[11]\tTrain-logloss:0.40236\tValid-logloss:0.40405\n",
      "[12]\tTrain-logloss:0.39086\tValid-logloss:0.39274\n",
      "[13]\tTrain-logloss:0.38002\tValid-logloss:0.38211\n",
      "[14]\tTrain-logloss:0.37002\tValid-logloss:0.37223\n",
      "[15]\tTrain-logloss:0.36140\tValid-logloss:0.36365\n",
      "[16]\tTrain-logloss:0.35316\tValid-logloss:0.35552\n",
      "[17]\tTrain-logloss:0.34566\tValid-logloss:0.34812\n",
      "[18]\tTrain-logloss:0.33877\tValid-logloss:0.34145\n",
      "[19]\tTrain-logloss:0.33235\tValid-logloss:0.33518\n",
      "[20]\tTrain-logloss:0.32651\tValid-logloss:0.32954\n",
      "[21]\tTrain-logloss:0.32095\tValid-logloss:0.32412\n",
      "[22]\tTrain-logloss:0.31585\tValid-logloss:0.31916\n",
      "[23]\tTrain-logloss:0.31095\tValid-logloss:0.31444\n",
      "[24]\tTrain-logloss:0.30673\tValid-logloss:0.31036\n",
      "[25]\tTrain-logloss:0.30270\tValid-logloss:0.30643\n",
      "[26]\tTrain-logloss:0.29886\tValid-logloss:0.30264\n",
      "[27]\tTrain-logloss:0.29543\tValid-logloss:0.29940\n",
      "[28]\tTrain-logloss:0.29223\tValid-logloss:0.29626\n",
      "[29]\tTrain-logloss:0.28898\tValid-logloss:0.29317\n",
      "[30]\tTrain-logloss:0.28601\tValid-logloss:0.29035\n",
      "[31]\tTrain-logloss:0.28313\tValid-logloss:0.28769\n",
      "[32]\tTrain-logloss:0.28051\tValid-logloss:0.28517\n",
      "[33]\tTrain-logloss:0.27814\tValid-logloss:0.28292\n",
      "[34]\tTrain-logloss:0.27580\tValid-logloss:0.28068\n",
      "[35]\tTrain-logloss:0.27359\tValid-logloss:0.27861\n",
      "[36]\tTrain-logloss:0.27157\tValid-logloss:0.27674\n",
      "[37]\tTrain-logloss:0.26975\tValid-logloss:0.27501\n",
      "[38]\tTrain-logloss:0.26797\tValid-logloss:0.27331\n",
      "[39]\tTrain-logloss:0.26624\tValid-logloss:0.27174\n",
      "[40]\tTrain-logloss:0.26470\tValid-logloss:0.27024\n",
      "[41]\tTrain-logloss:0.26316\tValid-logloss:0.26884\n",
      "[42]\tTrain-logloss:0.26180\tValid-logloss:0.26758\n",
      "[43]\tTrain-logloss:0.26046\tValid-logloss:0.26636\n",
      "[44]\tTrain-logloss:0.25919\tValid-logloss:0.26523\n",
      "[45]\tTrain-logloss:0.25799\tValid-logloss:0.26415\n",
      "[46]\tTrain-logloss:0.25674\tValid-logloss:0.26308\n",
      "[47]\tTrain-logloss:0.25545\tValid-logloss:0.26198\n",
      "[48]\tTrain-logloss:0.25421\tValid-logloss:0.26095\n",
      "[49]\tTrain-logloss:0.25320\tValid-logloss:0.26007\n",
      "[50]\tTrain-logloss:0.25206\tValid-logloss:0.25907\n",
      "[51]\tTrain-logloss:0.25117\tValid-logloss:0.25824\n",
      "[52]\tTrain-logloss:0.25011\tValid-logloss:0.25732\n",
      "[53]\tTrain-logloss:0.24917\tValid-logloss:0.25652\n",
      "[54]\tTrain-logloss:0.24828\tValid-logloss:0.25568\n",
      "[55]\tTrain-logloss:0.24742\tValid-logloss:0.25499\n",
      "[56]\tTrain-logloss:0.24662\tValid-logloss:0.25430\n",
      "[57]\tTrain-logloss:0.24587\tValid-logloss:0.25367\n",
      "[58]\tTrain-logloss:0.24501\tValid-logloss:0.25296\n",
      "[59]\tTrain-logloss:0.24429\tValid-logloss:0.25236\n",
      "[60]\tTrain-logloss:0.24352\tValid-logloss:0.25173\n",
      "[61]\tTrain-logloss:0.24269\tValid-logloss:0.25100\n",
      "[62]\tTrain-logloss:0.24210\tValid-logloss:0.25053\n",
      "[63]\tTrain-logloss:0.24147\tValid-logloss:0.24997\n",
      "[64]\tTrain-logloss:0.24076\tValid-logloss:0.24936\n",
      "[65]\tTrain-logloss:0.24010\tValid-logloss:0.24892\n",
      "[66]\tTrain-logloss:0.23953\tValid-logloss:0.24848\n",
      "[67]\tTrain-logloss:0.23894\tValid-logloss:0.24801\n",
      "[68]\tTrain-logloss:0.23837\tValid-logloss:0.24757\n",
      "[69]\tTrain-logloss:0.23785\tValid-logloss:0.24718\n",
      "[70]\tTrain-logloss:0.23730\tValid-logloss:0.24679\n",
      "[71]\tTrain-logloss:0.23680\tValid-logloss:0.24639\n",
      "[72]\tTrain-logloss:0.23628\tValid-logloss:0.24598\n",
      "[73]\tTrain-logloss:0.23583\tValid-logloss:0.24569\n",
      "[74]\tTrain-logloss:0.23535\tValid-logloss:0.24538\n",
      "[75]\tTrain-logloss:0.23490\tValid-logloss:0.24504\n",
      "[76]\tTrain-logloss:0.23445\tValid-logloss:0.24470\n",
      "[77]\tTrain-logloss:0.23402\tValid-logloss:0.24437\n",
      "[78]\tTrain-logloss:0.23359\tValid-logloss:0.24409\n",
      "[79]\tTrain-logloss:0.23312\tValid-logloss:0.24375\n",
      "[80]\tTrain-logloss:0.23273\tValid-logloss:0.24346\n",
      "[81]\tTrain-logloss:0.23232\tValid-logloss:0.24318\n",
      "[82]\tTrain-logloss:0.23194\tValid-logloss:0.24293\n",
      "[83]\tTrain-logloss:0.23150\tValid-logloss:0.24262\n",
      "[84]\tTrain-logloss:0.23116\tValid-logloss:0.24237\n",
      "[85]\tTrain-logloss:0.23075\tValid-logloss:0.24207\n",
      "[86]\tTrain-logloss:0.23031\tValid-logloss:0.24176\n",
      "[87]\tTrain-logloss:0.22992\tValid-logloss:0.24149\n",
      "[88]\tTrain-logloss:0.22955\tValid-logloss:0.24124\n",
      "[89]\tTrain-logloss:0.22922\tValid-logloss:0.24108\n",
      "[90]\tTrain-logloss:0.22885\tValid-logloss:0.24084\n",
      "[91]\tTrain-logloss:0.22853\tValid-logloss:0.24065\n",
      "[92]\tTrain-logloss:0.22821\tValid-logloss:0.24048\n",
      "[93]\tTrain-logloss:0.22791\tValid-logloss:0.24028\n",
      "[94]\tTrain-logloss:0.22754\tValid-logloss:0.24005\n",
      "[95]\tTrain-logloss:0.22731\tValid-logloss:0.23990\n",
      "[96]\tTrain-logloss:0.22702\tValid-logloss:0.23973\n",
      "[97]\tTrain-logloss:0.22673\tValid-logloss:0.23959\n",
      "[98]\tTrain-logloss:0.22643\tValid-logloss:0.23942\n",
      "[99]\tTrain-logloss:0.22618\tValid-logloss:0.23923\n",
      "[100]\tTrain-logloss:0.22588\tValid-logloss:0.23907\n",
      "[101]\tTrain-logloss:0.22566\tValid-logloss:0.23892\n",
      "[102]\tTrain-logloss:0.22538\tValid-logloss:0.23880\n",
      "[103]\tTrain-logloss:0.22506\tValid-logloss:0.23864\n",
      "[104]\tTrain-logloss:0.22475\tValid-logloss:0.23849\n",
      "[105]\tTrain-logloss:0.22445\tValid-logloss:0.23833\n",
      "[106]\tTrain-logloss:0.22416\tValid-logloss:0.23817\n",
      "[107]\tTrain-logloss:0.22389\tValid-logloss:0.23801\n",
      "[108]\tTrain-logloss:0.22364\tValid-logloss:0.23789\n",
      "[109]\tTrain-logloss:0.22336\tValid-logloss:0.23774\n",
      "[110]\tTrain-logloss:0.22310\tValid-logloss:0.23759\n",
      "[111]\tTrain-logloss:0.22286\tValid-logloss:0.23748\n",
      "[112]\tTrain-logloss:0.22258\tValid-logloss:0.23734\n",
      "[113]\tTrain-logloss:0.22232\tValid-logloss:0.23722\n",
      "[114]\tTrain-logloss:0.22208\tValid-logloss:0.23709\n",
      "[115]\tTrain-logloss:0.22191\tValid-logloss:0.23696\n",
      "[116]\tTrain-logloss:0.22162\tValid-logloss:0.23681\n",
      "[117]\tTrain-logloss:0.22139\tValid-logloss:0.23674\n",
      "[118]\tTrain-logloss:0.22114\tValid-logloss:0.23664\n",
      "[119]\tTrain-logloss:0.22092\tValid-logloss:0.23654\n",
      "[120]\tTrain-logloss:0.22063\tValid-logloss:0.23640\n",
      "[121]\tTrain-logloss:0.22043\tValid-logloss:0.23629\n",
      "[122]\tTrain-logloss:0.22015\tValid-logloss:0.23616\n",
      "[123]\tTrain-logloss:0.21988\tValid-logloss:0.23603\n",
      "[124]\tTrain-logloss:0.21970\tValid-logloss:0.23594\n",
      "[125]\tTrain-logloss:0.21947\tValid-logloss:0.23583\n",
      "[126]\tTrain-logloss:0.21924\tValid-logloss:0.23569\n",
      "[127]\tTrain-logloss:0.21901\tValid-logloss:0.23561\n",
      "[128]\tTrain-logloss:0.21878\tValid-logloss:0.23551\n",
      "[129]\tTrain-logloss:0.21854\tValid-logloss:0.23542\n",
      "[130]\tTrain-logloss:0.21828\tValid-logloss:0.23527\n",
      "[131]\tTrain-logloss:0.21806\tValid-logloss:0.23523\n",
      "[132]\tTrain-logloss:0.21785\tValid-logloss:0.23514\n",
      "[133]\tTrain-logloss:0.21763\tValid-logloss:0.23503\n",
      "[134]\tTrain-logloss:0.21750\tValid-logloss:0.23494\n",
      "[135]\tTrain-logloss:0.21731\tValid-logloss:0.23486\n",
      "[136]\tTrain-logloss:0.21707\tValid-logloss:0.23474\n",
      "[137]\tTrain-logloss:0.21687\tValid-logloss:0.23466\n",
      "[138]\tTrain-logloss:0.21664\tValid-logloss:0.23456\n",
      "[139]\tTrain-logloss:0.21638\tValid-logloss:0.23445\n",
      "[140]\tTrain-logloss:0.21614\tValid-logloss:0.23438\n",
      "[141]\tTrain-logloss:0.21594\tValid-logloss:0.23433\n",
      "[142]\tTrain-logloss:0.21571\tValid-logloss:0.23423\n",
      "[143]\tTrain-logloss:0.21555\tValid-logloss:0.23415\n",
      "[144]\tTrain-logloss:0.21540\tValid-logloss:0.23406\n",
      "[145]\tTrain-logloss:0.21522\tValid-logloss:0.23397\n",
      "[146]\tTrain-logloss:0.21503\tValid-logloss:0.23391\n",
      "[147]\tTrain-logloss:0.21475\tValid-logloss:0.23379\n",
      "[148]\tTrain-logloss:0.21458\tValid-logloss:0.23374\n",
      "[149]\tTrain-logloss:0.21441\tValid-logloss:0.23366\n",
      "[150]\tTrain-logloss:0.21416\tValid-logloss:0.23353\n",
      "[151]\tTrain-logloss:0.21398\tValid-logloss:0.23347\n",
      "[152]\tTrain-logloss:0.21380\tValid-logloss:0.23344\n",
      "[153]\tTrain-logloss:0.21361\tValid-logloss:0.23338\n",
      "[154]\tTrain-logloss:0.21345\tValid-logloss:0.23333\n",
      "[155]\tTrain-logloss:0.21329\tValid-logloss:0.23328\n",
      "[156]\tTrain-logloss:0.21313\tValid-logloss:0.23322\n",
      "[157]\tTrain-logloss:0.21290\tValid-logloss:0.23315\n",
      "[158]\tTrain-logloss:0.21270\tValid-logloss:0.23309\n",
      "[159]\tTrain-logloss:0.21251\tValid-logloss:0.23299\n",
      "[160]\tTrain-logloss:0.21233\tValid-logloss:0.23295\n",
      "[161]\tTrain-logloss:0.21217\tValid-logloss:0.23290\n",
      "[162]\tTrain-logloss:0.21195\tValid-logloss:0.23281\n",
      "[163]\tTrain-logloss:0.21176\tValid-logloss:0.23276\n",
      "[164]\tTrain-logloss:0.21159\tValid-logloss:0.23272\n",
      "[165]\tTrain-logloss:0.21140\tValid-logloss:0.23265\n",
      "[166]\tTrain-logloss:0.21120\tValid-logloss:0.23260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[167]\tTrain-logloss:0.21101\tValid-logloss:0.23255\n",
      "[168]\tTrain-logloss:0.21084\tValid-logloss:0.23251\n",
      "[169]\tTrain-logloss:0.21074\tValid-logloss:0.23248\n",
      "[170]\tTrain-logloss:0.21058\tValid-logloss:0.23243\n",
      "[171]\tTrain-logloss:0.21045\tValid-logloss:0.23242\n",
      "[172]\tTrain-logloss:0.21025\tValid-logloss:0.23235\n",
      "[173]\tTrain-logloss:0.21008\tValid-logloss:0.23231\n",
      "[174]\tTrain-logloss:0.20997\tValid-logloss:0.23224\n",
      "[175]\tTrain-logloss:0.20982\tValid-logloss:0.23220\n",
      "[176]\tTrain-logloss:0.20969\tValid-logloss:0.23217\n",
      "[177]\tTrain-logloss:0.20949\tValid-logloss:0.23204\n",
      "[178]\tTrain-logloss:0.20931\tValid-logloss:0.23193\n",
      "[179]\tTrain-logloss:0.20916\tValid-logloss:0.23189\n",
      "[180]\tTrain-logloss:0.20899\tValid-logloss:0.23188\n",
      "[181]\tTrain-logloss:0.20881\tValid-logloss:0.23182\n",
      "[182]\tTrain-logloss:0.20864\tValid-logloss:0.23181\n",
      "[183]\tTrain-logloss:0.20851\tValid-logloss:0.23178\n",
      "[184]\tTrain-logloss:0.20834\tValid-logloss:0.23175\n",
      "[185]\tTrain-logloss:0.20819\tValid-logloss:0.23171\n",
      "[186]\tTrain-logloss:0.20805\tValid-logloss:0.23169\n",
      "[187]\tTrain-logloss:0.20790\tValid-logloss:0.23165\n",
      "[188]\tTrain-logloss:0.20778\tValid-logloss:0.23162\n",
      "[189]\tTrain-logloss:0.20760\tValid-logloss:0.23153\n",
      "[190]\tTrain-logloss:0.20742\tValid-logloss:0.23148\n",
      "[191]\tTrain-logloss:0.20729\tValid-logloss:0.23145\n",
      "[192]\tTrain-logloss:0.20711\tValid-logloss:0.23143\n",
      "[193]\tTrain-logloss:0.20694\tValid-logloss:0.23143\n",
      "[194]\tTrain-logloss:0.20676\tValid-logloss:0.23136\n",
      "[195]\tTrain-logloss:0.20655\tValid-logloss:0.23130\n",
      "[196]\tTrain-logloss:0.20640\tValid-logloss:0.23129\n",
      "[197]\tTrain-logloss:0.20622\tValid-logloss:0.23125\n",
      "[198]\tTrain-logloss:0.20608\tValid-logloss:0.23123\n",
      "[199]\tTrain-logloss:0.20594\tValid-logloss:0.23122\n",
      "[200]\tTrain-logloss:0.20575\tValid-logloss:0.23114\n",
      "[201]\tTrain-logloss:0.20556\tValid-logloss:0.23109\n",
      "[202]\tTrain-logloss:0.20540\tValid-logloss:0.23105\n",
      "[203]\tTrain-logloss:0.20531\tValid-logloss:0.23103\n",
      "[204]\tTrain-logloss:0.20516\tValid-logloss:0.23099\n",
      "[205]\tTrain-logloss:0.20499\tValid-logloss:0.23094\n",
      "[206]\tTrain-logloss:0.20485\tValid-logloss:0.23090\n",
      "[207]\tTrain-logloss:0.20477\tValid-logloss:0.23089\n",
      "[208]\tTrain-logloss:0.20468\tValid-logloss:0.23085\n",
      "[209]\tTrain-logloss:0.20459\tValid-logloss:0.23083\n",
      "[210]\tTrain-logloss:0.20447\tValid-logloss:0.23083\n",
      "[211]\tTrain-logloss:0.20431\tValid-logloss:0.23081\n",
      "[212]\tTrain-logloss:0.20413\tValid-logloss:0.23078\n",
      "[213]\tTrain-logloss:0.20404\tValid-logloss:0.23075\n",
      "[214]\tTrain-logloss:0.20389\tValid-logloss:0.23072\n",
      "[215]\tTrain-logloss:0.20376\tValid-logloss:0.23069\n",
      "[216]\tTrain-logloss:0.20363\tValid-logloss:0.23064\n",
      "[217]\tTrain-logloss:0.20347\tValid-logloss:0.23062\n",
      "[218]\tTrain-logloss:0.20330\tValid-logloss:0.23061\n",
      "[219]\tTrain-logloss:0.20314\tValid-logloss:0.23061\n",
      "[220]\tTrain-logloss:0.20307\tValid-logloss:0.23059\n",
      "[221]\tTrain-logloss:0.20290\tValid-logloss:0.23056\n",
      "[222]\tTrain-logloss:0.20282\tValid-logloss:0.23055\n",
      "[223]\tTrain-logloss:0.20267\tValid-logloss:0.23051\n",
      "[224]\tTrain-logloss:0.20251\tValid-logloss:0.23047\n",
      "[225]\tTrain-logloss:0.20237\tValid-logloss:0.23045\n",
      "[226]\tTrain-logloss:0.20222\tValid-logloss:0.23039\n",
      "[227]\tTrain-logloss:0.20206\tValid-logloss:0.23040\n",
      "[228]\tTrain-logloss:0.20196\tValid-logloss:0.23040\n",
      "[229]\tTrain-logloss:0.20183\tValid-logloss:0.23036\n",
      "[230]\tTrain-logloss:0.20175\tValid-logloss:0.23036\n",
      "[231]\tTrain-logloss:0.20159\tValid-logloss:0.23034\n",
      "[232]\tTrain-logloss:0.20151\tValid-logloss:0.23032\n",
      "[233]\tTrain-logloss:0.20135\tValid-logloss:0.23030\n",
      "[234]\tTrain-logloss:0.20119\tValid-logloss:0.23029\n",
      "[235]\tTrain-logloss:0.20108\tValid-logloss:0.23027\n",
      "[236]\tTrain-logloss:0.20095\tValid-logloss:0.23025\n",
      "[237]\tTrain-logloss:0.20079\tValid-logloss:0.23023\n",
      "[238]\tTrain-logloss:0.20064\tValid-logloss:0.23021\n",
      "[239]\tTrain-logloss:0.20050\tValid-logloss:0.23018\n",
      "[240]\tTrain-logloss:0.20030\tValid-logloss:0.23011\n",
      "[241]\tTrain-logloss:0.20020\tValid-logloss:0.23007\n",
      "[242]\tTrain-logloss:0.20007\tValid-logloss:0.23006\n",
      "[243]\tTrain-logloss:0.19989\tValid-logloss:0.23002\n",
      "[244]\tTrain-logloss:0.19977\tValid-logloss:0.23001\n",
      "[245]\tTrain-logloss:0.19962\tValid-logloss:0.23000\n",
      "[246]\tTrain-logloss:0.19954\tValid-logloss:0.22998\n",
      "[247]\tTrain-logloss:0.19937\tValid-logloss:0.22998\n",
      "[248]\tTrain-logloss:0.19927\tValid-logloss:0.22996\n",
      "[249]\tTrain-logloss:0.19913\tValid-logloss:0.22996\n",
      "[250]\tTrain-logloss:0.19897\tValid-logloss:0.22995\n",
      "[251]\tTrain-logloss:0.19890\tValid-logloss:0.22992\n",
      "[252]\tTrain-logloss:0.19877\tValid-logloss:0.22993\n",
      "[253]\tTrain-logloss:0.19862\tValid-logloss:0.22993\n",
      "[254]\tTrain-logloss:0.19851\tValid-logloss:0.22989\n",
      "[255]\tTrain-logloss:0.19835\tValid-logloss:0.22988\n",
      "[256]\tTrain-logloss:0.19821\tValid-logloss:0.22985\n",
      "[257]\tTrain-logloss:0.19806\tValid-logloss:0.22982\n",
      "[258]\tTrain-logloss:0.19795\tValid-logloss:0.22981\n",
      "[259]\tTrain-logloss:0.19777\tValid-logloss:0.22977\n",
      "[260]\tTrain-logloss:0.19765\tValid-logloss:0.22978\n",
      "[261]\tTrain-logloss:0.19754\tValid-logloss:0.22976\n",
      "[262]\tTrain-logloss:0.19748\tValid-logloss:0.22976\n",
      "[263]\tTrain-logloss:0.19739\tValid-logloss:0.22975\n",
      "[264]\tTrain-logloss:0.19727\tValid-logloss:0.22974\n",
      "[265]\tTrain-logloss:0.19711\tValid-logloss:0.22973\n",
      "[266]\tTrain-logloss:0.19702\tValid-logloss:0.22971\n",
      "[267]\tTrain-logloss:0.19688\tValid-logloss:0.22969\n",
      "[268]\tTrain-logloss:0.19678\tValid-logloss:0.22968\n",
      "[269]\tTrain-logloss:0.19665\tValid-logloss:0.22966\n",
      "[270]\tTrain-logloss:0.19652\tValid-logloss:0.22966\n",
      "[271]\tTrain-logloss:0.19635\tValid-logloss:0.22963\n",
      "[272]\tTrain-logloss:0.19627\tValid-logloss:0.22960\n",
      "[273]\tTrain-logloss:0.19620\tValid-logloss:0.22959\n",
      "[274]\tTrain-logloss:0.19606\tValid-logloss:0.22956\n",
      "[275]\tTrain-logloss:0.19595\tValid-logloss:0.22951\n",
      "[276]\tTrain-logloss:0.19586\tValid-logloss:0.22953\n",
      "[277]\tTrain-logloss:0.19578\tValid-logloss:0.22949\n",
      "[278]\tTrain-logloss:0.19563\tValid-logloss:0.22949\n",
      "[279]\tTrain-logloss:0.19549\tValid-logloss:0.22948\n",
      "[280]\tTrain-logloss:0.19536\tValid-logloss:0.22948\n",
      "[281]\tTrain-logloss:0.19525\tValid-logloss:0.22947\n",
      "[282]\tTrain-logloss:0.19518\tValid-logloss:0.22948\n",
      "[283]\tTrain-logloss:0.19504\tValid-logloss:0.22947\n",
      "[284]\tTrain-logloss:0.19490\tValid-logloss:0.22947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7749020011541358"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params9 = {\n",
    "    'verbosity': 1,\n",
    "    'max_depth': 3,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eta': 0.075,\n",
    "    'random_state': seed,\n",
    "    'colsample_bytree': 0.4,\n",
    "    'colsample_bylevel': 0.8,\n",
    "    'subsample': 0.8,\n",
    "    'min_child_weight': 16\n",
    "}\n",
    "\n",
    "model9 = xgb.train(params9, train_matrix, steps, early_stopping_rounds=3,\n",
    "                   evals=[(train_matrix, 'Train'), (valid_matrix, 'Valid')])\n",
    "\n",
    "result9 = mf.model_evaluator(model9, valid_matrix, valid['target'])\n",
    "result9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658e0fcf",
   "metadata": {},
   "source": [
    "Increasing min_child_weight beyond 4 has a small negative impact on my performance, and I assume it will only get worse if I increase it from there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bd808d",
   "metadata": {},
   "source": [
    "My last investigation will be into scale_pos_weight. The dataset we have has roughly 3 negative cases for every postive one. The equation to calculate scale_pos_weight is sum(negative instances) / sum(positive instances. I will use 3 for this hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1364b00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTrain-logloss:0.65751\tValid-logloss:0.65804\n",
      "[1]\tTrain-logloss:0.62315\tValid-logloss:0.62390\n",
      "[2]\tTrain-logloss:0.59164\tValid-logloss:0.59242\n",
      "[3]\tTrain-logloss:0.56604\tValid-logloss:0.56701\n",
      "[4]\tTrain-logloss:0.54191\tValid-logloss:0.54315\n",
      "[5]\tTrain-logloss:0.51968\tValid-logloss:0.52106\n",
      "[6]\tTrain-logloss:0.50078\tValid-logloss:0.50247\n",
      "[7]\tTrain-logloss:0.48326\tValid-logloss:0.48517\n",
      "[8]\tTrain-logloss:0.46756\tValid-logloss:0.46966\n",
      "[9]\tTrain-logloss:0.45399\tValid-logloss:0.45632\n",
      "[10]\tTrain-logloss:0.44219\tValid-logloss:0.44481\n",
      "[11]\tTrain-logloss:0.43130\tValid-logloss:0.43403\n",
      "[12]\tTrain-logloss:0.42118\tValid-logloss:0.42407\n",
      "[13]\tTrain-logloss:0.41215\tValid-logloss:0.41522\n",
      "[14]\tTrain-logloss:0.40334\tValid-logloss:0.40655\n",
      "[15]\tTrain-logloss:0.39614\tValid-logloss:0.39944\n",
      "[16]\tTrain-logloss:0.38894\tValid-logloss:0.39240\n",
      "[17]\tTrain-logloss:0.38258\tValid-logloss:0.38618\n",
      "[18]\tTrain-logloss:0.37670\tValid-logloss:0.38045\n",
      "[19]\tTrain-logloss:0.37131\tValid-logloss:0.37517\n",
      "[20]\tTrain-logloss:0.36655\tValid-logloss:0.37063\n",
      "[21]\tTrain-logloss:0.36159\tValid-logloss:0.36582\n",
      "[22]\tTrain-logloss:0.35741\tValid-logloss:0.36174\n",
      "[23]\tTrain-logloss:0.35311\tValid-logloss:0.35752\n",
      "[24]\tTrain-logloss:0.34904\tValid-logloss:0.35357\n",
      "[25]\tTrain-logloss:0.34569\tValid-logloss:0.35031\n",
      "[26]\tTrain-logloss:0.34235\tValid-logloss:0.34708\n",
      "[27]\tTrain-logloss:0.33925\tValid-logloss:0.34420\n",
      "[28]\tTrain-logloss:0.33609\tValid-logloss:0.34106\n",
      "[29]\tTrain-logloss:0.33311\tValid-logloss:0.33827\n",
      "[30]\tTrain-logloss:0.33056\tValid-logloss:0.33584\n",
      "[31]\tTrain-logloss:0.32777\tValid-logloss:0.33322\n",
      "[32]\tTrain-logloss:0.32550\tValid-logloss:0.33112\n",
      "[33]\tTrain-logloss:0.32314\tValid-logloss:0.32900\n",
      "[34]\tTrain-logloss:0.32106\tValid-logloss:0.32702\n",
      "[35]\tTrain-logloss:0.31876\tValid-logloss:0.32489\n",
      "[36]\tTrain-logloss:0.31693\tValid-logloss:0.32323\n",
      "[37]\tTrain-logloss:0.31517\tValid-logloss:0.32168\n",
      "[38]\tTrain-logloss:0.31355\tValid-logloss:0.32017\n",
      "[39]\tTrain-logloss:0.31187\tValid-logloss:0.31867\n",
      "[40]\tTrain-logloss:0.31021\tValid-logloss:0.31705\n",
      "[41]\tTrain-logloss:0.30835\tValid-logloss:0.31532\n",
      "[42]\tTrain-logloss:0.30685\tValid-logloss:0.31403\n",
      "[43]\tTrain-logloss:0.30558\tValid-logloss:0.31290\n",
      "[44]\tTrain-logloss:0.30438\tValid-logloss:0.31182\n",
      "[45]\tTrain-logloss:0.30292\tValid-logloss:0.31056\n",
      "[46]\tTrain-logloss:0.30158\tValid-logloss:0.30939\n",
      "[47]\tTrain-logloss:0.30006\tValid-logloss:0.30806\n",
      "[48]\tTrain-logloss:0.29904\tValid-logloss:0.30719\n",
      "[49]\tTrain-logloss:0.29788\tValid-logloss:0.30621\n",
      "[50]\tTrain-logloss:0.29682\tValid-logloss:0.30526\n",
      "[51]\tTrain-logloss:0.29575\tValid-logloss:0.30436\n",
      "[52]\tTrain-logloss:0.29453\tValid-logloss:0.30320\n",
      "[53]\tTrain-logloss:0.29353\tValid-logloss:0.30232\n",
      "[54]\tTrain-logloss:0.29261\tValid-logloss:0.30143\n",
      "[55]\tTrain-logloss:0.29168\tValid-logloss:0.30067\n",
      "[56]\tTrain-logloss:0.29082\tValid-logloss:0.29992\n",
      "[57]\tTrain-logloss:0.29005\tValid-logloss:0.29932\n",
      "[58]\tTrain-logloss:0.28912\tValid-logloss:0.29851\n",
      "[59]\tTrain-logloss:0.28830\tValid-logloss:0.29778\n",
      "[60]\tTrain-logloss:0.28756\tValid-logloss:0.29711\n",
      "[61]\tTrain-logloss:0.28677\tValid-logloss:0.29650\n",
      "[62]\tTrain-logloss:0.28597\tValid-logloss:0.29587\n",
      "[63]\tTrain-logloss:0.28524\tValid-logloss:0.29529\n",
      "[64]\tTrain-logloss:0.28465\tValid-logloss:0.29482\n",
      "[65]\tTrain-logloss:0.28392\tValid-logloss:0.29431\n",
      "[66]\tTrain-logloss:0.28340\tValid-logloss:0.29389\n",
      "[67]\tTrain-logloss:0.28270\tValid-logloss:0.29339\n",
      "[68]\tTrain-logloss:0.28211\tValid-logloss:0.29296\n",
      "[69]\tTrain-logloss:0.28153\tValid-logloss:0.29252\n",
      "[70]\tTrain-logloss:0.28094\tValid-logloss:0.29211\n",
      "[71]\tTrain-logloss:0.28041\tValid-logloss:0.29167\n",
      "[72]\tTrain-logloss:0.27992\tValid-logloss:0.29131\n",
      "[73]\tTrain-logloss:0.27919\tValid-logloss:0.29074\n",
      "[74]\tTrain-logloss:0.27855\tValid-logloss:0.29029\n",
      "[75]\tTrain-logloss:0.27802\tValid-logloss:0.28984\n",
      "[76]\tTrain-logloss:0.27750\tValid-logloss:0.28948\n",
      "[77]\tTrain-logloss:0.27702\tValid-logloss:0.28913\n",
      "[78]\tTrain-logloss:0.27660\tValid-logloss:0.28884\n",
      "[79]\tTrain-logloss:0.27607\tValid-logloss:0.28836\n",
      "[80]\tTrain-logloss:0.27554\tValid-logloss:0.28790\n",
      "[81]\tTrain-logloss:0.27505\tValid-logloss:0.28753\n",
      "[82]\tTrain-logloss:0.27462\tValid-logloss:0.28724\n",
      "[83]\tTrain-logloss:0.27425\tValid-logloss:0.28700\n",
      "[84]\tTrain-logloss:0.27391\tValid-logloss:0.28677\n",
      "[85]\tTrain-logloss:0.27343\tValid-logloss:0.28637\n",
      "[86]\tTrain-logloss:0.27311\tValid-logloss:0.28617\n",
      "[87]\tTrain-logloss:0.27265\tValid-logloss:0.28584\n",
      "[88]\tTrain-logloss:0.27236\tValid-logloss:0.28570\n",
      "[89]\tTrain-logloss:0.27197\tValid-logloss:0.28546\n",
      "[90]\tTrain-logloss:0.27151\tValid-logloss:0.28520\n",
      "[91]\tTrain-logloss:0.27114\tValid-logloss:0.28498\n",
      "[92]\tTrain-logloss:0.27088\tValid-logloss:0.28488\n",
      "[93]\tTrain-logloss:0.27052\tValid-logloss:0.28464\n",
      "[94]\tTrain-logloss:0.27009\tValid-logloss:0.28430\n",
      "[95]\tTrain-logloss:0.26981\tValid-logloss:0.28416\n",
      "[96]\tTrain-logloss:0.26945\tValid-logloss:0.28392\n",
      "[97]\tTrain-logloss:0.26906\tValid-logloss:0.28373\n",
      "[98]\tTrain-logloss:0.26874\tValid-logloss:0.28353\n",
      "[99]\tTrain-logloss:0.26835\tValid-logloss:0.28326\n",
      "[100]\tTrain-logloss:0.26795\tValid-logloss:0.28299\n",
      "[101]\tTrain-logloss:0.26760\tValid-logloss:0.28276\n",
      "[102]\tTrain-logloss:0.26723\tValid-logloss:0.28254\n",
      "[103]\tTrain-logloss:0.26703\tValid-logloss:0.28244\n",
      "[104]\tTrain-logloss:0.26672\tValid-logloss:0.28223\n",
      "[105]\tTrain-logloss:0.26634\tValid-logloss:0.28199\n",
      "[106]\tTrain-logloss:0.26598\tValid-logloss:0.28168\n",
      "[107]\tTrain-logloss:0.26568\tValid-logloss:0.28148\n",
      "[108]\tTrain-logloss:0.26536\tValid-logloss:0.28124\n",
      "[109]\tTrain-logloss:0.26506\tValid-logloss:0.28109\n",
      "[110]\tTrain-logloss:0.26472\tValid-logloss:0.28089\n",
      "[111]\tTrain-logloss:0.26426\tValid-logloss:0.28057\n",
      "[112]\tTrain-logloss:0.26396\tValid-logloss:0.28042\n",
      "[113]\tTrain-logloss:0.26375\tValid-logloss:0.28034\n",
      "[114]\tTrain-logloss:0.26341\tValid-logloss:0.28013\n",
      "[115]\tTrain-logloss:0.26313\tValid-logloss:0.27995\n",
      "[116]\tTrain-logloss:0.26280\tValid-logloss:0.27976\n",
      "[117]\tTrain-logloss:0.26251\tValid-logloss:0.27962\n",
      "[118]\tTrain-logloss:0.26227\tValid-logloss:0.27954\n",
      "[119]\tTrain-logloss:0.26202\tValid-logloss:0.27944\n",
      "[120]\tTrain-logloss:0.26164\tValid-logloss:0.27923\n",
      "[121]\tTrain-logloss:0.26140\tValid-logloss:0.27912\n",
      "[122]\tTrain-logloss:0.26115\tValid-logloss:0.27906\n",
      "[123]\tTrain-logloss:0.26084\tValid-logloss:0.27891\n",
      "[124]\tTrain-logloss:0.26058\tValid-logloss:0.27880\n",
      "[125]\tTrain-logloss:0.26026\tValid-logloss:0.27861\n",
      "[126]\tTrain-logloss:0.25991\tValid-logloss:0.27841\n",
      "[127]\tTrain-logloss:0.25961\tValid-logloss:0.27827\n",
      "[128]\tTrain-logloss:0.25934\tValid-logloss:0.27814\n",
      "[129]\tTrain-logloss:0.25915\tValid-logloss:0.27802\n",
      "[130]\tTrain-logloss:0.25881\tValid-logloss:0.27786\n",
      "[131]\tTrain-logloss:0.25846\tValid-logloss:0.27772\n",
      "[132]\tTrain-logloss:0.25819\tValid-logloss:0.27763\n",
      "[133]\tTrain-logloss:0.25794\tValid-logloss:0.27756\n",
      "[134]\tTrain-logloss:0.25764\tValid-logloss:0.27735\n",
      "[135]\tTrain-logloss:0.25743\tValid-logloss:0.27724\n",
      "[136]\tTrain-logloss:0.25720\tValid-logloss:0.27710\n",
      "[137]\tTrain-logloss:0.25695\tValid-logloss:0.27691\n",
      "[138]\tTrain-logloss:0.25674\tValid-logloss:0.27682\n",
      "[139]\tTrain-logloss:0.25665\tValid-logloss:0.27679\n",
      "[140]\tTrain-logloss:0.25643\tValid-logloss:0.27673\n",
      "[141]\tTrain-logloss:0.25619\tValid-logloss:0.27665\n",
      "[142]\tTrain-logloss:0.25602\tValid-logloss:0.27664\n",
      "[143]\tTrain-logloss:0.25577\tValid-logloss:0.27650\n",
      "[144]\tTrain-logloss:0.25548\tValid-logloss:0.27632\n",
      "[145]\tTrain-logloss:0.25526\tValid-logloss:0.27620\n",
      "[146]\tTrain-logloss:0.25500\tValid-logloss:0.27608\n",
      "[147]\tTrain-logloss:0.25468\tValid-logloss:0.27588\n",
      "[148]\tTrain-logloss:0.25436\tValid-logloss:0.27566\n",
      "[149]\tTrain-logloss:0.25413\tValid-logloss:0.27562\n",
      "[150]\tTrain-logloss:0.25389\tValid-logloss:0.27551\n",
      "[151]\tTrain-logloss:0.25368\tValid-logloss:0.27542\n",
      "[152]\tTrain-logloss:0.25343\tValid-logloss:0.27535\n",
      "[153]\tTrain-logloss:0.25323\tValid-logloss:0.27535\n",
      "[154]\tTrain-logloss:0.25313\tValid-logloss:0.27533\n",
      "[155]\tTrain-logloss:0.25288\tValid-logloss:0.27527\n",
      "[156]\tTrain-logloss:0.25272\tValid-logloss:0.27526\n",
      "[157]\tTrain-logloss:0.25254\tValid-logloss:0.27519\n",
      "[158]\tTrain-logloss:0.25234\tValid-logloss:0.27516\n",
      "[159]\tTrain-logloss:0.25210\tValid-logloss:0.27504\n",
      "[160]\tTrain-logloss:0.25183\tValid-logloss:0.27488\n",
      "[161]\tTrain-logloss:0.25161\tValid-logloss:0.27481\n",
      "[162]\tTrain-logloss:0.25128\tValid-logloss:0.27460\n",
      "[163]\tTrain-logloss:0.25112\tValid-logloss:0.27455\n",
      "[164]\tTrain-logloss:0.25091\tValid-logloss:0.27440\n",
      "[165]\tTrain-logloss:0.25058\tValid-logloss:0.27417\n",
      "[166]\tTrain-logloss:0.25045\tValid-logloss:0.27418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[167]\tTrain-logloss:0.25034\tValid-logloss:0.27419\n",
      "[168]\tTrain-logloss:0.25012\tValid-logloss:0.27414\n",
      "[169]\tTrain-logloss:0.24984\tValid-logloss:0.27400\n",
      "[170]\tTrain-logloss:0.24967\tValid-logloss:0.27393\n",
      "[171]\tTrain-logloss:0.24937\tValid-logloss:0.27379\n",
      "[172]\tTrain-logloss:0.24905\tValid-logloss:0.27361\n",
      "[173]\tTrain-logloss:0.24879\tValid-logloss:0.27346\n",
      "[174]\tTrain-logloss:0.24854\tValid-logloss:0.27334\n",
      "[175]\tTrain-logloss:0.24848\tValid-logloss:0.27335\n",
      "[176]\tTrain-logloss:0.24835\tValid-logloss:0.27333\n",
      "[177]\tTrain-logloss:0.24811\tValid-logloss:0.27323\n",
      "[178]\tTrain-logloss:0.24786\tValid-logloss:0.27305\n",
      "[179]\tTrain-logloss:0.24770\tValid-logloss:0.27301\n",
      "[180]\tTrain-logloss:0.24740\tValid-logloss:0.27289\n",
      "[181]\tTrain-logloss:0.24717\tValid-logloss:0.27280\n",
      "[182]\tTrain-logloss:0.24685\tValid-logloss:0.27263\n",
      "[183]\tTrain-logloss:0.24669\tValid-logloss:0.27255\n",
      "[184]\tTrain-logloss:0.24647\tValid-logloss:0.27246\n",
      "[185]\tTrain-logloss:0.24631\tValid-logloss:0.27238\n",
      "[186]\tTrain-logloss:0.24610\tValid-logloss:0.27227\n",
      "[187]\tTrain-logloss:0.24592\tValid-logloss:0.27226\n",
      "[188]\tTrain-logloss:0.24580\tValid-logloss:0.27228\n",
      "[189]\tTrain-logloss:0.24565\tValid-logloss:0.27226\n",
      "[190]\tTrain-logloss:0.24544\tValid-logloss:0.27215\n",
      "[191]\tTrain-logloss:0.24529\tValid-logloss:0.27210\n",
      "[192]\tTrain-logloss:0.24509\tValid-logloss:0.27203\n",
      "[193]\tTrain-logloss:0.24488\tValid-logloss:0.27195\n",
      "[194]\tTrain-logloss:0.24473\tValid-logloss:0.27199\n",
      "[195]\tTrain-logloss:0.24451\tValid-logloss:0.27190\n",
      "[196]\tTrain-logloss:0.24444\tValid-logloss:0.27193\n",
      "[197]\tTrain-logloss:0.24422\tValid-logloss:0.27184\n",
      "[198]\tTrain-logloss:0.24405\tValid-logloss:0.27179\n",
      "[199]\tTrain-logloss:0.24392\tValid-logloss:0.27182\n",
      "[200]\tTrain-logloss:0.24373\tValid-logloss:0.27176\n",
      "[201]\tTrain-logloss:0.24350\tValid-logloss:0.27169\n",
      "[202]\tTrain-logloss:0.24324\tValid-logloss:0.27156\n",
      "[203]\tTrain-logloss:0.24303\tValid-logloss:0.27147\n",
      "[204]\tTrain-logloss:0.24281\tValid-logloss:0.27138\n",
      "[205]\tTrain-logloss:0.24271\tValid-logloss:0.27135\n",
      "[206]\tTrain-logloss:0.24252\tValid-logloss:0.27127\n",
      "[207]\tTrain-logloss:0.24232\tValid-logloss:0.27119\n",
      "[208]\tTrain-logloss:0.24217\tValid-logloss:0.27116\n",
      "[209]\tTrain-logloss:0.24203\tValid-logloss:0.27113\n",
      "[210]\tTrain-logloss:0.24185\tValid-logloss:0.27109\n",
      "[211]\tTrain-logloss:0.24157\tValid-logloss:0.27095\n",
      "[212]\tTrain-logloss:0.24139\tValid-logloss:0.27090\n",
      "[213]\tTrain-logloss:0.24120\tValid-logloss:0.27080\n",
      "[214]\tTrain-logloss:0.24087\tValid-logloss:0.27061\n",
      "[215]\tTrain-logloss:0.24071\tValid-logloss:0.27058\n",
      "[216]\tTrain-logloss:0.24059\tValid-logloss:0.27057\n",
      "[217]\tTrain-logloss:0.24046\tValid-logloss:0.27059\n",
      "[218]\tTrain-logloss:0.24017\tValid-logloss:0.27047\n",
      "[219]\tTrain-logloss:0.24003\tValid-logloss:0.27047\n",
      "[220]\tTrain-logloss:0.23986\tValid-logloss:0.27044\n",
      "[221]\tTrain-logloss:0.23972\tValid-logloss:0.27039\n",
      "[222]\tTrain-logloss:0.23952\tValid-logloss:0.27036\n",
      "[223]\tTrain-logloss:0.23927\tValid-logloss:0.27019\n",
      "[224]\tTrain-logloss:0.23915\tValid-logloss:0.27015\n",
      "[225]\tTrain-logloss:0.23888\tValid-logloss:0.27002\n",
      "[226]\tTrain-logloss:0.23879\tValid-logloss:0.27004\n",
      "[227]\tTrain-logloss:0.23858\tValid-logloss:0.26997\n",
      "[228]\tTrain-logloss:0.23839\tValid-logloss:0.26992\n",
      "[229]\tTrain-logloss:0.23818\tValid-logloss:0.26987\n",
      "[230]\tTrain-logloss:0.23807\tValid-logloss:0.26985\n",
      "[231]\tTrain-logloss:0.23785\tValid-logloss:0.26980\n",
      "[232]\tTrain-logloss:0.23776\tValid-logloss:0.26977\n",
      "[233]\tTrain-logloss:0.23750\tValid-logloss:0.26970\n",
      "[234]\tTrain-logloss:0.23738\tValid-logloss:0.26975\n",
      "[235]\tTrain-logloss:0.23722\tValid-logloss:0.26966\n",
      "[236]\tTrain-logloss:0.23702\tValid-logloss:0.26959\n",
      "[237]\tTrain-logloss:0.23692\tValid-logloss:0.26961\n",
      "[238]\tTrain-logloss:0.23683\tValid-logloss:0.26964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7732946179740022"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params10 = {\n",
    "    'verbosity': 1,\n",
    "    'max_depth': 3,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eta': 0.075,\n",
    "    'random_state': seed,\n",
    "    'colsample_bytree': 0.4,\n",
    "    'colsample_bylevel': 0.8,\n",
    "    'subsample': 0.8,\n",
    "    'min_child_weight': 4,\n",
    "    'scale_pos_weight': 3\n",
    "}\n",
    "\n",
    "model10 = xgb.train(params10, train_matrix, steps, early_stopping_rounds=3,\n",
    "                   evals=[(train_matrix, 'Train'), (valid_matrix, 'Valid')])\n",
    "\n",
    "result10 = mf.model_evaluator(model10, valid_matrix, valid['target'])\n",
    "result10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54edcc9",
   "metadata": {},
   "source": [
    "Something bad happened."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf50e1b",
   "metadata": {},
   "source": [
    "The main takeaway from this exploration is that marginal improvements in model performance can be made by hyperparameter tuning. The greatest improvements were achieved from the data-side of the project: engineering useful features and determing how to cap values and impute null values. The best way forward is to engineer additional useful features and merge the validation dataset onto the train dataset for a greater body of training data. Currently, the train portion is 10% and validation is the other 90%. Combining this data and using the holdout test portion on the Kaggle website as the validation subset could greatly improve model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1683de",
   "metadata": {},
   "source": [
    "Model8 had the best performance on the validation subset with an amex score of 0.775. The hyperparameters for this model are as follows:\n",
    "\n",
    "params8 = {  \n",
    "    'verbosity': 1,  \n",
    "    'max_depth': 3,  \n",
    "    'objective': 'binary:logistic',  \n",
    "    'eta': 0.075,  \n",
    "    'random_state': seed,  \n",
    "    'colsample_bytree': 0.4,  \n",
    "    'colsample_bylevel': 0.8,  \n",
    "    'subsample': 0.8,  \n",
    "    'min_child_weight': 4  \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1a9ee8",
   "metadata": {},
   "source": [
    "I will investigate the importance of features passed in to the model. I do this with the get_score Booster object attribute. I can choose from one of five ways to define importance. In this case, I went with weight, which is the number of times each feature was used to split the data. In essence, the features with the greatest weight have the greatest decision-making power in my decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c9d6e186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'P_2_min': 24.0,\n",
       " 'P_2_max': 3.0,\n",
       " 'P_2_median': 14.0,\n",
       " 'P_2_std': 1.0,\n",
       " 'P_2_last': 57.0,\n",
       " 'P_2_change': 4.0,\n",
       " 'D_39_min': 1.0,\n",
       " 'D_39_max': 15.0,\n",
       " 'D_39_std': 5.0,\n",
       " 'D_39_last': 32.0,\n",
       " 'D_39_change': 11.0,\n",
       " 'B_1_min': 1.0,\n",
       " 'B_1_max': 2.0,\n",
       " 'B_1_std': 1.0,\n",
       " 'B_1_last': 14.0,\n",
       " 'B_1_change': 3.0,\n",
       " 'B_2_min': 2.0,\n",
       " 'B_2_max': 1.0,\n",
       " 'B_2_median': 1.0,\n",
       " 'B_2_last': 15.0,\n",
       " 'B_2_change': 3.0,\n",
       " 'R_1_min': 3.0,\n",
       " 'R_1_max': 8.0,\n",
       " 'R_1_std': 5.0,\n",
       " 'R_1_last': 11.0,\n",
       " 'R_1_change': 2.0,\n",
       " 'S_3_min': 6.0,\n",
       " 'S_3_median': 9.0,\n",
       " 'S_3_std': 2.0,\n",
       " 'S_3_last': 7.0,\n",
       " 'S_3_change': 5.0,\n",
       " 'D_41_min': 1.0,\n",
       " 'D_41_max': 4.0,\n",
       " 'D_41_median': 1.0,\n",
       " 'D_41_std': 9.0,\n",
       " 'D_41_last': 11.0,\n",
       " 'D_41_change': 14.0,\n",
       " 'B_3_min': 3.0,\n",
       " 'B_3_max': 8.0,\n",
       " 'B_3_median': 2.0,\n",
       " 'B_3_std': 5.0,\n",
       " 'B_3_last': 17.0,\n",
       " 'B_3_change': 10.0,\n",
       " 'D_42_min': 11.0,\n",
       " 'D_42_max': 6.0,\n",
       " 'D_42_median': 7.0,\n",
       " 'D_42_last': 3.0,\n",
       " 'D_43_median': 3.0,\n",
       " 'D_43_std': 4.0,\n",
       " 'D_43_change': 3.0,\n",
       " 'D_44_std': 2.0,\n",
       " 'D_44_last': 4.0,\n",
       " 'D_44_change': 7.0,\n",
       " 'B_4_min': 1.0,\n",
       " 'B_4_max': 9.0,\n",
       " 'B_4_median': 1.0,\n",
       " 'B_4_std': 12.0,\n",
       " 'B_4_last': 17.0,\n",
       " 'B_4_change': 18.0,\n",
       " 'D_45_min': 2.0,\n",
       " 'D_45_max': 10.0,\n",
       " 'D_45_median': 7.0,\n",
       " 'D_45_std': 1.0,\n",
       " 'D_45_last': 2.0,\n",
       " 'D_45_change': 2.0,\n",
       " 'B_5_min': 1.0,\n",
       " 'B_5_max': 1.0,\n",
       " 'B_5_median': 9.0,\n",
       " 'B_5_last': 7.0,\n",
       " 'B_5_change': 2.0,\n",
       " 'R_2_median': 1.0,\n",
       " 'R_2_std': 1.0,\n",
       " 'R_2_last': 5.0,\n",
       " 'R_2_change': 2.0,\n",
       " 'D_46_min': 1.0,\n",
       " 'D_46_median': 1.0,\n",
       " 'D_46_std': 1.0,\n",
       " 'D_46_last': 10.0,\n",
       " 'D_46_change': 1.0,\n",
       " 'D_47_min': 5.0,\n",
       " 'D_47_max': 4.0,\n",
       " 'D_47_median': 10.0,\n",
       " 'D_47_std': 1.0,\n",
       " 'D_47_last': 2.0,\n",
       " 'D_47_change': 1.0,\n",
       " 'D_48_min': 1.0,\n",
       " 'D_48_max': 1.0,\n",
       " 'D_48_std': 5.0,\n",
       " 'D_48_last': 2.0,\n",
       " 'D_48_change': 2.0,\n",
       " 'D_49_min': 1.0,\n",
       " 'D_49_std': 3.0,\n",
       " 'D_49_last': 6.0,\n",
       " 'D_49_change': 2.0,\n",
       " 'B_6_min': 3.0,\n",
       " 'B_6_max': 1.0,\n",
       " 'B_6_median': 3.0,\n",
       " 'B_6_std': 1.0,\n",
       " 'B_6_last': 3.0,\n",
       " 'B_7_max': 4.0,\n",
       " 'B_7_median': 2.0,\n",
       " 'B_7_std': 4.0,\n",
       " 'B_7_last': 13.0,\n",
       " 'B_7_change': 4.0,\n",
       " 'B_8_min': 3.0,\n",
       " 'B_8_max': 4.0,\n",
       " 'B_8_median': 1.0,\n",
       " 'B_8_std': 1.0,\n",
       " 'B_8_last': 3.0,\n",
       " 'B_8_change': 5.0,\n",
       " 'D_50_min': 4.0,\n",
       " 'D_50_median': 2.0,\n",
       " 'D_50_std': 5.0,\n",
       " 'D_50_last': 3.0,\n",
       " 'D_50_change': 6.0,\n",
       " 'D_51_min': 4.0,\n",
       " 'D_51_max': 3.0,\n",
       " 'D_51_median': 3.0,\n",
       " 'D_51_std': 1.0,\n",
       " 'D_51_last': 6.0,\n",
       " 'B_9_max': 4.0,\n",
       " 'B_9_std': 1.0,\n",
       " 'B_9_last': 5.0,\n",
       " 'R_3_min': 2.0,\n",
       " 'R_3_max': 8.0,\n",
       " 'R_3_median': 8.0,\n",
       " 'R_3_std': 2.0,\n",
       " 'R_3_last': 19.0,\n",
       " 'R_3_change': 1.0,\n",
       " 'D_52_min': 3.0,\n",
       " 'D_52_max': 1.0,\n",
       " 'D_52_median': 3.0,\n",
       " 'D_52_std': 2.0,\n",
       " 'D_52_last': 2.0,\n",
       " 'P_3_max': 1.0,\n",
       " 'P_3_median': 1.0,\n",
       " 'P_3_last': 4.0,\n",
       " 'P_3_change': 2.0,\n",
       " 'B_10_min': 2.0,\n",
       " 'B_10_max': 1.0,\n",
       " 'B_10_median': 1.0,\n",
       " 'B_10_std': 1.0,\n",
       " 'B_10_last': 3.0,\n",
       " 'D_53_max': 1.0,\n",
       " 'D_53_median': 1.0,\n",
       " 'D_53_last': 2.0,\n",
       " 'S_5_max': 3.0,\n",
       " 'S_5_median': 2.0,\n",
       " 'S_5_last': 2.0,\n",
       " 'S_5_change': 6.0,\n",
       " 'B_11_min': 1.0,\n",
       " 'B_11_median': 1.0,\n",
       " 'B_11_last': 12.0,\n",
       " 'B_11_change': 3.0,\n",
       " 'S_6_median': 1.0,\n",
       " 'S_6_std': 3.0,\n",
       " 'S_6_last': 1.0,\n",
       " 'S_6_change': 2.0,\n",
       " 'D_54_min': 2.0,\n",
       " 'D_54_std': 1.0,\n",
       " 'D_54_last': 3.0,\n",
       " 'D_54_change': 3.0,\n",
       " 'R_4_max': 1.0,\n",
       " 'R_4_median': 1.0,\n",
       " 'R_4_last': 2.0,\n",
       " 'R_4_change': 1.0,\n",
       " 'S_7_median': 2.0,\n",
       " 'S_7_std': 1.0,\n",
       " 'S_7_last': 4.0,\n",
       " 'S_7_change': 2.0,\n",
       " 'B_12_min': 1.0,\n",
       " 'B_12_std': 3.0,\n",
       " 'B_12_change': 1.0,\n",
       " 'S_8_max': 6.0,\n",
       " 'S_8_median': 2.0,\n",
       " 'S_8_std': 3.0,\n",
       " 'S_8_last': 2.0,\n",
       " 'D_55_min': 2.0,\n",
       " 'D_55_max': 1.0,\n",
       " 'D_55_std': 2.0,\n",
       " 'D_55_last': 1.0,\n",
       " 'D_55_change': 4.0,\n",
       " 'D_56_min': 7.0,\n",
       " 'D_56_std': 1.0,\n",
       " 'D_56_last': 1.0,\n",
       " 'B_13_median': 1.0,\n",
       " 'B_13_last': 3.0,\n",
       " 'R_5_min': 1.0,\n",
       " 'R_5_median': 1.0,\n",
       " 'R_5_std': 3.0,\n",
       " 'R_5_last': 2.0,\n",
       " 'R_5_change': 3.0,\n",
       " 'D_58_min': 1.0,\n",
       " 'D_58_max': 1.0,\n",
       " 'D_58_median': 1.0,\n",
       " 'D_58_last': 5.0,\n",
       " 'D_58_change': 2.0,\n",
       " 'S_9_min': 6.0,\n",
       " 'S_9_median': 1.0,\n",
       " 'S_9_std': 1.0,\n",
       " 'S_9_last': 2.0,\n",
       " 'B_14_min': 1.0,\n",
       " 'B_14_max': 1.0,\n",
       " 'B_14_median': 2.0,\n",
       " 'B_14_std': 2.0,\n",
       " 'B_14_last': 4.0,\n",
       " 'B_14_change': 1.0,\n",
       " 'D_59_median': 1.0,\n",
       " 'D_59_std': 1.0,\n",
       " 'D_59_last': 4.0,\n",
       " 'D_59_change': 1.0,\n",
       " 'D_60_min': 1.0,\n",
       " 'D_60_max': 2.0,\n",
       " 'D_60_median': 1.0,\n",
       " 'D_60_last': 5.0,\n",
       " 'D_60_change': 6.0,\n",
       " 'D_61_min': 4.0,\n",
       " 'D_61_change': 1.0,\n",
       " 'B_15_min': 1.0,\n",
       " 'B_15_max': 2.0,\n",
       " 'B_15_median': 1.0,\n",
       " 'B_15_std': 6.0,\n",
       " 'B_15_change': 1.0,\n",
       " 'S_11_min': 4.0,\n",
       " 'S_11_max': 8.0,\n",
       " 'S_11_median': 4.0,\n",
       " 'S_11_std': 1.0,\n",
       " 'S_11_last': 6.0,\n",
       " 'S_11_change': 1.0,\n",
       " 'D_62_min': 7.0,\n",
       " 'D_62_max': 1.0,\n",
       " 'D_62_median': 2.0,\n",
       " 'D_62_std': 1.0,\n",
       " 'D_62_last': 4.0,\n",
       " 'D_62_change': 1.0,\n",
       " 'D_65_max': 8.0,\n",
       " 'D_65_median': 1.0,\n",
       " 'D_65_std': 5.0,\n",
       " 'D_65_last': 4.0,\n",
       " 'D_65_change': 1.0,\n",
       " 'B_16_max': 1.0,\n",
       " 'B_16_median': 1.0,\n",
       " 'B_16_std': 1.0,\n",
       " 'B_16_change': 2.0,\n",
       " 'B_17_min': 1.0,\n",
       " 'B_17_median': 1.0,\n",
       " 'B_17_last': 2.0,\n",
       " 'B_18_min': 1.0,\n",
       " 'B_18_max': 1.0,\n",
       " 'B_18_median': 1.0,\n",
       " 'B_18_last': 4.0,\n",
       " 'B_19_last': 1.0,\n",
       " 'B_20_median': 1.0,\n",
       " 'B_20_last': 1.0,\n",
       " 'B_20_change': 1.0,\n",
       " 'S_12_min': 1.0,\n",
       " 'S_12_max': 6.0,\n",
       " 'S_12_median': 2.0,\n",
       " 'S_12_std': 9.0,\n",
       " 'S_12_last': 2.0,\n",
       " 'R_6_min': 1.0,\n",
       " 'R_6_max': 1.0,\n",
       " 'R_6_median': 4.0,\n",
       " 'R_6_std': 2.0,\n",
       " 'R_6_last': 4.0,\n",
       " 'R_6_change': 3.0,\n",
       " 'S_13_min': 1.0,\n",
       " 'S_13_max': 3.0,\n",
       " 'S_13_last': 3.0,\n",
       " 'B_21_max': 2.0,\n",
       " 'B_21_median': 1.0,\n",
       " 'B_21_std': 3.0,\n",
       " 'B_21_change': 2.0,\n",
       " 'D_69_max': 1.0,\n",
       " 'D_69_last': 1.0,\n",
       " 'D_69_change': 2.0,\n",
       " 'B_22_median': 2.0,\n",
       " 'B_22_last': 2.0,\n",
       " 'D_70_min': 1.0,\n",
       " 'D_70_max': 3.0,\n",
       " 'D_70_median': 4.0,\n",
       " 'D_70_std': 1.0,\n",
       " 'D_70_last': 1.0,\n",
       " 'D_71_max': 1.0,\n",
       " 'D_71_last': 3.0,\n",
       " 'D_71_change': 1.0,\n",
       " 'D_72_min': 1.0,\n",
       " 'D_72_median': 1.0,\n",
       " 'D_72_last': 1.0,\n",
       " 'D_72_change': 1.0,\n",
       " 'S_15_max': 6.0,\n",
       " 'S_15_median': 5.0,\n",
       " 'S_15_last': 2.0,\n",
       " 'S_15_change': 2.0,\n",
       " 'B_23_min': 1.0,\n",
       " 'B_23_max': 2.0,\n",
       " 'B_23_median': 1.0,\n",
       " 'B_23_std': 5.0,\n",
       " 'B_23_last': 7.0,\n",
       " 'B_23_change': 1.0,\n",
       " 'P_4_min': 1.0,\n",
       " 'P_4_std': 1.0,\n",
       " 'P_4_last': 2.0,\n",
       " 'P_4_change': 1.0,\n",
       " 'D_74_min': 1.0,\n",
       " 'D_74_median': 1.0,\n",
       " 'D_74_std': 2.0,\n",
       " 'D_74_last': 2.0,\n",
       " 'D_75_max': 1.0,\n",
       " 'D_75_median': 1.0,\n",
       " 'D_75_std': 5.0,\n",
       " 'D_75_last': 1.0,\n",
       " 'D_75_change': 1.0,\n",
       " 'B_24_max': 2.0,\n",
       " 'B_24_median': 1.0,\n",
       " 'B_24_last': 1.0,\n",
       " 'B_24_change': 1.0,\n",
       " 'R_7_min': 1.0,\n",
       " 'R_7_median': 2.0,\n",
       " 'R_7_std': 3.0,\n",
       " 'R_7_last': 3.0,\n",
       " 'R_7_change': 2.0,\n",
       " 'D_77_max': 1.0,\n",
       " 'D_77_median': 5.0,\n",
       " 'D_77_last': 1.0,\n",
       " 'B_25_last': 2.0,\n",
       " 'B_25_change': 5.0,\n",
       " 'B_26_max': 2.0,\n",
       " 'B_26_std': 2.0,\n",
       " 'B_26_last': 2.0,\n",
       " 'B_26_change': 1.0,\n",
       " 'D_78_last': 1.0,\n",
       " 'D_78_change': 1.0,\n",
       " 'D_79_min': 1.0,\n",
       " 'D_79_median': 2.0,\n",
       " 'D_79_std': 1.0,\n",
       " 'D_79_last': 7.0,\n",
       " 'D_79_change': 4.0,\n",
       " 'R_8_min': 1.0,\n",
       " 'R_8_max': 2.0,\n",
       " 'R_8_median': 1.0,\n",
       " 'R_8_std': 2.0,\n",
       " 'R_8_last': 3.0,\n",
       " 'R_8_change': 2.0,\n",
       " 'R_9_std': 2.0,\n",
       " 'S_16_max': 3.0,\n",
       " 'S_16_std': 1.0,\n",
       " 'S_16_last': 1.0,\n",
       " 'D_80_min': 1.0,\n",
       " 'D_80_max': 1.0,\n",
       " 'D_80_median': 1.0,\n",
       " 'D_80_std': 1.0,\n",
       " 'D_80_change': 1.0,\n",
       " 'R_10_min': 2.0,\n",
       " 'R_10_last': 4.0,\n",
       " 'R_11_min': 1.0,\n",
       " 'R_11_max': 1.0,\n",
       " 'R_11_median': 2.0,\n",
       " 'R_11_std': 4.0,\n",
       " 'R_11_last': 2.0,\n",
       " 'R_11_change': 1.0,\n",
       " 'B_27_min': 2.0,\n",
       " 'B_27_std': 1.0,\n",
       " 'B_27_change': 3.0,\n",
       " 'D_81_min': 2.0,\n",
       " 'D_81_change': 1.0,\n",
       " 'D_82_min': 1.0,\n",
       " 'D_82_std': 3.0,\n",
       " 'S_17_min': 1.0,\n",
       " 'S_17_median': 1.0,\n",
       " 'R_12_min': 3.0,\n",
       " 'R_12_max': 1.0,\n",
       " 'R_12_last': 5.0,\n",
       " 'R_12_change': 1.0,\n",
       " 'B_28_median': 2.0,\n",
       " 'R_13_min': 1.0,\n",
       " 'R_13_median': 2.0,\n",
       " 'R_13_std': 1.0,\n",
       " 'R_13_change': 2.0,\n",
       " 'R_14_median': 1.0,\n",
       " 'R_14_std': 1.0,\n",
       " 'R_15_median': 1.0,\n",
       " 'R_15_std': 2.0,\n",
       " 'D_84_last': 3.0,\n",
       " 'R_16_max': 1.0,\n",
       " 'R_16_std': 3.0,\n",
       " 'R_16_last': 2.0,\n",
       " 'R_16_change': 1.0,\n",
       " 'B_29_min': 2.0,\n",
       " 'B_29_median': 1.0,\n",
       " 'B_29_std': 5.0,\n",
       " 'S_18_min': 1.0,\n",
       " 'S_18_last': 2.0,\n",
       " 'D_86_min': 3.0,\n",
       " 'D_86_median': 2.0,\n",
       " 'D_86_last': 2.0,\n",
       " 'D_86_change': 3.0,\n",
       " 'R_18_min': 2.0,\n",
       " 'R_18_max': 1.0,\n",
       " 'R_18_median': 3.0,\n",
       " 'R_18_std': 2.0,\n",
       " 'R_18_last': 1.0,\n",
       " 'R_18_change': 2.0,\n",
       " 'D_88_min': 2.0,\n",
       " 'S_19_median': 1.0,\n",
       " 'S_19_last': 1.0,\n",
       " 'R_19_std': 7.0,\n",
       " 'R_19_last': 1.0,\n",
       " 'R_19_change': 2.0,\n",
       " 'B_32_min': 1.0,\n",
       " 'B_32_max': 7.0,\n",
       " 'B_32_median': 1.0,\n",
       " 'B_32_std': 2.0,\n",
       " 'B_32_last': 1.0,\n",
       " 'B_32_change': 2.0,\n",
       " 'S_20_min': 1.0,\n",
       " 'S_20_max': 3.0,\n",
       " 'S_20_median': 2.0,\n",
       " 'S_20_std': 2.0,\n",
       " 'S_20_last': 2.0,\n",
       " 'S_20_change': 1.0,\n",
       " 'R_20_max': 3.0,\n",
       " 'R_20_median': 1.0,\n",
       " 'R_20_change': 3.0,\n",
       " 'R_21_min': 1.0,\n",
       " 'R_21_max': 2.0,\n",
       " 'R_21_median': 1.0,\n",
       " 'R_21_std': 1.0,\n",
       " 'R_21_last': 1.0,\n",
       " 'R_21_change': 1.0,\n",
       " 'B_33_min': 1.0,\n",
       " 'B_33_median': 1.0,\n",
       " 'B_33_std': 2.0,\n",
       " 'B_33_last': 2.0,\n",
       " 'B_33_change': 1.0,\n",
       " 'D_89_min': 1.0,\n",
       " 'D_89_last': 3.0,\n",
       " 'R_22_last': 1.0,\n",
       " 'R_23_median': 2.0,\n",
       " 'R_23_std': 2.0,\n",
       " 'D_91_last': 1.0,\n",
       " 'D_91_change': 2.0,\n",
       " 'D_92_median': 1.0,\n",
       " 'D_92_last': 1.0,\n",
       " 'D_93_min': 3.0,\n",
       " 'D_93_max': 2.0,\n",
       " 'D_93_median': 1.0,\n",
       " 'D_94_min': 3.0,\n",
       " 'D_94_std': 2.0,\n",
       " 'D_94_change': 1.0,\n",
       " 'R_24_median': 1.0,\n",
       " 'R_24_std': 1.0,\n",
       " 'R_24_change': 2.0,\n",
       " 'R_25_min': 1.0,\n",
       " 'R_25_std': 1.0,\n",
       " 'R_25_last': 1.0,\n",
       " 'D_96_min': 1.0,\n",
       " 'D_96_max': 2.0,\n",
       " 'D_96_median': 1.0,\n",
       " 'D_96_std': 1.0,\n",
       " 'D_96_last': 1.0,\n",
       " 'S_23_max': 4.0,\n",
       " 'S_23_std': 2.0,\n",
       " 'S_23_last': 9.0,\n",
       " 'S_23_change': 3.0,\n",
       " 'S_24_max': 6.0,\n",
       " 'S_24_median': 3.0,\n",
       " 'S_24_std': 1.0,\n",
       " 'S_24_last': 1.0,\n",
       " 'S_25_max': 1.0,\n",
       " 'S_25_std': 4.0,\n",
       " 'S_25_last': 1.0,\n",
       " 'S_25_change': 1.0,\n",
       " 'S_26_min': 1.0,\n",
       " 'S_26_max': 3.0,\n",
       " 'S_26_median': 7.0,\n",
       " 'S_26_std': 4.0,\n",
       " 'S_26_change': 1.0,\n",
       " 'D_102_max': 4.0,\n",
       " 'D_102_median': 2.0,\n",
       " 'D_102_last': 1.0,\n",
       " 'D_102_change': 2.0,\n",
       " 'D_103_max': 1.0,\n",
       " 'D_103_std': 1.0,\n",
       " 'D_103_last': 1.0,\n",
       " 'D_105_median': 1.0,\n",
       " 'D_105_std': 1.0,\n",
       " 'D_106_median': 1.0,\n",
       " 'D_107_std': 1.0,\n",
       " 'D_107_last': 1.0,\n",
       " 'B_36_min': 4.0,\n",
       " 'B_36_max': 1.0,\n",
       " 'B_36_median': 6.0,\n",
       " 'B_36_std': 4.0,\n",
       " 'B_36_change': 2.0,\n",
       " 'B_37_min': 3.0,\n",
       " 'B_37_max': 1.0,\n",
       " 'B_37_median': 2.0,\n",
       " 'B_37_last': 13.0,\n",
       " 'R_26_min': 3.0,\n",
       " 'R_26_max': 1.0,\n",
       " 'R_26_std': 2.0,\n",
       " 'R_27_min': 2.0,\n",
       " 'R_27_max': 2.0,\n",
       " 'R_27_median': 4.0,\n",
       " 'R_27_last': 3.0,\n",
       " 'D_110_min': 1.0,\n",
       " 'D_111_median': 1.0,\n",
       " 'D_111_std': 1.0,\n",
       " 'D_111_last': 1.0,\n",
       " 'B_39_last': 1.0,\n",
       " 'D_112_min': 3.0,\n",
       " 'D_112_last': 2.0,\n",
       " 'D_112_change': 4.0,\n",
       " 'B_40_min': 3.0,\n",
       " 'B_40_max': 7.0,\n",
       " 'B_40_median': 2.0,\n",
       " 'B_40_std': 3.0,\n",
       " 'B_40_change': 1.0,\n",
       " 'S_27_min': 2.0,\n",
       " 'S_27_change': 2.0,\n",
       " 'D_113_min': 1.0,\n",
       " 'D_113_std': 1.0,\n",
       " 'D_113_change': 1.0,\n",
       " 'D_115_min': 1.0,\n",
       " 'D_115_max': 1.0,\n",
       " 'D_115_last': 1.0,\n",
       " 'D_118_min': 1.0,\n",
       " 'D_118_median': 2.0,\n",
       " 'D_118_std': 2.0,\n",
       " 'D_118_last': 2.0,\n",
       " 'D_119_max': 1.0,\n",
       " 'D_119_median': 1.0,\n",
       " 'D_119_last': 1.0,\n",
       " 'D_121_min': 2.0,\n",
       " 'D_121_max': 1.0,\n",
       " 'D_121_median': 1.0,\n",
       " 'D_121_last': 2.0,\n",
       " 'D_121_change': 1.0,\n",
       " 'D_122_max': 1.0,\n",
       " 'D_123_min': 1.0,\n",
       " 'D_123_last': 1.0,\n",
       " 'D_124_min': 10.0,\n",
       " 'D_124_last': 4.0,\n",
       " 'D_125_median': 2.0,\n",
       " 'D_125_std': 2.0,\n",
       " 'D_127_max': 1.0,\n",
       " 'D_127_std': 2.0,\n",
       " 'D_127_change': 1.0,\n",
       " 'D_128_min': 2.0,\n",
       " 'D_128_max': 1.0,\n",
       " 'D_128_median': 1.0,\n",
       " 'D_128_std': 1.0,\n",
       " 'D_128_last': 3.0,\n",
       " 'D_129_min': 4.0,\n",
       " 'D_129_max': 5.0,\n",
       " 'D_129_median': 2.0,\n",
       " 'D_129_last': 4.0,\n",
       " 'B_41_median': 1.0,\n",
       " 'B_41_std': 1.0,\n",
       " 'B_41_last': 2.0,\n",
       " 'D_130_min': 3.0,\n",
       " 'D_130_median': 2.0,\n",
       " 'D_130_last': 5.0,\n",
       " 'D_131_median': 1.0,\n",
       " 'D_131_last': 3.0,\n",
       " 'D_132_median': 1.0,\n",
       " 'D_132_std': 1.0,\n",
       " 'D_132_last': 5.0,\n",
       " 'D_133_min': 1.0,\n",
       " 'D_133_median': 1.0,\n",
       " 'D_133_last': 2.0,\n",
       " 'D_133_change': 1.0,\n",
       " 'R_28_max': 4.0,\n",
       " 'R_28_std': 1.0,\n",
       " 'R_28_change': 1.0,\n",
       " 'D_136_change': 2.0,\n",
       " 'D_137_last': 1.0,\n",
       " 'D_139_min': 2.0,\n",
       " 'D_139_max': 1.0,\n",
       " 'D_139_median': 1.0,\n",
       " 'D_139_std': 1.0,\n",
       " 'D_139_change': 1.0,\n",
       " 'D_140_min': 2.0,\n",
       " 'D_140_max': 1.0,\n",
       " 'D_140_median': 1.0,\n",
       " 'D_140_std': 1.0,\n",
       " 'D_140_last': 1.0,\n",
       " 'D_140_change': 1.0,\n",
       " 'D_141_median': 1.0,\n",
       " 'D_142_min': 1.0,\n",
       " 'D_142_median': 1.0,\n",
       " 'D_142_std': 1.0,\n",
       " 'D_142_change': 1.0,\n",
       " 'D_143_min': 1.0,\n",
       " 'D_143_std': 2.0,\n",
       " 'D_143_last': 1.0,\n",
       " 'D_143_change': 1.0,\n",
       " 'D_144_min': 1.0,\n",
       " 'D_144_median': 1.0,\n",
       " 'D_144_last': 1.0,\n",
       " 'D_144_change': 4.0,\n",
       " 'D_145_min': 1.0,\n",
       " 'D_145_std': 1.0,\n",
       " 'D_145_last': 1.0,\n",
       " 'D_145_change': 1.0,\n",
       " 'D_120': 1.0,\n",
       " 'D_66': 4.0,\n",
       " 'D_63_CO': 1.0,\n",
       " 'D_64_O': 3.0,\n",
       " 'S_3_nulls': 2.0,\n",
       " 'D_42_nulls': 1.0,\n",
       " 'D_49_nulls': 1.0,\n",
       " 'D_56_nulls': 1.0,\n",
       " 'B_29_nulls': 1.0,\n",
       " 'D_106_nulls': 2.0,\n",
       " 'R_26_nulls': 4.0,\n",
       " 'R_27_nulls': 3.0,\n",
       " 'D_137_nulls': 1.0}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model8.get_score(importance_type='weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8cca6d",
   "metadata": {},
   "source": [
    "The result is a dictionary. I use the dictionary to create a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ec71f9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model8_performance = pd.DataFrame([model8.get_score(importance_type='weight')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba71f14b",
   "metadata": {},
   "source": [
    "The resulting dataframe has a column for each feature and one row containing all the weights. I transpose the dataframe to get all weights in one column, allowing for easier sorting and investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fc88fe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model8_performance = model8_performance.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2f2a26",
   "metadata": {},
   "source": [
    "The documentation says that zero-importance features are not included in the model score (in this case, any feature that was not involved in a single split decision). I will look at the shape of my dataframe to see how many features are considered relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7111ee57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(619, 1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model8_performance.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285a5d78",
   "metadata": {},
   "source": [
    "I started the training process with over 1200 features in my dataframe. It looks like half of those are relevant to the problem at hand. I can potentially trim the number of features I pass into my model to speed up training and improve results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b882ad07",
   "metadata": {},
   "outputs": [],
   "source": [
    "model8_performance.rename(columns={0: 'weight'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ced213",
   "metadata": {},
   "source": [
    "This is great, but I would prefer to build a dataframe containing all available evaluation metrics for feature performance: weight, gain, cover, total_gain, and total_cover. Gain is considered to be the best metric to judge feature performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "db17da43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>weight</th>\n",
       "      <th>gain</th>\n",
       "      <th>cover</th>\n",
       "      <th>total_gain</th>\n",
       "      <th>total_cover</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P_2_min</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1046.174927</td>\n",
       "      <td>3564.391602</td>\n",
       "      <td>25108.199219</td>\n",
       "      <td>85545.398438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P_2_max</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.868271</td>\n",
       "      <td>1446.203491</td>\n",
       "      <td>50.604813</td>\n",
       "      <td>4338.610352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P_2_median</td>\n",
       "      <td>14.0</td>\n",
       "      <td>378.496765</td>\n",
       "      <td>2358.535889</td>\n",
       "      <td>5298.954590</td>\n",
       "      <td>33019.503906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P_2_std</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.919077</td>\n",
       "      <td>131.254517</td>\n",
       "      <td>10.919077</td>\n",
       "      <td>131.254517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P_2_last</td>\n",
       "      <td>57.0</td>\n",
       "      <td>606.084595</td>\n",
       "      <td>2461.301758</td>\n",
       "      <td>34546.820312</td>\n",
       "      <td>140294.203125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0  weight         gain        cover    total_gain    total_cover\n",
       "0     P_2_min    24.0  1046.174927  3564.391602  25108.199219   85545.398438\n",
       "1     P_2_max     3.0    16.868271  1446.203491     50.604813    4338.610352\n",
       "2  P_2_median    14.0   378.496765  2358.535889   5298.954590   33019.503906\n",
       "3     P_2_std     1.0    10.919077   131.254517     10.919077     131.254517\n",
       "4    P_2_last    57.0   606.084595  2461.301758  34546.820312  140294.203125"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_columns = ['weight', 'gain', 'cover', 'total_gain', 'total_cover']\n",
    "\n",
    "model8_scores = pd.DataFrame()\n",
    "\n",
    "for col in score_columns:\n",
    "    model8_scores[col] = model8.get_score(importance_type=col).values()\n",
    "    \n",
    "my_index = pd.DataFrame(list(model8.get_score(importance_type='weight').keys()))\n",
    "model8_scores = pd.concat([my_index, model8_scores], axis=1)\n",
    "model8_scores.head()   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e513d07",
   "metadata": {},
   "source": [
    "I need to set the index as the feature name and I'm good to go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0f84d049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "      <th>gain</th>\n",
       "      <th>cover</th>\n",
       "      <th>total_gain</th>\n",
       "      <th>total_cover</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P_2_min</th>\n",
       "      <td>24.0</td>\n",
       "      <td>1046.174927</td>\n",
       "      <td>3564.391602</td>\n",
       "      <td>25108.199219</td>\n",
       "      <td>85545.398438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_2_max</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16.868271</td>\n",
       "      <td>1446.203491</td>\n",
       "      <td>50.604813</td>\n",
       "      <td>4338.610352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_2_median</th>\n",
       "      <td>14.0</td>\n",
       "      <td>378.496765</td>\n",
       "      <td>2358.535889</td>\n",
       "      <td>5298.954590</td>\n",
       "      <td>33019.503906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_2_std</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.919077</td>\n",
       "      <td>131.254517</td>\n",
       "      <td>10.919077</td>\n",
       "      <td>131.254517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_2_last</th>\n",
       "      <td>57.0</td>\n",
       "      <td>606.084595</td>\n",
       "      <td>2461.301758</td>\n",
       "      <td>34546.820312</td>\n",
       "      <td>140294.203125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            weight         gain        cover    total_gain    total_cover\n",
       "0                                                                        \n",
       "P_2_min       24.0  1046.174927  3564.391602  25108.199219   85545.398438\n",
       "P_2_max        3.0    16.868271  1446.203491     50.604813    4338.610352\n",
       "P_2_median    14.0   378.496765  2358.535889   5298.954590   33019.503906\n",
       "P_2_std        1.0    10.919077   131.254517     10.919077     131.254517\n",
       "P_2_last      57.0   606.084595  2461.301758  34546.820312  140294.203125"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model8_scores.set_index(0, inplace=True)\n",
    "model8_scores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887528be",
   "metadata": {},
   "source": [
    "I will save a copy of this dataframe to analyze my best-performing features and determine if I can drop some original features from my data entirely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "968195d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model8_scores.to_csv('model8_feature_scores.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a875054d",
   "metadata": {},
   "source": [
    "I want to take a look at the features that provided the greatest gain to my model. Gain describes how greatly the accuracy of the model was improved by the addition the feature to the tree. Features with high gain are doing the best job minimizing the error of trees. Gain seems to represent the greatest positive impact offered by each feature to one tree, while total gain represents the benefit offered to the entire ensemble by the feature. I will look at the top performers in both categories to get a decent picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cbc29f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "      <th>gain</th>\n",
       "      <th>cover</th>\n",
       "      <th>total_gain</th>\n",
       "      <th>total_cover</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B_9_last</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1930.199829</td>\n",
       "      <td>4813.571289</td>\n",
       "      <td>9650.999023</td>\n",
       "      <td>24067.855469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_9_max</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1725.645752</td>\n",
       "      <td>3515.094238</td>\n",
       "      <td>6902.583008</td>\n",
       "      <td>14060.376953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_18_last</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1508.544678</td>\n",
       "      <td>3608.366699</td>\n",
       "      <td>6034.178711</td>\n",
       "      <td>14433.466797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_75_last</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1304.041016</td>\n",
       "      <td>5534.000000</td>\n",
       "      <td>1304.041016</td>\n",
       "      <td>5534.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_2_min</th>\n",
       "      <td>24.0</td>\n",
       "      <td>1046.174927</td>\n",
       "      <td>3564.391602</td>\n",
       "      <td>25108.199219</td>\n",
       "      <td>85545.398438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_1_std</th>\n",
       "      <td>5.0</td>\n",
       "      <td>808.695923</td>\n",
       "      <td>2965.106934</td>\n",
       "      <td>4043.479492</td>\n",
       "      <td>14825.535156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_2_last</th>\n",
       "      <td>57.0</td>\n",
       "      <td>606.084595</td>\n",
       "      <td>2461.301758</td>\n",
       "      <td>34546.820312</td>\n",
       "      <td>140294.203125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_44_last</th>\n",
       "      <td>4.0</td>\n",
       "      <td>549.951538</td>\n",
       "      <td>3008.229980</td>\n",
       "      <td>2199.806152</td>\n",
       "      <td>12032.919922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_2_median</th>\n",
       "      <td>14.0</td>\n",
       "      <td>378.496765</td>\n",
       "      <td>2358.535889</td>\n",
       "      <td>5298.954590</td>\n",
       "      <td>33019.503906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_2_change</th>\n",
       "      <td>4.0</td>\n",
       "      <td>349.812317</td>\n",
       "      <td>2365.248535</td>\n",
       "      <td>1399.249268</td>\n",
       "      <td>9460.994141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_7_last</th>\n",
       "      <td>13.0</td>\n",
       "      <td>271.518860</td>\n",
       "      <td>1980.896606</td>\n",
       "      <td>3529.745361</td>\n",
       "      <td>25751.656250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_1_max</th>\n",
       "      <td>8.0</td>\n",
       "      <td>269.742157</td>\n",
       "      <td>1694.713745</td>\n",
       "      <td>2157.937256</td>\n",
       "      <td>13557.709961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_7_median</th>\n",
       "      <td>2.0</td>\n",
       "      <td>229.943619</td>\n",
       "      <td>2272.567383</td>\n",
       "      <td>459.887238</td>\n",
       "      <td>4545.134766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_7_max</th>\n",
       "      <td>4.0</td>\n",
       "      <td>207.338272</td>\n",
       "      <td>2007.090698</td>\n",
       "      <td>829.353088</td>\n",
       "      <td>8028.362793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_1_last</th>\n",
       "      <td>11.0</td>\n",
       "      <td>192.225342</td>\n",
       "      <td>2360.121094</td>\n",
       "      <td>2114.478760</td>\n",
       "      <td>25961.332031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S_13_min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>175.942993</td>\n",
       "      <td>945.750000</td>\n",
       "      <td>175.942993</td>\n",
       "      <td>945.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_1_last</th>\n",
       "      <td>14.0</td>\n",
       "      <td>175.890549</td>\n",
       "      <td>1989.841919</td>\n",
       "      <td>2462.467773</td>\n",
       "      <td>27857.787109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_2_last</th>\n",
       "      <td>15.0</td>\n",
       "      <td>175.641174</td>\n",
       "      <td>1758.774048</td>\n",
       "      <td>2634.617676</td>\n",
       "      <td>26381.611328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_3_median</th>\n",
       "      <td>8.0</td>\n",
       "      <td>172.600433</td>\n",
       "      <td>1712.722290</td>\n",
       "      <td>1380.803467</td>\n",
       "      <td>13701.778320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_1_change</th>\n",
       "      <td>2.0</td>\n",
       "      <td>170.654694</td>\n",
       "      <td>1151.052124</td>\n",
       "      <td>341.309387</td>\n",
       "      <td>2302.104248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_41_last</th>\n",
       "      <td>11.0</td>\n",
       "      <td>150.026077</td>\n",
       "      <td>1437.614136</td>\n",
       "      <td>1650.286865</td>\n",
       "      <td>15813.754883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_37_last</th>\n",
       "      <td>13.0</td>\n",
       "      <td>140.837097</td>\n",
       "      <td>1767.360840</td>\n",
       "      <td>1830.882202</td>\n",
       "      <td>22975.691406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_65_change</th>\n",
       "      <td>1.0</td>\n",
       "      <td>136.768005</td>\n",
       "      <td>1421.588989</td>\n",
       "      <td>136.768005</td>\n",
       "      <td>1421.588989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_75_change</th>\n",
       "      <td>1.0</td>\n",
       "      <td>131.770508</td>\n",
       "      <td>3275.305908</td>\n",
       "      <td>131.770508</td>\n",
       "      <td>3275.305908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S_3_std</th>\n",
       "      <td>2.0</td>\n",
       "      <td>127.934097</td>\n",
       "      <td>2377.590088</td>\n",
       "      <td>255.868195</td>\n",
       "      <td>4755.180176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             weight         gain        cover    total_gain    total_cover\n",
       "0                                                                         \n",
       "B_9_last        5.0  1930.199829  4813.571289   9650.999023   24067.855469\n",
       "B_9_max         4.0  1725.645752  3515.094238   6902.583008   14060.376953\n",
       "B_18_last       4.0  1508.544678  3608.366699   6034.178711   14433.466797\n",
       "D_75_last       1.0  1304.041016  5534.000000   1304.041016    5534.000000\n",
       "P_2_min        24.0  1046.174927  3564.391602  25108.199219   85545.398438\n",
       "R_1_std         5.0   808.695923  2965.106934   4043.479492   14825.535156\n",
       "P_2_last       57.0   606.084595  2461.301758  34546.820312  140294.203125\n",
       "D_44_last       4.0   549.951538  3008.229980   2199.806152   12032.919922\n",
       "P_2_median     14.0   378.496765  2358.535889   5298.954590   33019.503906\n",
       "P_2_change      4.0   349.812317  2365.248535   1399.249268    9460.994141\n",
       "B_7_last       13.0   271.518860  1980.896606   3529.745361   25751.656250\n",
       "R_1_max         8.0   269.742157  1694.713745   2157.937256   13557.709961\n",
       "B_7_median      2.0   229.943619  2272.567383    459.887238    4545.134766\n",
       "B_7_max         4.0   207.338272  2007.090698    829.353088    8028.362793\n",
       "R_1_last       11.0   192.225342  2360.121094   2114.478760   25961.332031\n",
       "S_13_min        1.0   175.942993   945.750000    175.942993     945.750000\n",
       "B_1_last       14.0   175.890549  1989.841919   2462.467773   27857.787109\n",
       "B_2_last       15.0   175.641174  1758.774048   2634.617676   26381.611328\n",
       "R_3_median      8.0   172.600433  1712.722290   1380.803467   13701.778320\n",
       "R_1_change      2.0   170.654694  1151.052124    341.309387    2302.104248\n",
       "D_41_last      11.0   150.026077  1437.614136   1650.286865   15813.754883\n",
       "B_37_last      13.0   140.837097  1767.360840   1830.882202   22975.691406\n",
       "D_65_change     1.0   136.768005  1421.588989    136.768005    1421.588989\n",
       "D_75_change     1.0   131.770508  3275.305908    131.770508    3275.305908\n",
       "S_3_std         2.0   127.934097  2377.590088    255.868195    4755.180176"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model8_scores.sort_values('gain', ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "048e4e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "      <th>gain</th>\n",
       "      <th>cover</th>\n",
       "      <th>total_gain</th>\n",
       "      <th>total_cover</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P_2_last</th>\n",
       "      <td>57.0</td>\n",
       "      <td>606.084595</td>\n",
       "      <td>2461.301758</td>\n",
       "      <td>34546.820312</td>\n",
       "      <td>140294.203125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_2_min</th>\n",
       "      <td>24.0</td>\n",
       "      <td>1046.174927</td>\n",
       "      <td>3564.391602</td>\n",
       "      <td>25108.199219</td>\n",
       "      <td>85545.398438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_9_last</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1930.199829</td>\n",
       "      <td>4813.571289</td>\n",
       "      <td>9650.999023</td>\n",
       "      <td>24067.855469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_9_max</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1725.645752</td>\n",
       "      <td>3515.094238</td>\n",
       "      <td>6902.583008</td>\n",
       "      <td>14060.376953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_18_last</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1508.544678</td>\n",
       "      <td>3608.366699</td>\n",
       "      <td>6034.178711</td>\n",
       "      <td>14433.466797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_2_median</th>\n",
       "      <td>14.0</td>\n",
       "      <td>378.496765</td>\n",
       "      <td>2358.535889</td>\n",
       "      <td>5298.954590</td>\n",
       "      <td>33019.503906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_1_std</th>\n",
       "      <td>5.0</td>\n",
       "      <td>808.695923</td>\n",
       "      <td>2965.106934</td>\n",
       "      <td>4043.479492</td>\n",
       "      <td>14825.535156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_7_last</th>\n",
       "      <td>13.0</td>\n",
       "      <td>271.518860</td>\n",
       "      <td>1980.896606</td>\n",
       "      <td>3529.745361</td>\n",
       "      <td>25751.656250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_2_last</th>\n",
       "      <td>15.0</td>\n",
       "      <td>175.641174</td>\n",
       "      <td>1758.774048</td>\n",
       "      <td>2634.617676</td>\n",
       "      <td>26381.611328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_1_last</th>\n",
       "      <td>14.0</td>\n",
       "      <td>175.890549</td>\n",
       "      <td>1989.841919</td>\n",
       "      <td>2462.467773</td>\n",
       "      <td>27857.787109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_4_change</th>\n",
       "      <td>18.0</td>\n",
       "      <td>125.491646</td>\n",
       "      <td>1724.065063</td>\n",
       "      <td>2258.849609</td>\n",
       "      <td>31033.171875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_44_last</th>\n",
       "      <td>4.0</td>\n",
       "      <td>549.951538</td>\n",
       "      <td>3008.229980</td>\n",
       "      <td>2199.806152</td>\n",
       "      <td>12032.919922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_1_max</th>\n",
       "      <td>8.0</td>\n",
       "      <td>269.742157</td>\n",
       "      <td>1694.713745</td>\n",
       "      <td>2157.937256</td>\n",
       "      <td>13557.709961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_1_last</th>\n",
       "      <td>11.0</td>\n",
       "      <td>192.225342</td>\n",
       "      <td>2360.121094</td>\n",
       "      <td>2114.478760</td>\n",
       "      <td>25961.332031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_39_last</th>\n",
       "      <td>32.0</td>\n",
       "      <td>59.507698</td>\n",
       "      <td>1719.172485</td>\n",
       "      <td>1904.246338</td>\n",
       "      <td>55013.519531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_3_last</th>\n",
       "      <td>17.0</td>\n",
       "      <td>110.655365</td>\n",
       "      <td>2401.634277</td>\n",
       "      <td>1881.141235</td>\n",
       "      <td>40827.781250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_37_last</th>\n",
       "      <td>13.0</td>\n",
       "      <td>140.837097</td>\n",
       "      <td>1767.360840</td>\n",
       "      <td>1830.882202</td>\n",
       "      <td>22975.691406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_41_last</th>\n",
       "      <td>11.0</td>\n",
       "      <td>150.026077</td>\n",
       "      <td>1437.614136</td>\n",
       "      <td>1650.286865</td>\n",
       "      <td>15813.754883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_41_change</th>\n",
       "      <td>14.0</td>\n",
       "      <td>104.835693</td>\n",
       "      <td>1227.333618</td>\n",
       "      <td>1467.699707</td>\n",
       "      <td>17182.669922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_2_change</th>\n",
       "      <td>4.0</td>\n",
       "      <td>349.812317</td>\n",
       "      <td>2365.248535</td>\n",
       "      <td>1399.249268</td>\n",
       "      <td>9460.994141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_3_median</th>\n",
       "      <td>8.0</td>\n",
       "      <td>172.600433</td>\n",
       "      <td>1712.722290</td>\n",
       "      <td>1380.803467</td>\n",
       "      <td>13701.778320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_75_last</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1304.041016</td>\n",
       "      <td>5534.000000</td>\n",
       "      <td>1304.041016</td>\n",
       "      <td>5534.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_3_last</th>\n",
       "      <td>19.0</td>\n",
       "      <td>57.192883</td>\n",
       "      <td>1959.286377</td>\n",
       "      <td>1086.664795</td>\n",
       "      <td>37226.441406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_3_change</th>\n",
       "      <td>10.0</td>\n",
       "      <td>107.841873</td>\n",
       "      <td>1894.614624</td>\n",
       "      <td>1078.418701</td>\n",
       "      <td>18946.146484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_11_last</th>\n",
       "      <td>12.0</td>\n",
       "      <td>87.696930</td>\n",
       "      <td>1694.177856</td>\n",
       "      <td>1052.363159</td>\n",
       "      <td>20330.134766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             weight         gain        cover    total_gain    total_cover\n",
       "0                                                                         \n",
       "P_2_last       57.0   606.084595  2461.301758  34546.820312  140294.203125\n",
       "P_2_min        24.0  1046.174927  3564.391602  25108.199219   85545.398438\n",
       "B_9_last        5.0  1930.199829  4813.571289   9650.999023   24067.855469\n",
       "B_9_max         4.0  1725.645752  3515.094238   6902.583008   14060.376953\n",
       "B_18_last       4.0  1508.544678  3608.366699   6034.178711   14433.466797\n",
       "P_2_median     14.0   378.496765  2358.535889   5298.954590   33019.503906\n",
       "R_1_std         5.0   808.695923  2965.106934   4043.479492   14825.535156\n",
       "B_7_last       13.0   271.518860  1980.896606   3529.745361   25751.656250\n",
       "B_2_last       15.0   175.641174  1758.774048   2634.617676   26381.611328\n",
       "B_1_last       14.0   175.890549  1989.841919   2462.467773   27857.787109\n",
       "B_4_change     18.0   125.491646  1724.065063   2258.849609   31033.171875\n",
       "D_44_last       4.0   549.951538  3008.229980   2199.806152   12032.919922\n",
       "R_1_max         8.0   269.742157  1694.713745   2157.937256   13557.709961\n",
       "R_1_last       11.0   192.225342  2360.121094   2114.478760   25961.332031\n",
       "D_39_last      32.0    59.507698  1719.172485   1904.246338   55013.519531\n",
       "B_3_last       17.0   110.655365  2401.634277   1881.141235   40827.781250\n",
       "B_37_last      13.0   140.837097  1767.360840   1830.882202   22975.691406\n",
       "D_41_last      11.0   150.026077  1437.614136   1650.286865   15813.754883\n",
       "D_41_change    14.0   104.835693  1227.333618   1467.699707   17182.669922\n",
       "P_2_change      4.0   349.812317  2365.248535   1399.249268    9460.994141\n",
       "R_3_median      8.0   172.600433  1712.722290   1380.803467   13701.778320\n",
       "D_75_last       1.0  1304.041016  5534.000000   1304.041016    5534.000000\n",
       "R_3_last       19.0    57.192883  1959.286377   1086.664795   37226.441406\n",
       "B_3_change     10.0   107.841873  1894.614624   1078.418701   18946.146484\n",
       "B_11_last      12.0    87.696930  1694.177856   1052.363159   20330.134766"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model8_scores.sort_values('total_gain', ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b785f5fa",
   "metadata": {},
   "source": [
    "There is a considerable amount of overlap between the top performers in gain and total_gain. There are a couple odd cases in the gain table, where a few features have a top gain that's equal to their total gain. In these cases, their weight is one, which means these features were only used once in the whole ensemble to make an impactful split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fd50ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
