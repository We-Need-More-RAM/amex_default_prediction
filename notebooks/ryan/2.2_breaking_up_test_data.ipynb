{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a382c3aa-242f-4247-b95a-8630b8a56686",
   "metadata": {},
   "source": [
    "# Breaking up the Test Data File\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6e43fdb-205b-4ef1-9c7d-b8bd9f53beb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f34026-7e4b-4da8-b34b-2bb53f5377b3",
   "metadata": {},
   "source": [
    "## Break up time (It's not you, it's me)\n",
    "\n",
    "Looking at the kaggle data summary, this dataset has 11.4 million rows and is around 33 gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62231bf8-5b3c-449d-997b-c1fcbc94cd86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "345454.54545454547"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11_400_000 / 33"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5faa371-4f2c-4a16-b236-b80102b9615e",
   "metadata": {},
   "source": [
    "So if we want to chunk this into about 1gb chunks we will need to make chunksize around 350,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dc1ca6f-47b7-4fd0-8584-32218f38ed1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "for i,chunk in enumerate(pd.read_csv('data/test_data.csv', chunksize=350000)):\n",
    "    print(i)\n",
    "    chunk.to_csv('data/chunked/test_data_chunk{}.csv'.format(i), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "211c8efb-11b5-49d7-84ee-b5a4d1c21495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started file 0 at 2022-08-17 09:41:19.777774\n",
      "Started file 1 at 2022-08-17 09:41:30.905831\n",
      "Started file 2 at 2022-08-17 09:42:58.691209\n",
      "Started file 3 at 2022-08-17 09:44:26.142181\n",
      "Started file 4 at 2022-08-17 09:45:52.128740\n",
      "Started file 5 at 2022-08-17 09:46:02.927835\n",
      "Started file 6 at 2022-08-17 09:47:30.180244\n",
      "Started file 7 at 2022-08-17 09:48:57.325892\n",
      "Started file 8 at 2022-08-17 09:50:24.871182\n",
      "Started file 9 at 2022-08-17 09:51:52.373662\n",
      "Started file 10 at 2022-08-17 09:53:19.381998\n",
      "Started file 11 at 2022-08-17 09:54:46.954355\n",
      "Started file 12 at 2022-08-17 09:56:14.381402\n",
      "Started file 13 at 2022-08-17 09:57:41.050203\n",
      "Started file 14 at 2022-08-17 09:59:05.632900\n",
      "Started file 15 at 2022-08-17 10:00:28.798686\n",
      "Started file 16 at 2022-08-17 10:01:52.691871\n",
      "Started file 17 at 2022-08-17 10:03:15.958049\n",
      "Started file 18 at 2022-08-17 10:04:40.532151\n",
      "Started file 19 at 2022-08-17 10:06:05.502387\n",
      "Started file 20 at 2022-08-17 10:07:30.517332\n",
      "Started file 21 at 2022-08-17 10:08:55.569472\n",
      "Started file 22 at 2022-08-17 10:10:21.062184\n",
      "Started file 23 at 2022-08-17 10:11:44.951493\n",
      "Started file 24 at 2022-08-17 10:13:08.314868\n",
      "Started file 25 at 2022-08-17 10:14:33.424242\n",
      "Started file 26 at 2022-08-17 10:15:57.339218\n",
      "Started file 27 at 2022-08-17 10:17:23.094435\n",
      "Started file 28 at 2022-08-17 10:18:52.588290\n",
      "Started file 29 at 2022-08-17 10:20:22.215633\n",
      "Started file 30 at 2022-08-17 10:21:50.657168\n",
      "Started file 31 at 2022-08-17 10:23:20.696942\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 32):\n",
    "    print(f'Started file {i} at {datetime.now()}')\n",
    "    \n",
    "    df1 = pd.read_csv(f'data/chunked/test_data_chunk{i}.csv')\n",
    "    df2 = pd.read_csv(f'data/chunked/test_data_chunk{i+1}.csv')\n",
    "    \n",
    "    df1_last_id = df1.customer_ID.values[-1]\n",
    "    df2_first_id = df2.customer_ID.values[0]\n",
    "    \n",
    "    if df1_last_id == df2_first_id:\n",
    "        df2_first_id_df = df2[df2.customer_ID == df2_first_id]\n",
    "        \n",
    "        df2 = df2[df2.customer_ID != df2_first_id]\n",
    "        \n",
    "        df1 = pd.concat([df1, df2_first_id_df], ignore_index=True)\n",
    "        \n",
    "        df1.to_csv(f'data/chunked/test_data_chunk{i}.csv')\n",
    "        df2.to_csv(f'data/chunked/test_data_chunk{i+1}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a5ca93-1e69-4bed-94c8-e250aad1bea5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
