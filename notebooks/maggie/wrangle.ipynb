{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a966379c",
   "metadata": {},
   "source": [
    "Acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a149860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pandas.core.window.ewm import ExponentialMovingWindow as emw\n",
    "\n",
    "import wrangle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78dd06fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df, y_df = wrangle.acquire_amex(sample_size=200000)\n",
    "X_df = wrangle.clean_amex(X_df)\n",
    "# wrangle.split_amex(X_df, y_df, train_size=.5, test_size=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2aa5ae",
   "metadata": {},
   "source": [
    "Summarize/Verify data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b80ce9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.741066\n",
       "1    0.258934\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df.target.value_counts(normalize=True)\n",
    "\n",
    "# print('Train: %d rows, %d cols' % y_train.shape)\n",
    "# print('Validate: %d rows, %d cols' % y_validate.shape)\n",
    "# print('Test: %d rows, %d cols' % y_validate.shape)\n",
    "\n",
    "# print('Train: %d rows, %d cols' % X_train.shape)\n",
    "# print('Validate: %d rows, %d cols' % X_validate.shape)\n",
    "# print('Test: %d rows, %d cols' % X_test.shape)\n",
    "\n",
    "# y_df.target.value_counts(normalize=True)\n",
    "\n",
    "# y_train.target.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d12f43",
   "metadata": {},
   "source": [
    "Flatten the time series data. \n",
    "\n",
    "For each variable, we need to create the following:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5f4dc9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_df.reset_index(drop=True).set_index(['S_2'])\n",
    "\n",
    "df = X_df[(X_df.customer_ID == \n",
    "               X_df.customer_ID[0])|(X_df.customer_ID == X_df.customer_ID[15])\n",
    "         ][['customer_ID','P_2','R_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "384c4572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collapse_columns(df):\n",
    "    df = df.copy()\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        df.columns = df.columns.to_series().apply(lambda x: \"_\".join(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0fc8ce",
   "metadata": {},
   "source": [
    "Slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d72b8185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slope(df):\n",
    "    slope = df.groupby('customer_ID').agg(lambda x: np.polyfit(df.index, x, 1)[0][0])\n",
    "    slope.columns = [x + '_slope' for x in slope.columns.remove('customer_ID')]\n",
    "    return slope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d22b8a",
   "metadata": {},
   "source": [
    "Correlation Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "44742fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corr_coeff(df):\n",
    "    r = df.groupby('customer_ID').agg(lambda x: np.corrcoef(df.index, x, rowvar=False)[0][1])\n",
    "    r.columns = [x + '_r' for x in r.columns]\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bad05b",
   "metadata": {},
   "source": [
    "Count number of missing values in the set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5ee85df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_null_count(df):\n",
    "    missing_vals = df.groupby('customer_ID').agg(lambda x: x.isnull().sum())\n",
    "    missing_vals.columns = [x + '_nulls' for x in missing_vals.columns]\n",
    "    return missing_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f1470f",
   "metadata": {},
   "source": [
    "Compute number of 0 values in the set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "16bfda82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zeros(df):\n",
    "    zeros = df.groupby('customer_ID').agg(lambda x: (x == 0.0).sum())\n",
    "    zeros.columns = [x + '_zeros' for x in zeros.columns]\n",
    "    return zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83660fc6",
   "metadata": {},
   "source": [
    "Compute coefficient of variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1ce40374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv(df):\n",
    "    cv = df.groupby('customer_ID').agg(lambda x: x.std()/x.mean())\n",
    "    cv.columns = [x + '_cv' for x in cv.columns]\n",
    "    return cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6952bea3",
   "metadata": {},
   "source": [
    "Get the change in value over every 2 periods. Use that information to gather:\n",
    "\n",
    "1. the current value (delta_value)\n",
    "2. the number of values over time that are less than 0 (neg_delta_count)\n",
    "3. the current 6 period moving average of the delta_values (delta_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "be4eee0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference(df):\n",
    "    delta = df.groupby('customer_ID').diff(periods=2)\n",
    "    delta.index = sample.customer_ID\n",
    "    return delta\n",
    "\n",
    "def delta_vals(df):\n",
    "    # first compute the 2 period delta and create a dataframe with those values\n",
    "    delta = difference(df)\n",
    "    delta.columns = [x + '_diff' for x in delta.columns]\n",
    "    \n",
    "    # Use the delta df to take the last value as the current delta\n",
    "    delta_value = delta.groupby('customer_ID').last()\n",
    "    \n",
    "    # use the delta df to count the number of changes over customer history that were negative\n",
    "    neg_delta_count = delta.groupby('customer_ID').agg(lambda x: (x < 0).sum())\n",
    "    neg_delta_count.columns = [x + '_count' for x in delta.columns]\n",
    "    \n",
    "    # use the delta df to compute the rolling average of the delta values\n",
    "    delta_mean = delta.groupby('customer_ID').transform(lambda x: x.rolling(window=6, \n",
    "                                                                       min_periods=3, \n",
    "                                                                       closed='left').mean())\n",
    "    delta_mean.columns = [x + '_mean' for x in delta.columns]\n",
    "    \n",
    "    # take the last value, the current average of change\n",
    "    delta_mean = delta_mean.groupby('customer_ID').last()\n",
    "    \n",
    "    # concatenate the dataframes with the computed values by concatenating columns along the customer index\n",
    "    delta_df = pd.concat([delta_value, neg_delta_count, delta_mean], axis=1)\n",
    "    return delta_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8783b91b",
   "metadata": {},
   "source": [
    "Compute the exponentially weighted moving average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "978a8867",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ema(df):\n",
    "    ema = sample.groupby('customer_ID').transform(lambda x: x.ewm(alpha=.8,\n",
    "                                                                  min_periods=1, \n",
    "                                                                  adjust=True).mean().shift(periods=1))\n",
    "    ema.columns = [x + '_ema' for x in ema.columns]\n",
    "    ema.index = sample.customer_ID\n",
    "    ema = ema.groupby('customer_ID').last()\n",
    "    return ema\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e5d033",
   "metadata": {},
   "source": [
    "Compute the rolling standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "63121a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rolling standard deviation\n",
    "def rolling_std(df):\n",
    "    std = df.groupby('customer_ID').transform(lambda x: x.rolling(window=12, min_periods=1, closed='left').mean())\n",
    "    std.columns = [x + '_std' for x in std.columns]\n",
    "    std.index = df.customer_ID\n",
    "    std_df = std.groupby('customer_ID').last()\n",
    "    return std_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c260718",
   "metadata": {},
   "source": [
    "Compute rolling values. These will return a dataframe with a value for each row. I will need to take the last value. \n",
    "\n",
    "- exponentially weighted moving average (alpha = .8)\n",
    "- rolling standard deviation (12 periods)\n",
    "- Upper and lower bollinger bands\n",
    "- %b\n",
    "- bandwidth\n",
    "- period over period difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3313018c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pctb(df, k):\n",
    "    # set the index in sample to customer_id\n",
    "    sample_indexed = sample.set_index('customer_ID')\n",
    "    \n",
    "    # create an empty series\n",
    "    pctb_series = pd.Series()\n",
    "\n",
    "    # loop through original column names and for eacsh one, compute pctb\n",
    "    for x in sample_indexed.columns:\n",
    "        ubb = metrics_df[x + '_ema'] + k*metrics_df[x + '_std']\n",
    "        lbb = metrics_df[(x + '_ema')] - k*metrics_df[x + '_std']\n",
    "        pctb = (metrics_df[x + '_last'] - lbb) / (ubb - lbb)\n",
    "        pctb_series = pd.concat([pctb_series, pctb], axis=1)\n",
    "\n",
    "    pctb_df = pd.DataFrame(pctb_series)\n",
    "    pctb_df = pctb_df.iloc[:,1:]\n",
    "    pctb_df.columns = [x + '_%b' for x in sample_indexed.columns]\n",
    "    \n",
    "    return pctb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e0251783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_features(df, k):\n",
    "    sample_agg = df.groupby('customer_ID').agg(['last', 'min', 'max', 'median', 'count'])\n",
    "    sample_df = collapse_columns(sample_agg)\n",
    "#    slope_df = get_slope(df)\n",
    "#    r_df = get_corr_coeff(df)\n",
    "    missing_vals_df = get_null_count(df)\n",
    "    zero_df = get_zeros(df)\n",
    "    cv_df = cv(df)\n",
    "    delta_df = delta_vals(df)\n",
    "    ema_df = ema(df)\n",
    "    std_df = rolling_std(df)\n",
    "    metrics_df = pd.concat([sample_df, \n",
    "                            # slope_df, r_df, \n",
    "                            missing_vals_df, zero_df, cv_df, delta_df, ema_df, std_df],axis=1)\n",
    "    pctb_df = compute_pctb(df, k)\n",
    "    metrics_df = pd.concat([pctb_df, metrics_df], axis=1)\n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "68ddc74b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_2_%b</th>\n",
       "      <th>R_1_%b</th>\n",
       "      <th>P_2_last</th>\n",
       "      <th>P_2_min</th>\n",
       "      <th>P_2_max</th>\n",
       "      <th>P_2_median</th>\n",
       "      <th>P_2_count</th>\n",
       "      <th>R_1_last</th>\n",
       "      <th>R_1_min</th>\n",
       "      <th>R_1_max</th>\n",
       "      <th>...</th>\n",
       "      <th>P_2_diff</th>\n",
       "      <th>R_1_diff</th>\n",
       "      <th>P_2_diff_count</th>\n",
       "      <th>R_1_diff_count</th>\n",
       "      <th>P_2_diff_mean</th>\n",
       "      <th>R_1_diff_mean</th>\n",
       "      <th>P_2_ema</th>\n",
       "      <th>R_1_ema</th>\n",
       "      <th>P_2_std</th>\n",
       "      <th>R_1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fbac11a8ed792feb62a</th>\n",
       "      <td>0.500704</td>\n",
       "      <td>0.661504</td>\n",
       "      <td>0.934745</td>\n",
       "      <td>0.868580</td>\n",
       "      <td>0.960384</td>\n",
       "      <td>0.938469</td>\n",
       "      <td>13</td>\n",
       "      <td>0.006104</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.009228</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024933</td>\n",
       "      <td>-0.002072</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.007675</td>\n",
       "      <td>-0.000507</td>\n",
       "      <td>0.930801</td>\n",
       "      <td>0.001864</td>\n",
       "      <td>0.933747</td>\n",
       "      <td>0.004376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00000fd6641609c6ece5454664794f0340ad84dddce9a267a310b5ae68e9d8e5</th>\n",
       "      <td>0.500347</td>\n",
       "      <td>0.496987</td>\n",
       "      <td>0.880519</td>\n",
       "      <td>0.861109</td>\n",
       "      <td>0.929122</td>\n",
       "      <td>0.904814</td>\n",
       "      <td>13</td>\n",
       "      <td>0.006911</td>\n",
       "      <td>0.001023</td>\n",
       "      <td>0.008996</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000406</td>\n",
       "      <td>0.000956</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.008756</td>\n",
       "      <td>-0.000381</td>\n",
       "      <td>0.878641</td>\n",
       "      <td>0.007023</td>\n",
       "      <td>0.901428</td>\n",
       "      <td>0.006191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      P_2_%b    R_1_%b  \\\n",
       "0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fb...  0.500704  0.661504   \n",
       "00000fd6641609c6ece5454664794f0340ad84dddce9a26...  0.500347  0.496987   \n",
       "\n",
       "                                                    P_2_last   P_2_min  \\\n",
       "0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fb...  0.934745  0.868580   \n",
       "00000fd6641609c6ece5454664794f0340ad84dddce9a26...  0.880519  0.861109   \n",
       "\n",
       "                                                     P_2_max  P_2_median  \\\n",
       "0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fb...  0.960384    0.938469   \n",
       "00000fd6641609c6ece5454664794f0340ad84dddce9a26...  0.929122    0.904814   \n",
       "\n",
       "                                                    P_2_count  R_1_last  \\\n",
       "0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fb...         13  0.006104   \n",
       "00000fd6641609c6ece5454664794f0340ad84dddce9a26...         13  0.006911   \n",
       "\n",
       "                                                     R_1_min   R_1_max  ...  \\\n",
       "0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fb...  0.000263  0.009228  ...   \n",
       "00000fd6641609c6ece5454664794f0340ad84dddce9a26...  0.001023  0.008996  ...   \n",
       "\n",
       "                                                    P_2_diff  R_1_diff  \\\n",
       "0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fb...  0.024933 -0.002072   \n",
       "00000fd6641609c6ece5454664794f0340ad84dddce9a26... -0.000406  0.000956   \n",
       "\n",
       "                                                    P_2_diff_count  \\\n",
       "0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fb...             6.0   \n",
       "00000fd6641609c6ece5454664794f0340ad84dddce9a26...             6.0   \n",
       "\n",
       "                                                    R_1_diff_count  \\\n",
       "0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fb...             7.0   \n",
       "00000fd6641609c6ece5454664794f0340ad84dddce9a26...             5.0   \n",
       "\n",
       "                                                    P_2_diff_mean  \\\n",
       "0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fb...      -0.007675   \n",
       "00000fd6641609c6ece5454664794f0340ad84dddce9a26...      -0.008756   \n",
       "\n",
       "                                                    R_1_diff_mean   P_2_ema  \\\n",
       "0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fb...      -0.000507  0.930801   \n",
       "00000fd6641609c6ece5454664794f0340ad84dddce9a26...      -0.000381  0.878641   \n",
       "\n",
       "                                                     R_1_ema   P_2_std  \\\n",
       "0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fb...  0.001864  0.933747   \n",
       "00000fd6641609c6ece5454664794f0340ad84dddce9a26...  0.007023  0.901428   \n",
       "\n",
       "                                                     R_1_std  \n",
       "0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fb...  0.004376  \n",
       "00000fd6641609c6ece5454664794f0340ad84dddce9a26...  0.006191  \n",
       "\n",
       "[2 rows x 28 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = agg_features(df, k=3)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3a10f4",
   "metadata": {},
   "source": [
    "Explore the different columns, datatypes, descriptive stats\n",
    "\n",
    "For reference: \n",
    "* D_* = Delinquency variables\n",
    "* S_* = Spend variables\n",
    "* P_* = Payment variables\n",
    "* B_* = Balance variables\n",
    "* R_* = Risk variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54e4311",
   "metadata": {},
   "outputs": [],
   "source": [
    "spend = X_df.iloc[:,X_df.columns.str[0] == 'S']\n",
    "delinq = X_df.iloc[:,X_df.columns.str[0] == 'D']\n",
    "pay = X_df.iloc[:,X_df.columns.str[0] == 'P']\n",
    "balance = X_df.iloc[:,X_df.columns.str[0] == 'B']\n",
    "risk = X_df.iloc[:,X_df.columns.str[0] == 'R']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace8176f",
   "metadata": {},
   "source": [
    "**Spend variables**\n",
    "\n",
    "- 22 total columns\n",
    "\n",
    "- S_2: date *needs to be converted* **done**\n",
    "\n",
    "- All others: float\n",
    "\n",
    "- S_2, S_5, S_6, S_8, S_11:S_13, S_15:S_20 : no missing values\n",
    "\n",
    "- S_22:S_26 : missing < 1% of values\n",
    "\n",
    "- S_3, S_7, S_27 : missing 1-25% of values\n",
    "\n",
    "- S_9, S_27 : missing 25-75% of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f71f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "spend.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93641bca",
   "metadata": {},
   "source": [
    "**Delinquency Variables**\n",
    "\n",
    "- 96 total columns\n",
    "\n",
    "- D_63: Object\n",
    "\n",
    "- D_64: Object\n",
    "\n",
    "- All others: float\n",
    "\n",
    "- D_39, D_47, D_51, D_58, D_60, D_63, D_65, D_71, D_75, D_86, D_92, D_93, D_94, D_96, D_127 : no missing values\n",
    "\n",
    "- D_42, D_49, D_66, D_73, D_76, D_87, D_88, D_106, D_108, D_110, D_111, D_132, D_134:D_138, D_142 : missing > 75% of values.\n",
    "\n",
    "- D_41, D_44:D_46, D_48, D_52, D_54:D_55, D_59, D_61, D_62, D_64, D_68:D_70, D_72, D_74, D_78:D_81, D_83, D_84, D_89, D_91, D_102:D_104, D_107, D_109, D_112:D_126, D_128:D_131, D_133, D_139:D_145: missing < 25%\n",
    "\n",
    "- D_43, D_50, D_53 D_56, D_77, D_82, D_105 : 25-75% missing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eeb2fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "delinq.D_63.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f930a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "delinq.D_64.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a288e24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "delinq.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3955709d",
   "metadata": {},
   "source": [
    "**Payment Variables**\n",
    "\n",
    "- 3 total columns (P_2, P_3, P_4)\n",
    "\n",
    "- all: float\n",
    "\n",
    "- P_4 : no missing values\n",
    "\n",
    "- P_2 & P_3 : missing < 1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ee039e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pay.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d286d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "pay.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7154901",
   "metadata": {},
   "source": [
    "**Balance Variables**\n",
    "\n",
    "- 40 variables\n",
    "\n",
    "- B_31: int (0, 1)\n",
    "\n",
    "- all others: float\n",
    "\n",
    "- B_29, B_39, and B_42 are majority null\n",
    "\n",
    "- B_17 is missing \n",
    "\n",
    "- B_1, B_4, B_5, B_7, B_9, B_10, B_11, B_12, B_14, B_18, B_21, B_23, B_24, B_28, B_31, B_32, B_36 have no missing values. \n",
    "\n",
    "- B_2, B_3, B_6, B_8, B_13, B_15, B_16, B_19, B_20, B_25, B_26, B_27, B_30, B_33, B_37, B_38, B_40, B_41 are missing < 1% \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3289d507",
   "metadata": {},
   "outputs": [],
   "source": [
    "balance.B_31.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276a2f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "balance.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7db81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "balance.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe08257",
   "metadata": {},
   "source": [
    "**Risk Variables**\n",
    "\n",
    "- 28 Columns\n",
    "\n",
    "- All: float\n",
    "\n",
    "- R_9, R_26: missing > 90% of values. \n",
    "\n",
    "- R_12, R_20, and R_27 are missing < 1%\n",
    "\n",
    "- R_1:R_8, R_10:R_11, R13:R19, R21:R26, R28 :  no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13cde6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "risk.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa46f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate lists of column names by datatype for future use in analysis\n",
    "object_cols = ['D_63', 'D_64']\n",
    "int_cols = ['B_31']\n",
    "date_cols = ['S_2']\n",
    "\n",
    "# list of non_float columns in order to generate a list of all float column names (186 columns)\n",
    "non_float_cols = object_cols + int_cols + date_cols\n",
    "float_cols = [col for col in X_df.columns if col not in non_float_cols]\n",
    "len(float_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824a24d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None,):\n",
    "    print(null_df.sort_values('total_nulls'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d393a807",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd71b5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_df.groupby('feature_category').percent_nulls.agg(['mean', 'median', 'max', 'min']).sort_values('mean', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
