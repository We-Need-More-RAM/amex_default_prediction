{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a966379c",
   "metadata": {},
   "source": [
    "Acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6a149860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pandas.core.window.ewm import ExponentialMovingWindow as emw\n",
    "\n",
    "import wrangle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "78dd06fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit -r 1 -n 1\n",
    "\n",
    "X_df, y_df = wrangle.acquire_amex(sample_size=199990)\n",
    "X_df = wrangle.clean_amex(X_df).drop(columns=['S_2'])\n",
    "# wrangle.split_amex(X_df, y_df, train_size=.5, test_size=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b88400b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "# Feature Engineering functions #\n",
    "#################################\n",
    "\n",
    "def collapse_columns(X_df):\n",
    "    '''\n",
    "    this function will collapse the multi-level index of the columns \n",
    "    that are generated after computing the first set of aggregates in \n",
    "    our groupby function in the agg_features function.\n",
    "    '''\n",
    "    # df = X_df.copy()\n",
    "    if isinstance(X_df.columns, pd.MultiIndex):\n",
    "        X_df.columns = X_df.columns.to_series().apply(lambda x: \"_\".join(x))\n",
    "    return X_df\n",
    "\n",
    "def get_null_count(X_df):\n",
    "    '''\n",
    "    this function will calculate the number of missing values for each feature. \n",
    "    it reaturns a dataframe with the columns: <column_name_orig>_nulls \n",
    "    '''\n",
    "    missing_vals = X_df.groupby('customer_ID').agg(lambda x: x.isnull().sum())\n",
    "    missing_vals.columns = [x + '_nulls' for x in missing_vals.columns]\n",
    "    return missing_vals\n",
    "\n",
    "def get_zeros(X_df):\n",
    "    '''\n",
    "    this function will calculate the number of zeros values for each feature. \n",
    "    it reaturns a dataframe with the columns: <column_name_orig>_zeros \n",
    "    '''\n",
    "    zeros_df = X_df.groupby('customer_ID').agg(lambda x: (x == 0.0).sum())\n",
    "    zeros_df.columns = [x + '_zeros' for x in zeros_df.columns]\n",
    "    return zeros_df\n",
    "\n",
    "# def get_cv(X_df):\n",
    "#     '''\n",
    "#     this function will compute the coefficient of variation for each feature. \n",
    "#     it reaturns a dataframe with the columns: <column_name_orig>_cv \n",
    "#     '''\n",
    "#     cv_df = X_df.groupby('customer_ID').agg(lambda x: x.std()/x.mean())\n",
    "#     cv_df.columns = [x + '_cv' for x in cv_df.columns]\n",
    "#     return cv_df\n",
    "\n",
    "def get_two_period_difference(X_df):\n",
    "    '''\n",
    "    This function computes the 2-period in values for each feature. \n",
    "    it returns a dataframe with the customer id set to the index. \n",
    "    the function is used in compute_delta_values() function\n",
    "    '''\n",
    "    delta_df = X_df.groupby('customer_ID').diff(periods=2)\n",
    "    delta_df.index = X_df.customer_ID\n",
    "    return delta_df\n",
    "\n",
    "    \n",
    "def get_delta_values(X_df):\n",
    "    '''\n",
    "    This function first gets the two-period difference in values for each feature and assigns that to a dataframe (delta).\n",
    "    It generates a dataframe of the most recent 2-period difference (delta_value).\n",
    "    Next, from the delta dataframe, it computes the number of negative deltas over the customer's history and \n",
    "    assigns that to a dataframe (neg_delta_count).\n",
    "    Next, it uses the delta dataframe to compute the average delta over the customer's history and assigns that to \n",
    "    a dadtaframe (delta_mean).\n",
    "    Finally, all of these dataframes are concatenated into a single dataframe, delta_df. \n",
    "    '''\n",
    "    # first compute the 2 period delta and create a dataframe with those values\n",
    "    delta_df = get_two_period_difference(X_df)\n",
    "    delta_df.columns = [x + '_diff' for x in delta_df.columns]\n",
    "    \n",
    "    # Use the delta df to take the last value as the current delta\n",
    "    delta_value = delta_df.groupby('customer_ID').last()\n",
    "    \n",
    "    # use the delta df to count the number of changes over customer history that were negative\n",
    "    neg_delta_count = delta_df.groupby('customer_ID').agg(lambda x: (x < 0).sum())\n",
    "    neg_delta_count.columns = [x + '_count' for x in delta_df.columns]\n",
    "    \n",
    "    # use the delta df to compute the rolling average of the delta values\n",
    "    delta_mean = delta_df.groupby('customer_ID').transform(lambda x: x.rolling(window=6, \n",
    "                                                                       min_periods=3, \n",
    "                                                                       closed='left').mean())\n",
    "    delta_mean.columns = [x + '_mean' for x in delta_df.columns]\n",
    "    \n",
    "    # take the last value, the current average of change\n",
    "    delta_mean = delta_mean.groupby('customer_ID').last()\n",
    "    \n",
    "    # concatenate the dataframes with the computed values by concatenating columns along the customer index\n",
    "    delta_df = pd.concat([delta_value, neg_delta_count, delta_mean], axis=1)\n",
    "    return delta_df\n",
    "\n",
    "def get_ema(X_df):\n",
    "    '''\n",
    "    This function will compute the exponential moving average, with an alpha of .8. \n",
    "    it returns a dataframe with the columns: <column_name_orig>_ema. \n",
    "    '''\n",
    "    ema_df = X_df.groupby('customer_ID').transform(lambda x: x.ewm(alpha=.8, min_periods=1, adjust=True).mean().shift(periods=1))\n",
    "    ema_df.columns = [x + '_ema' for x in ema_df.columns]\n",
    "    ema_df.index = X_df.customer_ID\n",
    "    ema_df = ema_df.groupby('customer_ID').last()\n",
    "    return ema_df\n",
    "\n",
    "def get_pctb(X_df, metrics_df):\n",
    "    df_customer_indexed = X_df.set_index('customer_ID')\n",
    "    pctb_series = pd.Series()\n",
    "\n",
    "    # loop through original column names and for eacsh one, compute pctb\n",
    "    k = 6\n",
    "    for x in df_customer_indexed.columns:\n",
    "        ubb = metrics_df[x + '_ema'] + k*metrics_df[x + '_std']\n",
    "        lbb = metrics_df[(x + '_ema')] - k*metrics_df[x + '_std']\n",
    "        pctb = (metrics_df[x + '_last'] - lbb) / (ubb - lbb)\n",
    "        pctb_series = pd.concat([pctb_series, pctb], axis=1)\n",
    "    \n",
    "    pctb_df = pd.DataFrame(pctb_series)\n",
    "    pctb_df = pctb_df.iloc[:,1:]\n",
    "    pctb_df.columns = [x + '_%b' for x in df_customer_indexed.columns]\n",
    "    metrics_df = pd.concat([pctb_df, metrics_df], axis=1)\n",
    "    return metrics_df\n",
    "\n",
    "def get_range(X_df, metrics_df):\n",
    "    range_series = pd.Series()\n",
    "    for x in df_customer_indexed.columns:\n",
    "        range_val = metrics_df[x + '_max'] - metrics_df[x + '_min']\n",
    "        range_series = pd.concat([range_series, range_val], axis=1)\n",
    "\n",
    "    range_df = pd.DataFrame(range_series)\n",
    "    range_df = range_df.iloc[:,1:]\n",
    "    range_df.columns = [x + '_%b' for x in df_customer_indexed.columns]\n",
    "    metrics_df = pd.concat([range_df, metrics_df], axis=1)\n",
    "    return metrics_df\n",
    "\n",
    "def get_cv(X_df, metrics_df):\n",
    "    cv_series = pd.Series()\n",
    "    for x in df_customer_indexed.columns:\n",
    "        cv = metrics_df[x + '_std']/metrics_df[x + '_ema']\n",
    "        cv_series = pd.concat([cv_series, cv], axis=1)\n",
    "\n",
    "    cv_df = pd.DataFrame(cv_series)\n",
    "    cv_df = cv_df.iloc[:,1:]\n",
    "    cv_df.columns = [x + '_cv' for x in df_customer_indexed.columns]\n",
    "    metrics_df = pd.concat([cv_df, metrics_df], axis=1)\n",
    "    return metrics_df\n",
    "\n",
    "def ent(data):\n",
    "    \"\"\"Calculates entropy of the passed `pd.Series`\n",
    "    \"\"\"\n",
    "    p_data = data.value_counts()           # counts occurrence of each value\n",
    "    entropy = scipy.stats.entropy(p_data)  # get entropy from counts\n",
    "    return entropy\n",
    "\n",
    "def get_features(X_df):\n",
    "\n",
    "    agg_df = X_df.groupby('customer_ID').agg(['last', 'std', 'min', 'max'])\n",
    "    agg_df = collapse_columns(agg_df)\n",
    "\n",
    "    missing_vals_df = get_null_count(X_df)\n",
    "    zero_df = get_zeros(X_df)\n",
    "    delta_df = get_delta_values(X_df)\n",
    "    ema_df = get_ema(X_df)\n",
    "\n",
    "    metrics_df = pd.concat([agg_df, missing_vals_df, zero_df, delta_df, ema_df],axis=1)\n",
    "\n",
    "    metrics_df = get_pctb(X_df, metrics_df)\n",
    "    metrics_df = get_range(X_df, metrics_df)\n",
    "    metrics_df = get_cv(X_df, metrics_df)\n",
    "\n",
    "    # drop the _min and _std columns. Those are captured in _range and _cv\n",
    "    cols_to_drop = metrics_df.filter(regex='(_min|_std)$', axis=1).columns\n",
    "    metrics_df = metrics_df.drop(columns=cols_to_drop)\n",
    "\n",
    "    # drop those columns where > 90% of rows are missing values\n",
    "    missing_counts_df = pd.DataFrame({'missing_count': metrics_df.isnull().sum(), 'missing_pct': metrics_df.isnull().sum()/len(metrics_df)})\n",
    "    cols_to_drop = missing_counts_df[missing_counts_df.missing_pct > .90].index\n",
    "    metrics_df = metrics_df.drop(columns=cols_to_drop)\n",
    "\n",
    "    entropy_series = metrics_df.apply(ent)\n",
    "    features_df = metrics_df[entropy_series[entropy_series > 1].index]\n",
    "    return features_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca679722",
   "metadata": {},
   "source": [
    "Run line by line, testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "926e1b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>P_2</th>\n",
       "      <th>D_39</th>\n",
       "      <th>B_1</th>\n",
       "      <th>B_2</th>\n",
       "      <th>R_1</th>\n",
       "      <th>S_3</th>\n",
       "      <th>D_41</th>\n",
       "      <th>B_3</th>\n",
       "      <th>D_42</th>\n",
       "      <th>...</th>\n",
       "      <th>D_145</th>\n",
       "      <th>D_63_CO</th>\n",
       "      <th>D_63_CR</th>\n",
       "      <th>D_63_XL</th>\n",
       "      <th>D_63_XM</th>\n",
       "      <th>D_63_XZ</th>\n",
       "      <th>D_64_O</th>\n",
       "      <th>D_64_R</th>\n",
       "      <th>D_64_U</th>\n",
       "      <th>B_31_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>0.938469</td>\n",
       "      <td>0.001733</td>\n",
       "      <td>0.008724</td>\n",
       "      <td>1.006838</td>\n",
       "      <td>0.009228</td>\n",
       "      <td>0.124035</td>\n",
       "      <td>0.008771</td>\n",
       "      <td>0.004709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002674</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>0.936665</td>\n",
       "      <td>0.005775</td>\n",
       "      <td>0.004923</td>\n",
       "      <td>1.000653</td>\n",
       "      <td>0.006151</td>\n",
       "      <td>0.126750</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.002714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009217</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>0.954180</td>\n",
       "      <td>0.091505</td>\n",
       "      <td>0.021655</td>\n",
       "      <td>1.009672</td>\n",
       "      <td>0.006815</td>\n",
       "      <td>0.123977</td>\n",
       "      <td>0.007598</td>\n",
       "      <td>0.009423</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>0.960384</td>\n",
       "      <td>0.002455</td>\n",
       "      <td>0.013683</td>\n",
       "      <td>1.002700</td>\n",
       "      <td>0.001373</td>\n",
       "      <td>0.117169</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>0.947248</td>\n",
       "      <td>0.002483</td>\n",
       "      <td>0.015193</td>\n",
       "      <td>1.000727</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>0.117325</td>\n",
       "      <td>0.004653</td>\n",
       "      <td>0.009312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009827</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199985</th>\n",
       "      <td>09572daa668d689b39d22d8a6a234d48141259b0675b0d...</td>\n",
       "      <td>0.837093</td>\n",
       "      <td>0.008891</td>\n",
       "      <td>0.010704</td>\n",
       "      <td>1.003218</td>\n",
       "      <td>0.009536</td>\n",
       "      <td>0.135677</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.009491</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002958</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199986</th>\n",
       "      <td>09572daa668d689b39d22d8a6a234d48141259b0675b0d...</td>\n",
       "      <td>0.836307</td>\n",
       "      <td>0.033900</td>\n",
       "      <td>0.037365</td>\n",
       "      <td>1.007822</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.124006</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.002805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002722</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199987</th>\n",
       "      <td>09572daa668d689b39d22d8a6a234d48141259b0675b0d...</td>\n",
       "      <td>0.878741</td>\n",
       "      <td>0.240031</td>\n",
       "      <td>0.044401</td>\n",
       "      <td>1.007089</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.128138</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>0.003904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009201</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199988</th>\n",
       "      <td>09572daa668d689b39d22d8a6a234d48141259b0675b0d...</td>\n",
       "      <td>0.836796</td>\n",
       "      <td>0.091514</td>\n",
       "      <td>0.013977</td>\n",
       "      <td>1.001713</td>\n",
       "      <td>0.007423</td>\n",
       "      <td>0.121567</td>\n",
       "      <td>0.008139</td>\n",
       "      <td>0.007592</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001935</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199989</th>\n",
       "      <td>09572daa668d689b39d22d8a6a234d48141259b0675b0d...</td>\n",
       "      <td>0.878058</td>\n",
       "      <td>0.212243</td>\n",
       "      <td>0.030657</td>\n",
       "      <td>1.000936</td>\n",
       "      <td>0.003643</td>\n",
       "      <td>0.117669</td>\n",
       "      <td>0.007408</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199990 rows × 195 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              customer_ID       P_2      D_39  \\\n",
       "0       0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  0.938469  0.001733   \n",
       "1       0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  0.936665  0.005775   \n",
       "2       0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  0.954180  0.091505   \n",
       "3       0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  0.960384  0.002455   \n",
       "4       0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  0.947248  0.002483   \n",
       "...                                                   ...       ...       ...   \n",
       "199985  09572daa668d689b39d22d8a6a234d48141259b0675b0d...  0.837093  0.008891   \n",
       "199986  09572daa668d689b39d22d8a6a234d48141259b0675b0d...  0.836307  0.033900   \n",
       "199987  09572daa668d689b39d22d8a6a234d48141259b0675b0d...  0.878741  0.240031   \n",
       "199988  09572daa668d689b39d22d8a6a234d48141259b0675b0d...  0.836796  0.091514   \n",
       "199989  09572daa668d689b39d22d8a6a234d48141259b0675b0d...  0.878058  0.212243   \n",
       "\n",
       "             B_1       B_2       R_1       S_3      D_41       B_3  D_42  ...  \\\n",
       "0       0.008724  1.006838  0.009228  0.124035  0.008771  0.004709   NaN  ...   \n",
       "1       0.004923  1.000653  0.006151  0.126750  0.000798  0.002714   NaN  ...   \n",
       "2       0.021655  1.009672  0.006815  0.123977  0.007598  0.009423   NaN  ...   \n",
       "3       0.013683  1.002700  0.001373  0.117169  0.000685  0.005531   NaN  ...   \n",
       "4       0.015193  1.000727  0.007605  0.117325  0.004653  0.009312   NaN  ...   \n",
       "...          ...       ...       ...       ...       ...       ...   ...  ...   \n",
       "199985  0.010704  1.003218  0.009536  0.135677  0.000292  0.009491   NaN  ...   \n",
       "199986  0.037365  1.007822  0.006882  0.124006  0.000891  0.002805   NaN  ...   \n",
       "199987  0.044401  1.007089  0.000405  0.128138  0.001392  0.003904   NaN  ...   \n",
       "199988  0.013977  1.001713  0.007423  0.121567  0.008139  0.007592   NaN  ...   \n",
       "199989  0.030657  1.000936  0.003643  0.117669  0.007408  0.000797   NaN  ...   \n",
       "\n",
       "           D_145  D_63_CO  D_63_CR  D_63_XL  D_63_XM  D_63_XZ  D_64_O  D_64_R  \\\n",
       "0       0.002674        0        1        0        0        0       1       0   \n",
       "1       0.009217        0        1        0        0        0       1       0   \n",
       "2       0.002603        0        1        0        0        0       1       0   \n",
       "3       0.009600        0        1        0        0        0       1       0   \n",
       "4       0.009827        0        1        0        0        0       1       0   \n",
       "...          ...      ...      ...      ...      ...      ...     ...     ...   \n",
       "199985  0.002958        1        0        0        0        0       1       0   \n",
       "199986  0.002722        1        0        0        0        0       1       0   \n",
       "199987  0.009201        1        0        0        0        0       1       0   \n",
       "199988  0.001935        1        0        0        0        0       1       0   \n",
       "199989  0.000492        1        0        0        0        0       1       0   \n",
       "\n",
       "        D_64_U  B_31_1  \n",
       "0            0       1  \n",
       "1            0       1  \n",
       "2            0       1  \n",
       "3            0       1  \n",
       "4            0       1  \n",
       "...        ...     ...  \n",
       "199985       0       1  \n",
       "199986       0       1  \n",
       "199987       0       1  \n",
       "199988       0       1  \n",
       "199989       0       1  \n",
       "\n",
       "[199990 rows x 195 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "994e9f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = get_features(X_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2a0a56eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.to_csv('features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d12f43",
   "metadata": {},
   "source": [
    "Flatten the time series data. \n",
    "\n",
    "For each variable, we need to create the following:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3a10f4",
   "metadata": {},
   "source": [
    "Explore the different columns, datatypes, descriptive stats\n",
    "\n",
    "For reference: \n",
    "* D_* = Delinquency variables\n",
    "* S_* = Spend variables\n",
    "* P_* = Payment variables\n",
    "* B_* = Balance variables\n",
    "* R_* = Risk variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54e4311",
   "metadata": {},
   "outputs": [],
   "source": [
    "spend = X_df.iloc[:,X_df.columns.str[0] == 'S']\n",
    "delinq = X_df.iloc[:,X_df.columns.str[0] == 'D']\n",
    "pay = X_df.iloc[:,X_df.columns.str[0] == 'P']\n",
    "balance = X_df.iloc[:,X_df.columns.str[0] == 'B']\n",
    "risk = X_df.iloc[:,X_df.columns.str[0] == 'R']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace8176f",
   "metadata": {},
   "source": [
    "**Spend variables**\n",
    "\n",
    "- 22 total columns\n",
    "\n",
    "- S_2: date *needs to be converted* **done**\n",
    "\n",
    "- All others: float\n",
    "\n",
    "- S_2, S_5, S_6, S_8, S_11:S_13, S_15:S_20 : no missing values\n",
    "\n",
    "- S_22:S_26 : missing < 1% of values\n",
    "\n",
    "- S_3, S_7, S_27 : missing 1-25% of values\n",
    "\n",
    "- S_9, S_27 : missing 25-75% of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f71f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "spend.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93641bca",
   "metadata": {},
   "source": [
    "**Delinquency Variables**\n",
    "\n",
    "- 96 total columns\n",
    "\n",
    "- D_63: Object\n",
    "\n",
    "- D_64: Object\n",
    "\n",
    "- All others: float\n",
    "\n",
    "- D_39, D_47, D_51, D_58, D_60, D_63, D_65, D_71, D_75, D_86, D_92, D_93, D_94, D_96, D_127 : no missing values\n",
    "\n",
    "- D_42, D_49, D_66, D_73, D_76, D_87, D_88, D_106, D_108, D_110, D_111, D_132, D_134:D_138, D_142 : missing > 75% of values.\n",
    "\n",
    "- D_41, D_44:D_46, D_48, D_52, D_54:D_55, D_59, D_61, D_62, D_64, D_68:D_70, D_72, D_74, D_78:D_81, D_83, D_84, D_89, D_91, D_102:D_104, D_107, D_109, D_112:D_126, D_128:D_131, D_133, D_139:D_145: missing < 25%\n",
    "\n",
    "- D_43, D_50, D_53 D_56, D_77, D_82, D_105 : 25-75% missing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eeb2fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "delinq.D_63.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f930a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "delinq.D_64.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a288e24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "delinq.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3955709d",
   "metadata": {},
   "source": [
    "**Payment Variables**\n",
    "\n",
    "- 3 total columns (P_2, P_3, P_4)\n",
    "\n",
    "- all: float\n",
    "\n",
    "- P_4 : no missing values\n",
    "\n",
    "- P_2 & P_3 : missing < 1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ee039e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pay.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d286d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "pay.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7154901",
   "metadata": {},
   "source": [
    "**Balance Variables**\n",
    "\n",
    "- 40 variables\n",
    "\n",
    "- B_31: int (0, 1)\n",
    "\n",
    "- all others: float\n",
    "\n",
    "- B_29, B_39, and B_42 are majority null\n",
    "\n",
    "- B_17 is missing \n",
    "\n",
    "- B_1, B_4, B_5, B_7, B_9, B_10, B_11, B_12, B_14, B_18, B_21, B_23, B_24, B_28, B_31, B_32, B_36 have no missing values. \n",
    "\n",
    "- B_2, B_3, B_6, B_8, B_13, B_15, B_16, B_19, B_20, B_25, B_26, B_27, B_30, B_33, B_37, B_38, B_40, B_41 are missing < 1% \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3289d507",
   "metadata": {},
   "outputs": [],
   "source": [
    "balance.B_31.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276a2f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "balance.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7db81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "balance.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe08257",
   "metadata": {},
   "source": [
    "**Risk Variables**\n",
    "\n",
    "- 28 Columns\n",
    "\n",
    "- All: float\n",
    "\n",
    "- R_9, R_26: missing > 90% of values. \n",
    "\n",
    "- R_12, R_20, and R_27 are missing < 1%\n",
    "\n",
    "- R_1:R_8, R_10:R_11, R13:R19, R21:R26, R28 :  no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13cde6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "risk.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa46f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate lists of column names by datatype for future use in analysis\n",
    "object_cols = ['D_63', 'D_64']\n",
    "int_cols = ['B_31']\n",
    "date_cols = ['S_2']\n",
    "\n",
    "# list of non_float columns in order to generate a list of all float column names (186 columns)\n",
    "non_float_cols = object_cols + int_cols + date_cols\n",
    "float_cols = [col for col in X_df.columns if col not in non_float_cols]\n",
    "len(float_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824a24d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None,):\n",
    "    print(null_df.sort_values('total_nulls'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d393a807",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd71b5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_df.groupby('feature_category').percent_nulls.agg(['mean', 'median', 'max', 'min']).sort_values('mean', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d9c26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df.target.value_counts(normalize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
